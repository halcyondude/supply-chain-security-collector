{
	"data": {
		"repository": {
			"name": "cilium",
			"nameWithOwner": "cilium/cilium",
			"url": "https://github.com/cilium/cilium",
			"description": "eBPF-based Networking, Security, and Observability",
			"releases": {
				"nodes": [
					{
						"name": "Cilium 0.8.0",
						"tagName": "v0.8.0",
						"url": "https://github.com/cilium/cilium/releases/tag/v0.8.0",
						"createdAt": "2017-03-28T10:56:08Z",
						"releaseAssets": {
							"nodes": []
						}
					}
				]
			},
			"workflows": {
				"entries": [
					{
						"name": "ariane-scheduled.yaml",
						"object": {
							"text": "name: Ariane scheduled workflows\n\non:\n  # Run every 1 hours\n  # Tests are only run when current hour % 6 corresponds\n  # to the branch hourModulo value in the matrix\n  schedule:\n    - cron: '0 */1 * * *'\n\n\npermissions:\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To trigger workflows via workflow_dispatch\n  actions: write\n\njobs:\n  ariane-scheduled:\n    name: Run Scheduled Workflows\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        # DON'T USE hourModulo=0 to avoid running ariane scheduled-workflows\n        # at the same time as regular main scheduled workflows\n          - branch: 'v1.16'\n            hourModulo: 1\n          - branch: 'v1.17'\n            hourModulo: 2\n          - branch: 'v1.18'\n            hourModulo: 3\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout branch\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ matrix.branch }}\n          persist-credentials: false\n\n      - name: Manually run Ariane workflows from the branch\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          HOUR=$(date -u +\"%H\")\n          if (( HOUR % 6 == ${{ matrix.hourModulo }} )); then\n            echo \"Running scheduled workflows for branch ${{ matrix.branch }}\"\n          else\n            echo \"Skipping scheduled workflows for branch ${{ matrix.branch }}\"\n            exit 0\n          fi\n\n          REF=\"${{ matrix.branch }}\"\n          SHA=$(git rev-parse ${REF})\n          readarray workflows < <((\n            yq '.triggers[\"/test\"].workflows[]' .github/ariane-config.yaml\n            yq '.schedule.nightly.workflows[]' .github/ariane-config.yaml\n          ) | sort -u)\n\n          for workflow in \"${workflows[@]}\"; do\n            echo triggering ${workflow}\n            gh workflow run ${workflow} \\\n              --ref ${REF} \\\n              -f PR-number=${REF/./-} \\\n              -f context-ref=${REF} \\\n              -f SHA=${SHA}\n          done\n"
						}
					},
					{
						"name": "auto-approve.yaml",
						"object": {
							"text": "name: Approve Renovate PR\n\non:\n  pull_request:\n    types:\n    - review_requested\n\njobs:\n  pre-approve:\n    # Avoid running the 'auto-approve' environment if we don't need to.\n    name: Pre-Approve\n    runs-on: ubuntu-24.04\n    if: ${{\n         github.event.pull_request.user.login == 'cilium-renovate[bot]' &&\n         github.triggering_actor == 'cilium-renovate[bot]' &&\n         github.event.requested_reviewer.login == 'ciliumbot'\n        }}\n    steps:\n    - name: Debug\n      run: |\n        echo ${{ github.event.pull_request.user.login }}\n        echo ${{ github.triggering_actor }}\n        echo ${{ github.event.requested_reviewer.login }}\n\n  approve:\n    name: Approve\n    needs: pre-approve\n    environment: auto-approve\n    runs-on: ubuntu-24.04\n    steps:\n    - name: Debug\n      run: |\n        echo ${{ github.event.pull_request.user.login }}\n        echo ${{ github.triggering_actor }}\n        echo ${{ github.event.requested_reviewer.login }}\n\n    - name: Approve PR\n      # Approve the PR if all the following conditions are true:\n      # - the PR review was requested by renovate bot and\n      # - the PR was also created by renovate bot\n      # - the requested reviewer was the trusted 'ciliumbot'\n      if: ${{\n           github.event.pull_request.user.login == 'cilium-renovate[bot]' &&\n           github.triggering_actor == 'cilium-renovate[bot]' &&\n           github.event.requested_reviewer.login == 'ciliumbot'\n          }}\n      env:\n        TOKEN: ${{ secrets.AUTO_APPROVE_TOKEN }}\n        GITHUB_REPOSITORY: ${{ github.repository }}\n        PULL_REQUEST_NUMBER: ${{ github.event.pull_request.number }}\n      run: |\n        echo ${TOKEN} | gh auth login --with-token\n        gh -R ${GITHUB_REPOSITORY} pr review ${PULL_REQUEST_NUMBER} --approve\n\n        echo \"Remove other reviewers except ciliumbot to avoid noise\"\n        reviewers=$(gh -R ${GITHUB_REPOSITORY} pr view ${PULL_REQUEST_NUMBER} --json reviewRequests --jq '.reviewRequests[] | select(.\"__typename\"==\"User\") | .login')\n        for reviewer in $reviewers; do\n          if [ \"$reviewer\" != \"ciliumbot\" ]; then\n            gh -R ${GITHUB_REPOSITORY} pr edit ${PULL_REQUEST_NUMBER} --remove-reviewer \"$reviewer\"\n          fi\n        done\n"
						}
					},
					{
						"name": "auto-labeler.yaml",
						"object": {
							"text": "name: PR and Issues Auto Labeler\n\non:\n  pull_request_target:\n    types:\n      - opened\n      - reopened\n\njobs:\n  external-contributions:\n    if: |\n      (\n        (github.event.pull_request.author_association != 'OWNER') &&\n        (github.event.pull_request.author_association != 'COLLABORATOR') &&\n        (github.event.pull_request.author_association != 'MEMBER')\n      )\n    runs-on: ubuntu-24.04\n    name: External Contributions\n    permissions:\n      pull-requests: write\n    steps:\n        # Detect if the secret 'CHECK_TEAM_ORG_APP_ID' is set. If it's not set, don't\n        # bother running this GH workflow.\n      - name: Check if CHECK_TEAM_ORG_APP_ID is set in github secrets\n        id: check_secret\n        run: |\n          echo \"is_CHECK_TEAM_ORG_APP_ID_set: ${{ secrets.CHECK_TEAM_ORG_APP_ID != '' }}\"\n          echo is_CHECK_TEAM_ORG_APP_ID_set=\"${{ secrets.CHECK_TEAM_ORG_APP_ID != '' }}\" >> $GITHUB_OUTPUT\n\n      - name: Get token\n        # Get a token with the read:org permissions so that the GH action\n        # can read the team membership for a user. We need to do this over a\n        # GH app because GH actions don't have support for these type of\n        # permissions.\n        if: ${{ steps.check_secret.outputs.is_CHECK_TEAM_ORG_APP_ID_set == 'true' }}\n        id: get_token\n        uses: cilium/actions-app-token@61a6271ce92ba02f49bf81c755685d59fb25a59a # v0.21.1\n        with:\n          APP_PEM: ${{ secrets.CHECK_TEAM_ORG_PEM }}\n          APP_ID: ${{ secrets.CHECK_TEAM_ORG_APP_ID }}\n\n      - name: Check author association\n        if: ${{ steps.check_secret.outputs.is_CHECK_TEAM_ORG_APP_ID_set == 'true' }}\n        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0\n        id: author_association\n        # https://docs.github.com/en/rest/orgs/members?apiVersion=2022-11-28#check-organization-membership-for-a-user\n        with:\n          github-token: ${{ steps.get_token.outputs.app_token }}\n          script: |\n            try {\n              const result = await github.rest.orgs.checkMembershipForUser({\n                org: \"${{ github.repository_owner }}\",\n                username: \"${{github.event.pull_request.user.login}}\",\n              })\n              return result.status == 204;\n            } catch {\n              return false;\n            }\n\n      - name: Print author association\n        if: ${{ steps.check_secret.outputs.is_CHECK_TEAM_ORG_APP_ID_set == 'true' }}\n        run: |\n          echo author_association_from_event=${{ github.event.pull_request.author_association }}\n          echo author_association_from_api=${{ steps.author_association.outputs.result }}\n\n      - name: Set label\n        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0\n        if: ${{ steps.check_secret.outputs.is_CHECK_TEAM_ORG_APP_ID_set == 'true' && steps.author_association.outputs.result != 'true' }}\n        with:\n          script: |\n            github.rest.issues.addLabels({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              labels: [\"kind/community-contribution\"]\n            })\n\n  auto-labeler:\n    name: Auto Labeler\n    permissions:\n      contents: read\n      pull-requests: write\n    runs-on: ubuntu-24.04\n    steps:\n    - name: Label The PR\n      uses: actions/labeler@634933edcd8ababfe52f92936142cc22ac488b1b # v6.0.1\n"
						}
					},
					{
						"name": "build-go-caches.yaml",
						"object": {
							"text": "name: Build Golang caches\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  push:\n    branches:\n      - main\n\n  # If the cache was cleaned we should re-build the cache with the latest commit\n  workflow_run:\n    workflows:\n     - \"Image CI Cache Cleaner\"\n    branches:\n     - main\n     - ft/main/**\n    types:\n     - completed\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.after }}\n  cancel-in-progress: true\n\njobs:\n  build_go_caches:\n    name: Build Go Caches\n    runs-on: ubuntu-24.04\n    timeout-minutes: 20\n    strategy:\n      matrix:\n        include:\n          - name: cilium\n            make-target: build-container\n\n          - name: cilium-cli\n            make-target: -C cilium-cli\n            require-dir: cilium-cli\n\n          - name: operator-aws\n            make-target: build-container-operator-aws\n\n          - name: operator-azure\n            make-target: build-container-operator-azure\n\n          - name: operator-alibabacloud\n            make-target: build-container-operator-alibabacloud\n\n          - name: operator-generic\n            make-target: build-container-operator-generic\n\n          - name: hubble-relay\n            make-target: build-container-hubble-relay\n\n          - name: clustermesh-apiserver\n            make-target: build-container-clustermesh-apiserver\n\n          - name: docker-plugin\n            make-target: -C plugins/cilium-docker\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Check for disk usage\n        shell: bash\n        run: |\n          df -h\n\n      # Load Golang cache build from GitHub\n      - name: Load Golang cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-${{ matrix.name }}-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-${{ matrix.name }}-cache-\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/go/.cache/go-build\n          mkdir -p /tmp/.cache/go/pkg\n\n      - name: Check build constraints\n        id: check\n        run: |\n          if [[ -z \"${{ matrix.require-dir }}\" ]] ||\n             [[ -d \"${{ matrix.require-dir }}\" ]]; then\n            echo build=\"true\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Build all programs\n        env:\n          BUILDER_GOCACHE_DIR: \"/tmp/.cache/go/.cache/go-build\"\n          BUILDER_GOMODCACHE_DIR: \"/tmp/.cache/go/pkg\"\n          RUN_AS_ROOT: \"true\"\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' &&\n              steps.check.outputs.build != ''\n           }}\n        run: |\n          set -eu -o pipefail\n          # Don't build cilium-cli for arm64\n          if [[ ${{ matrix.name }} != cilium-cli ]]; then\n            contrib/scripts/builder.sh make GOARCH=arm64 ${{ matrix.make-target }} -j \"$(nproc)\" || exit 1\n          fi\n          contrib/scripts/builder.sh make GOARCH=amd64 NOSTRIP=1 ${{ matrix.make-target }} -j \"$(nproc)\" || exit 1\n          contrib/scripts/builder.sh make GOARCH=amd64 LOCKDEBUG=1 RACE=1 ${{ matrix.make-target }} -j \"$(nproc)\" || exit 1\n          contrib/scripts/builder.sh make GOARCH=amd64 ${{ matrix.make-target }} -j \"$(nproc)\" || exit 1\n\n      - name: Reset cache ownership to GitHub runners user\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          sudo du -sh /tmp/.cache/go\n          sudo chown $USER:$USER -R /tmp/.cache/go\n"
						}
					},
					{
						"name": "build-images-base-renovate.yaml",
						"object": {
							"text": "name: Base Image Release Build - Renovate\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  push:\n    branches:\n      - \"renovate/main-**\"\n    paths:\n      - images/runtime/**\n      - images/builder/**\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n  # Required to generate OIDC tokens for `sigstore/cosign-installer` authentication\n  id-token: write\n\njobs:\n  build-base-images-from-renovate:\n    name: \"Build Base Images From Renovate\"\n    uses: ./.github/workflows/build-images-base.yaml\n    secrets: inherit\n    with:\n      # Build the base images from this environment which is set up specifically\n      # for renovate.\n      environment: release-base-images-renovate\n"
						}
					},
					{
						"name": "build-images-base.yaml",
						"object": {
							"text": "name: Base Image Release Build\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request_target:\n    types:\n      - opened\n      - synchronize\n      - reopened\n    paths:\n      - images/runtime/**\n      - images/builder/**\n  # This workflow can be reused so that renovate can execute this workflow_dispatch:\n  # run from a different environment than 'release-base-images'. See\n  # build-images-base-renovate.yaml\n  workflow_call:\n    secrets:\n      QUAY_BASE_RELEASE_USERNAME_202411:\n        required: true\n      QUAY_BASE_RELEASE_PASSWORD_202411:\n        required: true\n      AUTO_COMMITTER_PEM_202411:\n        required: true\n      AUTO_COMMITTER_APP_ID_202411:\n        required: true\n    inputs:\n      environment:\n        required: true\n        type: string\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n  # Required to generate OIDC tokens for `sigstore/cosign-installer` authentication\n  id-token: write\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build-and-push:\n    # Skip this workflow for repositories without credentials and branches that are created by renovate where the event type is pull_request_target\n    if: ${{ vars.QUAY_BASE_RELEASE_ENABLED == 'true' && ! (github.event_name == 'pull_request_target' && startsWith(github.head_ref, 'renovate/')) }}\n    name: Build and Push Images\n    timeout-minutes: 60\n    environment: ${{ inputs.environment || 'release-base-images' }}\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout base or default branch (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          # This workflow is supposed to run only on pull_request_target context, but in case workflow call is made from a push context we still keep the default to default_branch\n          ref: ${{ github.base_ref || github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Copy scripts to trusted directory\n        run: |\n          mkdir -p ../cilium-base-branch/images/runtime/\n          cp ./images/runtime/update-cilium-runtime-image.sh ../cilium-base-branch/images/runtime/\n          mkdir -p ../cilium-base-branch/images/builder/\n          cp ./images/builder/update-cilium-builder-image.sh ../cilium-base-branch/images/builder/\n          mkdir -p ../cilium-base-branch/images/scripts/\n          cp ./images/scripts/get-image-digest.sh ../cilium-base-branch/images/scripts/\n          mkdir -p ../cilium-base-branch/api/v1\n          cp ./api/v1/Makefile ../cilium-base-branch/api/v1/\n          cp ./Makefile.defs ../cilium-base-branch/Makefile.defs\n          cp ./Makefile.quiet ../cilium-base-branch/Makefile.quiet\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1\n\n      - name: Set up QEMU\n        id: qemu\n        uses: docker/setup-qemu-action@29109295f81e9208d7d86ff1c6c12d2833863392 # v3.6.0\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n\n      - name: Set-up git\n        run: |\n          git config user.name \"Cilium Imagebot\"\n          git config user.email \"noreply@cilium.io\"\n\n      - name: Generating image tag for Cilium-Runtime\n        id: runtime-tag\n        run: |\n          echo tag=\"$(git ls-tree --full-tree HEAD -- ./images/runtime | awk '{ print $3 }')\" >> $GITHUB_OUTPUT\n\n      - name: Checking if tag for Cilium-Runtime already exists\n        id: cilium-runtime-tag-in-repositories\n        shell: bash\n        run: |\n          if docker buildx imagetools inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{  steps.runtime-tag.outputs.tag }} &>/dev/null; then\n            echo exists=\"true\" >> $GITHUB_OUTPUT\n          else\n            echo exists=\"false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Login to quay.io\n        if: ${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_BASE_RELEASE_USERNAME_202411 }}\n          password: ${{ secrets.QUAY_BASE_RELEASE_PASSWORD_202411 }}\n\n      - name: Release build cilium-runtime\n        if: ${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_release_runtime\n        with:\n          provenance: false\n          context: ./images/runtime\n          file: ./images/runtime/Dockerfile\n          push: true\n          platforms: linux/amd64,linux/arm64\n          tags: |\n            quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}\n\n      - name: Generate SBOM, Sign, and Attest Runtime Image\n        if: ${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime@${{ steps.docker_build_release_runtime.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}\"\n          sbom_name: \"cilium-runtime_${{ steps.runtime-tag.outputs.tag }}\"\n\n      - name: Image Release Digest Runtime\n        if: ${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n          echo \"## cilium-runtime\" > image-digest/cilium-runtime.txt\n          echo \"\" >> image-digest/cilium-runtime.txt\n          echo \"\\`quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}@${{ steps.docker_build_release_runtime.outputs.digest }}\\`\" >> image-digest/cilium-runtime.txt\n          echo \"\" >> image-digest/cilium-runtime.txt\n\n      - name: Upload artifact digests runtime\n        if: ${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest cilium-runtime\n          path: image-digest\n          retention-days: 1\n\n      - name: Update Runtime Image\n        id: update-runtime-image\n        run: |\n          if [[ \"${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\" == \"true\" ]]; then\n            ../cilium-base-branch/images/runtime/update-cilium-runtime-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}@${{ steps.docker_build_release_runtime.outputs.digest }}\"\n          else\n            digest=$(../cilium-base-branch/images/scripts/get-image-digest.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}\")\n            ../cilium-base-branch/images/runtime/update-cilium-runtime-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}@${digest}\"\n          fi\n          if ! git diff --quiet; then\n            git commit -sam \"images: update cilium-{runtime,builder}\"\n            echo committed=\"true\" >> $GITHUB_OUTPUT\n          else\n            echo committed=\"false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Generating image tag for Cilium-Builder\n        id: builder-tag\n        run: |\n          echo tag=\"$(git ls-tree --full-tree HEAD -- ./images/builder | awk '{ print $3 }')\" >> $GITHUB_OUTPUT\n\n      - name: Checking if tag for Cilium-Builder already exists\n        id: cilium-builder-tag-in-repositories\n        shell: bash\n        run: |\n          if docker buildx imagetools inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{  steps.builder-tag.outputs.tag }} &>/dev/null; then\n            echo exists=\"true\" >> $GITHUB_OUTPUT\n          else\n            echo exists=\"false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Login to quay.io\n        if: ${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' && steps.cilium-runtime-tag-in-repositories.outputs.exists != 'false' }}\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_BASE_RELEASE_USERNAME_202411 }}\n          password: ${{ secrets.QUAY_BASE_RELEASE_PASSWORD_202411 }}\n\n      - name: Release build cilium-builder\n        if: ${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_release_builder\n        with:\n          provenance: false\n          context: ./images/builder\n          file: ./images/builder/Dockerfile\n          push: true\n          platforms: linux/amd64,linux/arm64\n          tags: |\n            quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}\n\n      - name: Generate SBOM, Sign, and Attest Builder Image\n        if: ${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' }}\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder@${{ steps.docker_build_release_builder.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}\"\n          sbom_name: \"cilium-builder_${{ steps.builder-tag.outputs.tag }}\"\n\n      - name: Image Release Digest Builder\n        if: ${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' }}\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n          echo \"## cilium-builder\" > image-digest/cilium-builder.txt\n          echo \"\" >> image-digest/cilium-builder.txt\n          echo \"\\`quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${{ steps.docker_build_release_builder.outputs.digest }}\\`\" >> image-digest/cilium-builder.txt\n          echo \"\" >> image-digest/cilium-builder.txt\n\n      - name: Upload artifact digests builder\n        if: ${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest cilium-builder\n          path: image-digest\n          retention-days: 1\n\n      - name: Update Runtime Image\n        run: |\n          if [[ \"${{ steps.cilium-runtime-tag-in-repositories.outputs.exists == 'false' }}\" == \"true\" ]]; then\n            ../cilium-base-branch/images/runtime/update-cilium-runtime-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}@${{ steps.docker_build_release_runtime.outputs.digest }}\"\n          else\n            digest=$(../cilium-base-branch/images/scripts/get-image-digest.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}\")\n            ../cilium-base-branch/images/runtime/update-cilium-runtime-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-runtime:${{ steps.runtime-tag.outputs.tag }}@${digest}\"\n          fi\n\n      - name: Update Builder Images\n        run: |\n          if [[ \"${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' }}\" == \"true\" ]]; then\n            ../cilium-base-branch/images/builder/update-cilium-builder-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${{ steps.docker_build_release_builder.outputs.digest }}\"\n          else\n            digest=$(../cilium-base-branch/images/scripts/get-image-digest.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}\")\n            ../cilium-base-branch/images/builder/update-cilium-builder-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${digest}\"\n          fi\n\n      - name: Update protobuf APIs and commit changes\n        id: update-builder-image\n        run: |\n          if [[ \"${{ steps.cilium-builder-tag-in-repositories.outputs.exists == 'false' }}\" == \"true\" ]]; then\n            ../cilium-base-branch/images/builder/update-cilium-builder-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${{ steps.docker_build_release_builder.outputs.digest }}\"\n            export CONTAINER_IMAGE=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${{ steps.docker_build_release_builder.outputs.digest }}\n          else\n            digest=$(../cilium-base-branch/images/scripts/get-image-digest.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}\")\n            ../cilium-base-branch/images/builder/update-cilium-builder-image.sh \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${digest}\"\n            export CONTAINER_IMAGE=\"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-builder:${{ steps.builder-tag.outputs.tag }}@${digest}\"\n          fi\n          export VOLUME=$PWD/api/v1\n          make -C ../cilium-base-branch/api/v1\n          if ! git diff --quiet; then\n            if [[ \"${{ steps.update-runtime-image.outputs.committed }}\" == \"true\" ]]; then\n              git commit --amend -sam \"images: update cilium-{runtime,builder}\"\n            else\n              git commit -sam \"images: update cilium-{runtime,builder}\"\n            fi\n            echo committed=\"true\" >> $GITHUB_OUTPUT\n          else\n            echo committed=\"false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Get token\n        if: ${{ steps.update-runtime-image.outputs.committed == 'true' || steps.update-builder-image.outputs.committed == 'true' }}\n        id: get_token\n        uses: cilium/actions-app-token@61a6271ce92ba02f49bf81c755685d59fb25a59a # v0.21.1\n        with:\n          APP_PEM: ${{ secrets.AUTO_COMMITTER_PEM_202411 }}\n          APP_ID: ${{ secrets.AUTO_COMMITTER_APP_ID_202411 }}\n\n      - name: Push changes into PR\n        if: ${{ steps.update-runtime-image.outputs.committed == 'true' || steps.update-builder-image.outputs.committed == 'true' }}\n        env:\n          ref: ${{ github.event.pull_request.head.ref || github.ref }}\n          repository:  ${{ github.event.pull_request.head.repo.full_name || github.repository }}\n        run: |\n          git diff HEAD^\n          git push https://x-access-token:${{ steps.get_token.outputs.app_token }}@github.com/${{ env.repository }}.git HEAD:$ref\n\n      - name: Prepare for Image Digests\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n\n      - name: Download digests of all images built\n        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0\n        with:\n          path: image-digest/\n          pattern: \"*image-digest *\"\n\n      - name: Image Digests Output\n        shell: bash\n        run: |\n          cd image-digest/\n          find -type f | sort | xargs -d '\\n' cat\n"
						}
					},
					{
						"name": "build-images-beta.yaml",
						"object": {
							"text": "name: Beta Image Release Build\n\non:\n  workflow_dispatch:\n    inputs:\n      tag:\n        description: 'Docker Image Tag'\n        required: true\n      suffix:\n        description: 'Docker Image Suffix (e.g. \"beta\" -> \"cilium-beta\")'\n        required: true\n        default: \"beta\"\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n  # Required to generate OIDC tokens for `sigstore/cosign-installer` authentication\n  id-token: write\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  build-and-push:\n    timeout-minutes: 45\n    name: Build and Push Images\n    environment: release-beta-images\n    runs-on: ubuntu-24.04\n    strategy:\n      matrix:\n        include:\n          - name: cilium\n            dockerfile: ./images/cilium/Dockerfile\n\n          - name: operator\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-aws\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-azure\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-alibabacloud\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-generic\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: hubble-relay\n            dockerfile: ./images/hubble-relay/Dockerfile\n\n          - name: clustermesh-apiserver\n            dockerfile: ./images/clustermesh-apiserver/Dockerfile\n\n          - name: docker-plugin\n            dockerfile: ./images/cilium-docker-plugin/Dockerfile\n\n    steps:\n      - name: Checkout main branch to access local actions\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1\n\n      - name: Login to quay.io\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_BETA_USERNAME }}\n          password: ${{ secrets.QUAY_BETA_PASSWORD }}\n\n      - name: Getting image tag\n        id: tag\n        run: |\n          echo tag=${GITHUB_REF##*/} >> $GITHUB_OUTPUT\n\n      - name: Checking if tag already exists\n        id: tag-in-repositories\n        shell: bash\n        run: |\n          if docker buildx imagetools inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-${{ github.event.inputs.suffix }}:${{ github.event.inputs.tag }} &>/dev/null; then\n            echo \"Tag already exists!\"\n            exit 1\n          fi\n\n      - name: Checkout Source Code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Release Build ${{ matrix.name }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_release\n        with:\n          provenance: false\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          platforms: linux/amd64,linux/arm64\n          tags: |\n            quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-${{ github.event.inputs.suffix }}:${{ github.event.inputs.tag }}\n          target: release\n          build-args: |\n            OPERATOR_VARIANT=${{ matrix.name }}\n\n      - name: Generate SBOM, Sign Images, and Attach Attestations\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-${{ github.event.inputs.suffix }}@${{ steps.docker_build_release.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-${{ github.event.inputs.suffix }}:${{ github.event.inputs.tag }}\"\n          sbom_name: \"${{ matrix.name }}_${{ github.event.inputs.tag }}\"\n\n      - name: Image Release Digest\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n          echo \"## ${{ matrix.name }}\" > image-digest/${{ matrix.name }}.txt\n          echo \"\" >> image-digest/${{ matrix.name }}.txt\n          echo \"\\`quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-${{ github.event.inputs.suffix }}:${{ github.event.inputs.tag }}@${{ steps.docker_build_release.outputs.digest }}\\`\" >> image-digest/${{ matrix.name }}.txt\n          echo \"\" >> image-digest/${{ matrix.name }}.txt\n\n      # Upload artifact digests\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest ${{ matrix.name }}\n          path: image-digest\n          retention-days: 1\n\n  image-digests:\n    name: Display Digests\n    runs-on: ubuntu-24.04\n    needs: build-and-push\n    steps:\n      - name: Downloading Image Digests\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n\n      - name: Download digests of all images built\n        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0\n        with:\n          path: image-digest/\n          pattern: \"*image-digest *\"\n\n      - name: Image Digests Output\n        shell: bash\n        run: |\n          cd image-digest/\n          find -type f | sort | xargs -d '\\n' cat\n"
						}
					},
					{
						"name": "build-images-ci.yaml",
						"object": {
							"text": "name: Image CI Build\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request_target:\n    types:\n      - opened\n      - synchronize\n      - reopened\n  push:\n    branches:\n      - main\n      - ft/main/**\n  merge_group:\n    types: [checks_requested]\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n  # Required to generate OIDC tokens for `sigstore/cosign-installer` authentication\n  id-token: write\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after || (github.event_name == 'merge_group' && github.run_id) }}\n  cancel-in-progress: true\n\njobs:\n  build-and-push-prs:\n    timeout-minutes: 45\n    name: Build and Push Images\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    outputs:\n      sha: ${{ steps.tag.outputs.sha }}\n    strategy:\n      matrix:\n        include:\n          - name: cilium\n            dockerfile: ./images/cilium/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: cilium-cli\n            dockerfile: ./cilium-cli/Dockerfile\n            platforms: linux/amd64\n            require-dir: cilium-cli\n\n          - name: operator-aws\n            dockerfile: ./images/operator/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: operator-azure\n            dockerfile: ./images/operator/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: operator-alibabacloud\n            dockerfile: ./images/operator/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: operator-generic\n            dockerfile: ./images/operator/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: hubble-relay\n            dockerfile: ./images/hubble-relay/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: clustermesh-apiserver\n            dockerfile: ./images/clustermesh-apiserver/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n          - name: docker-plugin\n            dockerfile: ./images/cilium-docker-plugin/Dockerfile\n            platforms: linux/amd64,linux/arm64\n\n    steps:\n      - name: Checkout base or default branch (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          # We first check if base_ref exist, meaning we're in pull_request_target context, and if not we just use default_branch\n          ref: ${{ github.base_ref || github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Copy scripts to trusted directory\n        run: |\n          mkdir -p ../cilium-base-branch\n          cp -r .github/actions/set-runtime-image ../cilium-base-branch\n\n      - name: Check for disk usage and cleanup /mnt\n        shell: bash\n        run: |\n          echo \"# Disk usage\"\n          df -h\n          echo \"# Usage for /mnt\"\n          sudo du --human-readable \\\n                -- /mnt\n          if compgen -G \"/mnt/.*\" > /dev/null; then\n            echo \"# Hidden files in /mnt:\"\n            sudo du --human-readable -- /mnt/.* 2>/dev/null\n          fi\n          echo \"# Removing all contents of /mnt except /mnt/swapfile\"\n          sudo find /mnt -mindepth 1 ! -path /mnt/swapfile -exec rm -rf {} + || true\n\n      - name: Setup docker volumes into /mnt\n        # This allows us to make use of all available disk.\n        shell: bash\n        run: |\n          sudo systemctl stop docker\n          sudo mv /var/lib/docker/volumes /mnt/docker-volumes\n          sudo ln -s /mnt/docker-volumes /var/lib/docker/volumes\n          sudo systemctl start docker\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1\n        # Disable GC entirely to avoid buildkit from GC caches.\n        with:\n          buildkitd-config-inline: |\n            [worker.oci]\n             gc=false\n\n      - name: Login to quay.io for CI\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_USERNAME_CI }}\n          password: ${{ secrets.QUAY_PASSWORD_CI }}\n\n      - name: Getting image tag\n        id: tag\n        run: |\n          if [ \"${{ github.event.pull_request.head.sha }}\" != \"\" ]; then\n            sha=${{ github.event.pull_request.head.sha }}\n          else\n            sha=${{ github.sha }}\n          fi\n          echo sha=${sha} >> $GITHUB_OUTPUT\n\n          tag=${sha}\n          echo tag=${tag} >> $GITHUB_OUTPUT\n\n          if [[ \"${{ github.event_name == 'push' }}\" == \"true\" ]]; then\n            if [[ \"${{ github.ref_name }}\" == \"${{ github.event.repository.default_branch }}\" ]]; then\n              floating_tag=latest\n            else\n              floating_tag=\"${{ github.ref_name }}\"\n              # Remove slashes from branch names\n              floating_tag=${floating_tag##*/}\n            fi\n            echo floating_tag=${floating_tag} >> $GITHUB_OUTPUT\n          fi\n\n          normal_tag=\"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${tag}\"\n          race_tag=\"${normal_tag}-race\"\n          unstripped_tag=\"${normal_tag}-unstripped\"\n\n          if [ -n \"${floating_tag}\" ]; then\n            floating_normal_tag=\"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${floating_tag}\"\n            normal_tag=\"${normal_tag},${floating_normal_tag}\"\n          fi\n\n          if [[ \"${{ github.event_name }}\" == 'merge_group' || \"${{ github.event_name }}\" == 'push' ]]; then\n            # Don't build race and unstripped images for merge_group or push events.\n            race_tag=\"\"\n            unstripped_tag=\"\"\n          fi\n\n          echo normal_tag=${normal_tag} >> $GITHUB_OUTPUT\n          echo race_tag=${race_tag} >> $GITHUB_OUTPUT\n          echo unstripped_tag=${unstripped_tag} >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ steps.tag.outputs.sha }}\n\n      - name: Check for disk usage\n        shell: bash\n        run: |\n          df -h\n\n      - name: Copy runtime image tag from untrusted branch\n        run: |\n          cp -r .github/actions/set-runtime-image/runtime-image.txt ../cilium-base-branch/set-runtime-image/\n\n      - name: Set runtime image environment variable\n        uses: ./../cilium-base-branch/set-runtime-image\n        with:\n          repository: ${{ env.CILIUM_RUNTIME_IMAGE_PREFIX }}\n\n      # Load Golang cache build from GitHub\n      - name: Restore Golang cache build from GitHub\n        uses: actions/cache/restore@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-${{ matrix.name }}-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-${{ matrix.name }}-cache-\n\n      - name: Check for disk usage\n        shell: bash\n        run: |\n          df -h\n          docker buildx du\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/go\n\n      # Import GitHub's cache build to docker cache\n      - name: Copy ${{ matrix.name }} Golang cache to docker cache\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        with:\n          provenance: false\n          context: /tmp/.cache/go\n          file: ./images/cache/Dockerfile\n          push: false\n          platforms: linux/amd64\n          target: import-cache\n\n      - name: Check for disk usage\n        shell: bash\n        run: |\n          df -h\n          docker buildx du\n\n      - name: Check build constraints\n        id: check\n        run: |\n          if [[ -z \"${{ matrix.require-dir }}\" ]] ||\n             [[ -d \"${{ matrix.require-dir }}\" ]]; then\n            echo build=\"true\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: CI Build ${{ matrix.name }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_ci\n        if: ${{ steps.check.outputs.build != '' }}\n        with:\n          provenance: false\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          platforms: ${{ matrix.platforms }}\n          tags: ${{ steps.tag.outputs.normal_tag }}\n          target: release\n          build-args: |\n            CILIUM_RUNTIME_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n            OPERATOR_VARIANT=${{ matrix.name }}\n\n      - name: CI race detection Build ${{ matrix.name }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_ci_detect_race_condition\n        if: ${{ steps.check.outputs.build != '' && steps.tag.outputs.race_tag != ''}}\n        with:\n          provenance: false\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          platforms: linux/amd64\n          tags: ${{ steps.tag.outputs.race_tag }}\n          target: release\n          build-args: |\n            BASE_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n            CILIUM_RUNTIME_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n            MODIFIERS=\"LOCKDEBUG=1 RACE=1\"\n            OPERATOR_VARIANT=${{ matrix.name }}\n\n      - name: CI Unstripped Binaries Build ${{ matrix.name }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_ci_unstripped\n        if: ${{ steps.check.outputs.build != '' && steps.tag.outputs.unstripped_tag != ''}}\n        with:\n          provenance: false\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          platforms: linux/amd64\n          tags: ${{ steps.tag.outputs.unstripped_tag }}\n          target: release\n          build-args: |\n            CILIUM_RUNTIME_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n            MODIFIERS=\"NOSTRIP=1\"\n            OPERATOR_VARIANT=${{ matrix.name }}\n\n      - name: Generate SBOM, Sign, and Attest Main CI Image\n        if: ${{ matrix.name != 'cilium-cli' && steps.check.outputs.build != '' }}\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci@${{ steps.docker_build_ci.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.tag }}\"\n          sbom_name: \"ci_${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n\n      - name: Generate SBOM, Sign, and Attest Race Detection Image\n        if: ${{ matrix.name != 'cilium-cli' && steps.docker_build_ci_detect_race_condition.outcome != 'skipped' }}\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci@${{ steps.docker_build_ci_detect_race_condition.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.tag }}-race\"\n          sbom_name: \"ci_race_${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n          install_cosign: 'false'\n\n      - name: Generate SBOM, Sign, and Attest Unstripped Image\n        if: ${{ matrix.name != 'cilium-cli' && steps.docker_build_ci_unstripped.outcome != 'skipped' }}\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci@${{ steps.docker_build_ci_unstripped.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.tag }}-unstripped\"\n          sbom_name: \"ci_unstripped_${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n          install_cosign: 'false'\n\n      - name: CI Image Releases digests\n        shell: bash\n        if: ${{ steps.check.outputs.build != '' }}\n        run: |\n          mkdir -p image-digest/\n          # shellcheck disable=SC2078\n          if [ ${{ github.event_name == 'push' && !startsWith(github.ref_name, 'ft/') }} ]; then\n            echo \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.floating_tag }}@${{ steps.docker_build_ci.outputs.digest }}\" > image-digest/${{ matrix.name }}.txt\n          fi\n          echo \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.tag }}@${{ steps.docker_build_ci.outputs.digest }}\" >> image-digest/${{ matrix.name }}.txt\n          if [[ \"${{ steps.docker_build_ci_detect_race_condition.outcome }}\" != 'skipped' ]]; then\n            echo \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.tag }}-race@${{ steps.docker_build_ci_detect_race_condition.outputs.digest }}\" >> image-digest/${{ matrix.name }}.txt\n          fi\n          if [[ \"${{ steps.docker_build_ci_unstripped.outcome }}\" != 'skipped' ]]; then\n            echo \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ steps.tag.outputs.tag }}-unstripped@${{ steps.docker_build_ci_unstripped.outputs.digest }}\" >> image-digest/${{ matrix.name }}.txt\n          fi\n\n      # Upload artifact digests\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        if: ${{ steps.check.outputs.build != '' }}\n        with:\n          name: image-digest ${{ matrix.name }}\n          path: image-digest\n          retention-days: 1\n\n      - name: Check for disk usage\n        if: ${{ always() }}\n        shell: bash\n        run: |\n          df -h\n\n  image-digests:\n    if: ${{ always() }}\n    name: Display Digests\n    runs-on: ubuntu-24.04\n    needs: build-and-push-prs\n    steps:\n      - name: Downloading Image Digests\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n\n      - name: Download digests of all images built\n        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0\n        with:\n          path: image-digest/\n          pattern: \"*image-digest *\"\n\n      - name: Image Digests Output\n        shell: bash\n        run: |\n          cd image-digest/\n          find -type f | sort | xargs -d '\\n' cat\n\n  push-chart:\n    name: Push dev chart\n    needs: build-and-push-prs\n    permissions:\n      contents: read\n      pull-requests: read\n      statuses: write\n    uses: ./.github/workflows/push-chart-ci.yaml\n    with:\n      checkout_ref: ${{ needs.build-and-push-prs.outputs.sha }}\n      image_tag: ${{ needs.build-and-push-prs.outputs.sha }}\n    secrets: inherit\n"
						}
					},
					{
						"name": "build-images-docs-builder.yaml",
						"object": {
							"text": "name: Docs-builder Image Build\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request_target:\n    types:\n      - opened\n      - synchronize\n      - reopened\n    paths:\n      - Documentation/Dockerfile\n      - Documentation/requirements.txt\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}\n  cancel-in-progress: true\n\njobs:\n  build-and-push:\n    name: Build and Push Image\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    environment: docs-builder\n    outputs:\n      tag: ${{ steps.docs-builder-tag.outputs.tag }}\n      digest: ${{ steps.docker-build-docs-builder.outputs.digest }}\n    steps:\n      - name: Checkout base branch (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.base_ref }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set environment variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n\n      - name: Generate image tag for docs-builder\n        id: docs-builder-tag\n        run: |\n          echo tag=\"$(git ls-tree --full-tree HEAD -- ./Documentation | awk '{ print $3 }')\" >> $GITHUB_OUTPUT\n\n      - name: Check if tag for docs-builder already exists\n        id: docs-builder-tag-in-repositories\n        shell: bash\n        run: |\n          if docker buildx imagetools inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/docs-builder:${{ steps.docs-builder-tag.outputs.tag }} &>/dev/null; then\n            echo exists=\"true\" >> $GITHUB_OUTPUT\n          else\n            echo exists=\"false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Login to quay.io\n        if: ${{ steps.docs-builder-tag-in-repositories.outputs.exists == 'false' }}\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_DOCS_BUILDER_USERNAME }}\n          password: ${{ secrets.QUAY_DOCS_BUILDER_PASSWORD }}\n          logout: true\n\n      - name: Build docs-builder image\n        if: ${{ steps.docs-builder-tag-in-repositories.outputs.exists == 'false' }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker-build-docs-builder\n        with:\n          provenance: false\n          context: ./Documentation\n          file: ./Documentation/Dockerfile\n          push: true\n          tags: |\n            quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/docs-builder:${{ steps.docs-builder-tag.outputs.tag }}\n\n  # Use a separate job for the steps below, to ensure we're no longer logged\n  # into Quay.io.\n  update-pr:\n    name: Update Pull Request with new image reference\n    needs: build-and-push\n    if: needs.build-and-push.outputs.digest\n    runs-on: ubuntu-24.04\n    timeout-minutes: 10\n    environment: docs-builder\n    steps:\n      - name: Checkout base branch (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.base_ref }}\n          persist-credentials: false\n\n      - name: Set environment variables\n        uses: ./.github/actions/set-env-variables\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n\n      - name: Set up git\n        run: |\n          git config user.name \"Cilium Imagebot\"\n          git config user.email \"noreply@cilium.io\"\n\n      - name: Update docs-builder image reference in CI workflow\n        run: |\n          NEW_IMAGE=\"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/docs-builder:${{ needs.build-and-push.outputs.tag }}@${{ needs.build-and-push.outputs.digest }}\"\n          # Run in Docker to prevent the script from accessing the environment.\n          docker run --rm -v $PWD:/cilium -w /cilium \"${NEW_IMAGE}\" \\\n              bash -c \"git config --global --add safe.directory /cilium && \\\n                       /cilium/Documentation/update-docs-builder-image.sh ${NEW_IMAGE}\"\n          git commit -sam \"ci: update docs-builder\"\n\n      - name: Get token\n        id: get_token\n        uses: cilium/actions-app-token@61a6271ce92ba02f49bf81c755685d59fb25a59a # v0.21.1\n        with:\n          APP_PEM: ${{ secrets.AUTO_COMMITTER_PEM_202411 }}\n          APP_ID: ${{ secrets.AUTO_COMMITTER_APP_ID_202411 }}\n\n      - name: Push changes into PR\n        env:\n          REF: ${{ github.event.pull_request.head.ref }}\n        run: |\n          git diff HEAD^\n          git push https://x-access-token:${{ steps.get_token.outputs.app_token }}@github.com/${{ github.event.pull_request.head.repo.full_name }}.git HEAD:\"$REF\"\n\n  image-digest:\n    name: Retrieve and display image digest\n    needs: build-and-push\n    if: needs.build-and-push.outputs.digest\n    runs-on: ubuntu-24.04\n    timeout-minutes: 10\n    steps:\n      - name: Checkout base branch (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.base_ref }}\n          persist-credentials: false\n\n      - name: Set environment variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Retrieve image digest\n        shell: bash\n        run: |\n          NEW_IMAGE=\"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/docs-builder:${{ needs.build-and-push.outputs.tag }}@${{ needs.build-and-push.outputs.digest }}\"\n          mkdir -p image-digest/\n          echo \"## docs-builder\" > image-digest/docs-builder.txt\n          echo \"\" >> image-digest/docs-builder.txt\n          echo \"\\`${NEW_IMAGE}\\`\" >> image-digest/docs-builder.txt\n          echo \"\" >> image-digest/docs-builder.txt\n\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest docs-builder\n          path: image-digest\n          retention-days: 1\n\n      - name: Output image digest\n        shell: bash\n        run: |\n          cd image-digest/\n          find -type f | sort | xargs -d '\\n' cat\n"
						}
					},
					{
						"name": "build-images-hotfixes.yaml",
						"object": {
							"text": "name: Hot Fix Image Release Build\n\non:\n  push:\n    branches:\n      - hf/main/**\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n  # Required to generate OIDC tokens for `sigstore/cosign-installer` authentication\n  id-token: write\n\njobs:\n  build-and-push:\n    timeout-minutes: 45\n    name: Build and Push Images\n    environment: release-developer-images\n    runs-on: ubuntu-24.04\n    outputs:\n      ref: ${{ steps.tag.outputs.ref }}\n      tag: ${{ steps.tag.outputs.tag }}\n    strategy:\n      matrix:\n        include:\n          - name: cilium\n            dockerfile: ./images/cilium/Dockerfile\n\n          - name: operator\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-aws\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-azure\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-alibabacloud\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-generic\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: hubble-relay\n            dockerfile: ./images/hubble-relay/Dockerfile\n\n          - name: clustermesh-apiserver\n            dockerfile: ./images/clustermesh-apiserver/Dockerfile\n\n          - name: docker-plugin\n            dockerfile: ./images/cilium-docker-plugin/Dockerfile\n\n    steps:\n      - name: Checkout main branch to access local actions\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Copy runtime image action to base branch directory\n        run: |\n          mkdir -p ../cilium-base-branch\n          cp -r .github/actions/set-runtime-image ../cilium-base-branch\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1\n\n      - name: Login to quay.io\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_DEVELOPER_USERNAME }}\n          password: ${{ secrets.QUAY_DEVELOPER_PASSWORD }}\n\n      - name: Getting image tag\n        id: tag\n        run: |\n          ref=${GITHUB_REF##*/}\n          echo ref=${ref} >> $GITHUB_OUTPUT\n          echo tag=${ref} >> $GITHUB_OUTPUT\n\n      - name: Checking if tag already exists\n        id: tag-in-repositories\n        shell: bash\n        run: |\n          if docker buildx imagetools inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-dev:${{ steps.tag.outputs.tag }} &>/dev/null; then\n            echo \"Tag already exists!\"\n            exit 1\n          fi\n\n      - name: Checkout Source Code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Copy runtime image tag from stable branch\n        run: |\n          cp -r .github/actions/set-runtime-image/runtime-image.txt ../cilium-base-branch/set-runtime-image/\n\n      - name: Set runtime image environment variable\n        uses: ./../cilium-base-branch/set-runtime-image\n        with:\n          repository: ${{ env.CILIUM_RUNTIME_IMAGE_PREFIX }}\n\n      - name: Release Build ${{ matrix.name }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_release\n        with:\n          provenance: false\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          platforms: linux/amd64,linux/arm64\n          tags: |\n            quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-dev:${{ steps.tag.outputs.tag }}\n            quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ github.sha }}\n          target: release\n          build-args: |\n            CILIUM_RUNTIME_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n            OPERATOR_VARIANT=${{ matrix.name }}\n\n      - name: Generate SBOM, Sign Images, and Attach Attestations\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-dev@${{ steps.docker_build_release.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-dev:${{ steps.tag.outputs.tag }}\"\n          sbom_name: \"${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n\n      - name: Generate SBOM, Sign Images, and Attach Attestations\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci@${{ steps.docker_build_release.outputs.digest }}\"\n          sbom_name: \"${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n          install_cosign: 'false'\n          generate_sbom: 'false'\n\n      - name: Image Release Digest\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n          echo \"## ${{ matrix.name }}\" > image-digest/${{ matrix.name }}.txt\n          echo \"\" >> image-digest/${{ matrix.name }}.txt\n          echo \"\\`quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-dev:${{ steps.tag.outputs.tag }}@${{ steps.docker_build_release.outputs.digest }}\\`\" >> image-digest/${{ matrix.name }}.txt\n          echo \"\\`quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/${{ matrix.name }}-ci:${{ github.sha }}@${{ steps.docker_build_release.outputs.digest }}\\`\" >> image-digest/${{ matrix.name }}.txt\n          echo \"\" >> image-digest/${{ matrix.name }}.txt\n\n      # Upload artifact digests\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest ${{ matrix.name }}\n          path: image-digest\n          retention-days: 1\n\n  image-digests:\n    name: Display Digests\n    runs-on: ubuntu-24.04\n    needs: build-and-push\n    steps:\n      - name: Downloading Image Digests\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n\n      - name: Download digests of all images built\n        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0\n        with:\n          path: image-digest/\n          pattern: \"*image-digest *\"\n\n      - name: Image Digests Output\n        shell: bash\n        run: |\n          cd image-digest/\n          find -type f | sort | xargs -d '\\n' cat\n\n  push-chart:\n    name: Push dev chart\n    needs: build-and-push\n    permissions:\n      contents: read\n      pull-requests: read\n      statuses: write\n    uses: ./.github/workflows/push-chart-ci.yaml\n    with:\n      checkout_ref: ${{ needs.build-and-push.outputs.ref }}\n      image_tag: ${{ needs.build-and-push.outputs.tag }}\n    secrets: inherit\n"
						}
					},
					{
						"name": "build-images-releases.yaml",
						"object": {
							"text": "name: Image Release Build\n\non:\n  push:\n    tags:\n      - v[0-9]+.[0-9]+.[0-9]+\n      - v[0-9]+.[0-9]+.[0-9]+-*\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n  # Required to generate OIDC tokens for `sigstore/cosign-installer` authentication\n  id-token: write\n\njobs:\n  build-and-push:\n    timeout-minutes: 45\n    name: Build and Push Images\n    environment: release\n    runs-on: ubuntu-24.04\n    strategy:\n      matrix:\n        include:\n          - name: cilium\n            dockerfile: ./images/cilium/Dockerfile\n\n          - name: operator\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-aws\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-azure\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-alibabacloud\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: operator-generic\n            dockerfile: ./images/operator/Dockerfile\n\n          - name: hubble-relay\n            dockerfile: ./images/hubble-relay/Dockerfile\n\n          - name: clustermesh-apiserver\n            dockerfile: ./images/clustermesh-apiserver/Dockerfile\n\n          - name: docker-plugin\n            dockerfile: ./images/cilium-docker-plugin/Dockerfile\n\n    steps:\n      - name: Checkout main branch to access local actions\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Copy runtime image action to base branch directory\n        run: |\n          mkdir -p ../cilium-base-branch\n          cp -r .github/actions/set-runtime-image ../cilium-base-branch\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.11.1\n\n      - name: Login to DockerHub\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        if: ${{ env.PUSH_TO_DOCKER_HUB == 'true' }}\n        with:\n          username: ${{ secrets.DOCKER_HUB_RELEASE_USERNAME }}\n          password: ${{ secrets.DOCKER_HUB_RELEASE_PASSWORD }}\n\n      - name: Login to quay.io\n        uses: docker/login-action@184bdaa0721073962dff0199f1fb9940f07167d1 # v3.5.0\n        with:\n          registry: quay.io\n          username: ${{ secrets.QUAY_USERNAME_RELEASE_USERNAME }}\n          password: ${{ secrets.QUAY_PASSWORD_RELEASE_PASSWORD }}\n\n      - name: Getting image tag\n        id: tag\n        run: |\n          tag=${GITHUB_REF##*/}\n          echo tag=$tag >> $GITHUB_OUTPUT\n          if [ \"${{ env.PUSH_TO_DOCKER_HUB }}\" == \"true\" ]; then\n            echo image_tags=${{ github.repository_owner }}/${{ matrix.name }}:$tag,quay.io/${{ env.QUAY_ORGANIZATION }}/${{ matrix.name }}:$tag >> $GITHUB_OUTPUT\n          else\n            echo image_tags=quay.io/${{ env.QUAY_ORGANIZATION }}/${{ matrix.name }}:$tag >> $GITHUB_OUTPUT\n          fi\n\n      - name: Checkout Source Code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Copy runtime image tag from stable branch\n        run: |\n          cp -r .github/actions/set-runtime-image/runtime-image.txt ../cilium-base-branch/set-runtime-image/\n\n      - name: Set runtime image environment variable\n        uses: ./../cilium-base-branch/set-runtime-image\n        with:\n          repository: ${{ env.CILIUM_RUNTIME_IMAGE_PREFIX }}\n\n      - name: Release Build ${{ matrix.name }}\n        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6.18.0\n        id: docker_build_release\n        with:\n          provenance: false\n          context: .\n          file: ${{ matrix.dockerfile }}\n          push: true\n          platforms: linux/amd64,linux/arm64\n          tags: ${{ steps.tag.outputs.image_tags }}\n          target: release\n          build-args: |\n            CILIUM_RUNTIME_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n            OPERATOR_VARIANT=${{ matrix.name }}\n\n      - name: Generate SBOM, Sign Images, and Attach Attestations\n        uses: ./.github/actions/cosign\n        with:\n          image: \"quay.io/${{ env.QUAY_ORGANIZATION }}/${{ matrix.name }}@${{ steps.docker_build_release.outputs.digest }}\"\n          image_tag: \"quay.io/${{ env.QUAY_ORGANIZATION }}/${{ matrix.name }}:${{ steps.tag.outputs.tag }}\"\n          sbom_name: \"${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n          upload_sbom_release_assets: 'false'\n\n      - name: Generate SBOM, Sign Images, and Attach Attestations\n        if: ${{ env.PUSH_TO_DOCKER_HUB == 'true' }}\n        uses: ./.github/actions/cosign\n        with:\n          image: \"docker.io/${{ github.repository_owner }}/${{ matrix.name }}@${{ steps.docker_build_release.outputs.digest }}\"\n          sbom_name: \"${{ matrix.name }}_${{ steps.tag.outputs.tag }}\"\n          generate_sbom: 'false'\n          install_cosign: 'false'\n          upload_sbom_release_assets: 'false'\n\n      - name: Image Release Digest\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n          job_name=${{ matrix.name }}\n          job_name_capital=${job_name^^}\n          job_name_underscored=${job_name_capital//-/_}\n          echo \"${job_name_underscored}_DIGEST := \\\"${{ steps.docker_build_release.outputs.digest }}\\\"\" > image-digest/makefile-digest.txt\n\n          echo \"### ${{ matrix.name }}\" > image-digest/${{ matrix.name }}.txt\n          echo \"\" >> image-digest/${{ matrix.name }}.txt\n          if [ \"${{ env.PUSH_TO_DOCKERHUB }}\" == \"true\" ]; then\n            echo \"\\`docker.io/${{ github.repository_owner }}/${{ matrix.name }}:${{ steps.tag.outputs.tag }}@${{ steps.docker_build_release.outputs.digest }}\\`\" >> image-digest/${{ matrix.name }}.txt\n          fi\n          echo \"\\`quay.io/${{ env.QUAY_ORGANIZATION }}/${{ matrix.name }}:${{ steps.tag.outputs.tag }}@${{ steps.docker_build_release.outputs.digest }}\\`\" >> image-digest/${{ matrix.name }}.txt\n          echo \"\" >> image-digest/${{ matrix.name }}.txt\n\n      # Upload artifact digests\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest ${{ matrix.name }}\n          path: image-digest\n\n  image-digests:\n    name: Display Digests\n    runs-on: ubuntu-24.04\n    needs: build-and-push\n    steps:\n      - name: Getting image tag\n        id: tag\n        run: |\n          echo tag=${GITHUB_REF##*/} >> $GITHUB_OUTPUT\n      - name: Downloading Image Digests\n        shell: bash\n        run: |\n          mkdir -p image-digest/\n\n      - name: Download digests of all images built\n        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0\n        with:\n          path: image-digest/\n          pattern: \"*image-digest *\"\n\n      - name: Image Digests Output\n        shell: bash\n        run: |\n          cd image-digest/\n          echo \"## Docker Manifests\" > ../image-digest-output.txt\n          echo \"\" >> ../image-digest-output.txt\n          find -type f -regex \".*image-digest .*\" -not -name \"makefile-digest.txt\" | sort | xargs -d '\\n' cat >> ../image-digest-output.txt\n\n      - name: Image Makefile Digests\n        shell: bash\n        run: |\n          cd image-digest/\n          echo \"# File generated by .github/workflows/build-images-releases.yaml; DO NOT EDIT.\" > ../Makefile.digests\n          echo \"# Copyright $(date +'%Y') Authors of Cilium\" >> ../Makefile.digests\n          echo \"# SPDX-License-Identifier: Apache-2.0\" >> ../Makefile.digests\n          echo \"\" >> ../Makefile.digests\n          # shellcheck disable=SC2016\n          find -type f  -name \"makefile-digest.txt\" | sort | xargs -d '\\n' awk '{print \"export \" $0}' >> ../Makefile.digests\n\n      # Upload artifact digests\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: image-digest-output.txt-${{ steps.tag.outputs.tag }}\n          path: image-digest-output.txt\n\n      # Upload artifact digests\n      - name: Upload artifact digests\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: Makefile.digests-${{ steps.tag.outputs.tag }}\n          path: Makefile.digests\n\n  call-post-release:\n    name: Call Post-Release Tool\n    uses: cilium/cilium/.github/workflows/release.yaml@main\n    needs: image-digests\n    with:\n      step: \"4-post-release\"\n      version: ${{ github.ref_name }}\n\n  call-publish-helm:\n    name: Publish Helm Chart\n    uses: cilium/cilium/.github/workflows/release.yaml@main\n    needs: image-digests\n    with:\n      step: \"5-publish-helm\"\n      version: ${{ github.ref_name }}\n"
						}
					},
					{
						"name": "call-backport-label-updater.yaml",
						"object": {
							"text": "---\n  name: Call Backport Label Updater\n  on:\n    pull_request_target:\n      types:\n        - closed\n      branches:\n        - v[0-9]+.[0-9]+*\n\n  jobs:\n    call-backport-label-updater:\n      name: Update backport labels for upstream PR\n      if: |\n        github.event.pull_request.merged == true &&\n        contains(github.event.pull_request.body, 'upstream-prs') &&\n        contains(join(github.event.pull_request.labels.*.name, ', '), 'backport/')\n      uses: cilium/cilium/.github/workflows/update-label-backport-pr.yaml@main\n      with:\n        pr-body: ${{ github.event.pull_request.body }}\n        branch: ${{ github.base_ref }}\n      secrets: inherit\n"
						}
					},
					{
						"name": "ci-images-cache-cleaner.yaml",
						"object": {
							"text": "name: Image CI Cache Cleaner\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n  schedule:\n    # Run the GC every Monday at 6am\n    - cron: \"0 6 * * 1\"\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\njobs:\n  cache-cleaner:\n    name: Clean Image Cache\n    runs-on: ubuntu-24.04\n    permissions:\n      # `actions:write` permission is required to delete caches\n      #   See also: https://docs.github.com/en/rest/actions/cache?apiVersion=2022-11-28#delete-a-github-actions-cache-for-a-repository-using-a-cache-id\n      actions: write\n      contents: read\n    steps:\n      - name: Clean cache from GitHub\n        shell: bash\n        run: |\n          gh extension install actions/gh-actions-cache\n\n          REPO=${{ github.repository }}\n          set +e\n          for cache in $(gh actions-cache list -R $REPO --key ${{ runner.os }}-go- -B ${{ github.event.repository.default_branch }} -L 100 | awk '{ print $1 }'); do\n            gh actions-cache delete ${cache} -R $REPO -B ${{ github.event.repository.default_branch }} --confirm || true\n          done\n          for cache in $(gh actions-cache list -R $REPO --key ${{ runner.os }}-ccache- -B ${{ github.event.repository.default_branch }} -L 100 | awk '{ print $1 }'); do\n            gh actions-cache delete ${cache} -R $REPO -B ${{ github.event.repository.default_branch }} --confirm || true\n          done\n        env:\n          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n"
						}
					},
					{
						"name": "ci-images-garbage-collect.yaml",
						"object": {
							"text": "name: Scruffy\non:\n  workflow_dispatch:\n  schedule:\n    # Run the GC every Monday at 9am\n    - cron: \"0 9 * * 1\"\n\npermissions: read-all\n\njobs:\n  scruffy:\n    if: github.repository_owner == 'cilium'\n    name: scruffy\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          fetch-depth: 0\n      - name: Garbage Collect Images\n        uses: docker://quay.io/cilium/scruffy:v0.0.3@sha256:ca997451b739cbf03c204cb2523a671c31c61edc606aa5d20dc3560bc7f25bc7\n        with:\n          entrypoint: scruffy\n          args: --git-repository=./ --stable-branches=origin/main,origin/v1.12,origin/v1.13,origin/v1.14,origin/v1.15,origin/v1.16,origin/v1.17,origin/v1.18\n        env:\n          QUAY_TOKEN: ${{ secrets.SCRUFFY_QUAY_TOKEN }}\n"
						}
					},
					{
						"name": "cilium-cli.yaml",
						"object": {
							"text": "name: Cilium CLI tests\n\non:\n  pull_request:\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}\n  cancel-in-progress: true\n\njobs:\n  build-cilium-cli-binaries:\n    name: Build Cilium CLI binaries\n    runs-on: ubuntu-24.04\n    permissions:\n      contents: read\n    steps:\n      - name: Checkout the repository\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n\n      - name: Setup go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      # Load Golang cache build from GitHub\n      - name: Load Golang cache build from GitHub\n        uses: actions/cache/restore@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-cilium-cli-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-cilium-cli-cache-\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/go/.cache/go-build\n          mkdir -p /tmp/.cache/go/pkg\n\n      - name: Build Cilium CLI release binaries\n        env:\n          GOCACHE: \"/tmp/.cache/go/.cache/go-build\"\n          GOMODCACHE: \"/tmp/.cache/go/pkg\"\n        run: |\n          make -C cilium-cli local-release\n"
						}
					},
					{
						"name": "close-stale-issues.yaml",
						"object": {
							"text": "name: Close stale issues\n\non:\n  schedule:\n  - cron: \"30 1 * * *\"\n\npermissions:\n  issues: write\n  pull-requests: write\n\njobs:\n  stale:\n    name: Close Stale Issues\n    runs-on: ubuntu-24.04\n    steps:\n    # https://github.com/marketplace/actions/close-stale-issues\n    - name: Close stale issues\n      uses: actions/stale@3a9db7e6a41a89f618792c92c0e97cc736e1b13f # v10.0.0\n      with:\n        operations-per-run: 1000\n        stale-issue-label: stale\n        exempt-all-issue-assignees: true\n        exempt-issue-labels: pinned,security,good-first-issue,help-wanted\n\n        days-before-issue-stale: 60\n        stale-issue-message: |\n          This issue has been automatically marked as stale because it has not\n          had recent activity. It will be closed if no further activity occurs.\n        days-before-issue-close: 14\n        close-issue-message: |\n          This issue has not seen any activity since it was marked stale.\n          Closing.\n\n        stale-pr-label: stale\n        exempt-pr-labels: pinned,security,good-first-issue,help-wanted\n\n        days-before-pr-stale: 30\n        stale-pr-message: |\n          This pull request has been automatically marked as stale because it\n          has not had recent activity. It will be closed if no further activity\n          occurs. Thank you for your contributions.\n        days-before-pr-close: 14\n        close-pr-message: |\n          This pull request has not seen any activity since it was marked stale.\n          Closing.\n"
						}
					},
					{
						"name": "common-post-jobs.yaml",
						"object": {
							"text": "name: Common Post Jobs\n\non:\n  workflow_call:\n    inputs:\n      context-ref:\n        required: true\n        type: string\n      sha:\n        required: true\n        type: string\n      result:\n        required: true\n        type: string\n\njobs:\n  merge-upload:\n    if: ${{ always() && inputs.result != 'skipped' }}\n    name: Merge and Upload Artifacts\n    runs-on: ubuntu-24.04\n    permissions:\n      contents: read\n      actions: read\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref }}\n          persist-credentials: false\n\n      - name: Merge JUnits\n        uses: ./.github/actions/merge-artifacts\n        with:\n          name: cilium-junits\n          pattern: cilium-junits-*\n          token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Merge Features tested\n        uses: ./.github/actions/merge-artifacts\n        with:\n          name: features-tested\n          pattern: features-tested-*\n          token: ${{ secrets.GITHUB_TOKEN }}\n          separate-directories: true\n\n  commit-status-final:\n    if: ${{ always() }}\n    name: Commit Status Final\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set final commit status\n        if: ${{ inputs.result != 'skipped' }}\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.sha }}\n          status: ${{ inputs.result == 'abandoned' && 'failure' || inputs.result }}\n\n      - name: Set final commit status\n        if: ${{ inputs.result == 'skipped' }}\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.sha }}\n          status: ${{ github.event_name != 'schedule' && 'success' || 'failure' }}\n          description: 'Skipped'\n"
						}
					},
					{
						"name": "conformance-aks.yaml",
						"object": {
							"text": "name: Conformance AKS (ci-aks)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 0/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n  # Required to generate OIDC tokens for `az` authentication\n  id-token: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  name: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-${{ github.run_attempt }}\n  cost_reduction: --node-vm-size Standard_B2s --node-osdisk-size 30\n  test_concurrency: 5\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      empty: ${{ steps.set-matrix.outputs.empty }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/azure\"\n          destination_directory=\"/tmp/generated/azure\"\n          mkdir -p \"${destination_directory}\"\n\n          yq -o=json \"${work_dir}/k8s-versions.yaml\" | jq . > \"${destination_directory}/azure.json\"\n\n      - name: Generate Matrix\n        run: |\n          cd /tmp/generated/azure\n\n          # Use complete matrix in case of scheduled run\n          # main -> event_name = schedule\n          # other stable branches -> PR-number starting with v (e.g. v1.14)\n          # shellcheck disable=SC2193\n          if [[ \"${{ github.event_name }}\" == \"schedule\" || \"${{ inputs.PR-number }}\" == v* ]];then\n            jq '{ \"include\": [ .include[] | select(.disabled==null) ] }' azure.json > /tmp/matrix.json\n          else\n            jq '{ \"include\": [ .include[] | select(.default) ] }' azure.json > /tmp/matrix.json\n          fi\n\n          echo \"Generated matrix:\"\n          cat /tmp/matrix.json\n\n      - name: Login to Azure\n        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2.3.0\n        with:\n          creds: ${{ secrets.AZURE_PR_SP_CREDS }}\n\n      - name: Filter Matrix\n        id: set-matrix\n        run: |\n          cp /tmp/matrix.json /tmp/result.json\n          jq -c '.include[]' /tmp/matrix.json | while read i; do\n            VERSION=$(echo $i | jq -r '.version')\n            LOCATION=$(echo $i | jq -r '.location')\n            # Don't use LTS versions for AKS, it requires premium tier\n            az aks get-versions --location $LOCATION --query \"values[?contains(capabilities.supportPlan,'KubernetesOfficial')].version\" > /tmp/output\n            if grep -q -F $VERSION /tmp/output; then\n              echo \"Version $VERSION is valid for location $LOCATION\"\n            else\n              echo \"::notice::Removing version $VERSION as it's not valid for location $LOCATION\"\n              jq 'del(.include[] | select(.version == \"'$VERSION'\"))' /tmp/result.json > /tmp/result.json.tmp\n              mv /tmp/result.json.tmp /tmp/result.json\n            fi\n          done\n          echo \"Filtered matrix:\"\n          cat /tmp/result.json\n          echo \"matrix=$(jq -c . < /tmp/result.json)\" >> $GITHUB_OUTPUT\n          echo \"empty=$(jq '(.include | length) == 0' /tmp/result.json)\" >> $GITHUB_OUTPUT\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-azure-ci hubble-relay-ci cilium-cli-ci\n\n  installation-and-connectivity:\n    name: Installation and Connectivity Test\n    needs: [generate-matrix, wait-for-images]\n    if: ${{ needs.generate-matrix.outputs.empty == 'false' }}\n    runs-on: ubuntu-24.04\n    timeout-minutes: 90\n    env:\n      job_name: \"Installation and Connectivity Test\"\n    strategy:\n      fail-fast: false\n      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Override cluster name\n        run: |\n          # Extend default name with matrix index to avoid cluster name conflicts\n          NAME=${{ env.name }}-${{ matrix.index }}\n          echo \"name=${NAME}\" >> \"$GITHUB_ENV\"\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            OWNER=\"${{ inputs.PR-number }}\"\n          else\n            OWNER=\"${{ github.ref_name }}\"\n            OWNER=\"${OWNER//[.\\/]/-}\"\n          fi\n\n          # We explicity set the cluster-pool Pod CIDR here to not clash with the AKS default Service CIDRs\n          # which are 10.0.0.0/16 and fd12:3456:789a:1::/108\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --datapath-mode=aks-byocni \\\n            --helm-set cluster.name=${{ env.name }} \\\n            --helm-set loadBalancer.l7.backend=envoy \\\n            --helm-set=azure.resourceGroup=${{ env.name }} \\\n            --helm-set kubeProxyReplacement=true \\\n            --helm-set=bpf.masquerade=true \\\n            --helm-set=ipv4.enabled=true \\\n            --helm-set=ipv6.enabled=true \\\n            --helm-set ipam.operator.clusterPoolIPv4PodCIDRList=192.168.0.0/16 \\\n            --helm-set ipam.operator.clusterPoolIPv6PodCIDRList=fd00::/104\"\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n      - name: Login to Azure\n        uses: azure/login@a457da9ea143d694b1b9c7c869ebb04ebe844ef5 # v2.3.0\n        with:\n          creds: ${{ secrets.AZURE_PR_SP_CREDS }}\n\n      - name: Create AKS cluster\n        uses: ./.github/actions/setup-aks-cluster\n        with:\n          cluster_name: ${{ env.name }}\n          location: ${{ matrix.location }}\n          version: ${{ matrix.version }}\n          tags: \"usage=${{ github.repository_owner }}-${{ github.event.repository.name }} owner=${{ steps.vars.outputs.owner }}\"\n          taints: ${{ env.cost_reduction }}\n\n      - name: Get cluster credentials\n        run: |\n          az aks get-credentials \\\n            --resource-group ${{ env.name }} \\\n            --name ${{ env.name }}\n\n      - name: Generate cilium-cli kubeconfig\n        id: gen-kubeconfig\n        uses: ./.github/actions/get-cloud-kubeconfig\n        with:\n          kubeconfig: \"~/.kube/config\"\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n          kubeconfig: ${{ steps.gen-kubeconfig.outputs.kubeconfig_path }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Enable Relay\n        run: |\n          cilium hubble enable\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run sequential connectivity test (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n          --test \"seq-.*\" \\\n          --junit-file \"cilium-junits/${{ env.job_name }}-sequential-clear (${{ join(matrix.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test (${{ join(matrix.*, ', ') }})\"\n\n      - name: Run concurrent connectivity test (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n          --test-concurrency=${{ env.test_concurrency }} \\\n          --test \"!seq-.*\" \\\n          --junit-file \"cilium-junits/${{ env.job_name }}-concurrent-clear (${{ join(matrix.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test (${{ join(matrix.*, ', ') }})\"\n\n      - name: Features tested\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - 1\"\n\n      - name: Clean up Cilium\n        run: |\n          cilium uninstall --wait\n\n      - name: Create custom IPsec secret\n        run: |\n          cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n\n      - name: Install Cilium with encryption\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            --helm-set encryption.enabled=true \\\n            --helm-set encryption.type=ipsec\n\n      - name: Enable Relay\n        run: |\n          cilium hubble enable\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n\n      - name: Run sequential connectivity test with IPSec (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} --force-deploy \\\n          --test \"seq-.*\" \\\n          --junit-file \"cilium-junits/${{ env.job_name }}-sequential-ipsec (${{ join(matrix.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test with IPSec (${{ join(matrix.*, ', ') }})\"\n\n      - name: Run concurrent connectivity test with IPSec (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} --force-deploy \\\n          --test-concurrency=${{ env.test_concurrency }} \\\n          --test \"!seq-.*\" \\\n          --junit-file \"cilium-junits/${{ env.job_name }}-concurrent-ipsec (${{ join(matrix.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test with IPSec (${{ join(matrix.*, ', ') }})\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - 2\"\n          job_status: \"${{ job.status }}\"\n\n      - name: Clean up AKS\n        if: ${{ always() }}\n        run: |\n          az group delete --name ${{ env.name }} --yes --no-wait\n        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-connectivity\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.installation-and-connectivity.result }}\n"
						}
					},
					{
						"name": "conformance-aws-cni.yaml",
						"object": {
							"text": "name: Conformance AWS-CNI (ci-awscni)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '30 0/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  clusterName: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-${{ github.run_attempt }}\n  # renovate: datasource=github-releases depName=eksctl-io/eksctl\n  eksctl_version: v0.214.0\n  # renovate: datasource=github-releases depName=kubernetes/kubernetes\n  kubectl_version: v1.34.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      empty: ${{ steps.set-matrix.outputs.empty }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/aws-cni\"\n          destination_directory=\"/tmp/generated/aws-cni\"\n          mkdir -p \"${destination_directory}\"\n\n          yq -o=json \"${work_dir}/k8s-versions.yaml\" | jq . > \"${destination_directory}/aws-cni.json\"\n\n      - name: Generate Matrix\n        run: |\n          cd /tmp/generated/aws-cni\n\n          # Use complete matrix in case of scheduled run\n          # main -> event_name = schedule\n          # other stable branches -> PR-number starting with v (e.g. v1.14)\n          # shellcheck disable=SC2193\n          if [[ \"${{ github.event_name }}\" == \"schedule\" || \"${{ inputs.PR-number }}\" == v* ]];then\n            cp aws-cni.json /tmp/matrix.json\n          else\n            jq '{ \"include\": [ .include[] | select(.default) ] }' aws-cni.json > /tmp/matrix.json\n          fi\n\n          echo \"Generated matrix:\"\n          cat /tmp/matrix.json\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: us-west-1\n\n      - name: Filter Matrix\n        id: set-matrix\n        run: |\n          cp /tmp/matrix.json /tmp/result.json\n          jq -c '.include[]' /tmp/matrix.json | while read i; do\n            VERSION=$(echo $i | jq -r '.version')\n            aws eks describe-cluster-versions | jq -r '.clusterVersions[].clusterVersion' > /tmp/output\n            if grep -q -F $VERSION /tmp/output; then\n              echo \"Version $VERSION is supported\"\n            else\n              echo \"::notice::Removing version $VERSION as it's not supported\"\n              jq 'del(.include[] | select(.version == \"'$VERSION'\"))' /tmp/result.json > /tmp/result.json.tmp\n              mv /tmp/result.json.tmp /tmp/result.json\n            fi\n          done\n          echo \"Filtered matrix:\"\n          cat /tmp/result.json\n          echo \"matrix=$(jq -c . < /tmp/result.json)\" >> $GITHUB_OUTPUT\n          echo \"empty=$(jq '(.include | length) == 0' /tmp/result.json)\" >> $GITHUB_OUTPUT\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  installation-and-connectivity:\n    name: Installation and Connectivity Test\n    needs: [generate-matrix, wait-for-images]\n    if: ${{ needs.generate-matrix.outputs.empty == 'false' }}\n    runs-on: ubuntu-24.04\n    timeout-minutes: 45\n    env:\n      job_name: \"Installation and Connectivity Test\"\n    strategy:\n      fail-fast: false\n      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          external-target: 'amazon.com.'\n          hubble: false\n          test-concurrency: 3\n          tests: '!fqdn,!l7' # L7 policies are not supported in chaining mode.\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            OWNER=\"${{ inputs.PR-number }}\"\n          else\n            OWNER=\"${{ github.ref_name }}\"\n            OWNER=\"${OWNER//[.\\/]/-}\"\n          fi\n\n          # Set ipam.mode=cluster-pool to overwrite the ipam value set by the\n          # cilium-cli which is setting it to 'eni' because it auto-detects\n          # the cluster as being EKS.\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cluster.name=${{ env.clusterName }} \\\n            --helm-set=hubble.relay.enabled=true \\\n            --helm-set=enableIPv4Masquerade=false \\\n            --helm-set=cni.chainingMode=aws-cni \\\n            --helm-set=eni.enabled=false \\\n            --helm-set=ipam.mode=cluster-pool \\\n            --helm-set=routingMode=native \\\n            --helm-set=bandwidthManager.enabled=false \\\n            --helm-set=extraArgs={--enable-identity-mark=false} \\\n            --wait=false\"\n\n          if [ \"${{ matrix.wireguard }}\" == \"true\" ]; then\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set=encryption.enabled=true \\\n                                      --helm-set=encryption.type=wireguard \\\n                                      --helm-set=cni.enableRouteMTUForCNIChaining=true\"\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n\n          # shellcheck disable=SC2046\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          # shellcheck disable=SC2046\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n          # shellcheck disable=SC2046\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n      - name: Install kubectl\n        run: |\n          curl -sLO \"https://dl.k8s.io/release/${{ env.kubectl_version }}/bin/linux/amd64/kubectl\"\n          curl -sLO \"https://dl.k8s.io/${{ env.kubectl_version }}/bin/linux/amd64/kubectl.sha256\"\n          echo \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check\n          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n          kubectl version --client\n\n      - name: Install eksctl CLI\n        run: |\n          curl -LO \"https://github.com/eksctl-io/eksctl/releases/download/${{ env.eksctl_version }}/eksctl_$(uname -s)_amd64.tar.gz\"\n          sudo tar -xzvf \"eksctl_$(uname -s)_amd64.tar.gz\" -C /usr/bin\n          rm \"eksctl_$(uname -s)_amd64.tar.gz\"\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: ${{ matrix.region }}\n\n      - name: Create EKS cluster\n        uses: ./.github/actions/setup-eks-cluster\n        with:\n          cluster_name: ${{ env.clusterName }}\n          region: ${{ matrix.region }}\n          owner: \"${{ steps.vars.outputs.owner }}\"\n          version: ${{ matrix.version }}\n          addons: \"coredns kube-proxy vpc-cni\"\n\n      - name: Create EKS nodegroups\n        uses: ./.github/actions/setup-eks-nodegroup\n        with:\n          cluster_name: ${{ env.clusterName }}\n          region: ${{ matrix.region }}\n          owner: \"${{ steps.vars.outputs.owner }}\"\n          version: ${{ matrix.version }}\n          spot: false\n\n      - name: Generate cilium-cli kubeconfig\n        id: gen-kubeconfig\n        uses: ./.github/actions/get-cloud-kubeconfig\n        with:\n          kubeconfig: \"~/.kube/config\"\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n          kubeconfig: ${{ steps.gen-kubeconfig.outputs.kubeconfig_path }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods -n kube-system\n\n      - name: Check that AWS iptables chains have not been removed\n        run: |\n          for pod in $(kubectl get po -n kube-system -l app.kubernetes.io/name=cilium-agent -o name); do\n            echo \"Checking ${pod}\"\n            if ! kubectl exec -n kube-system  ${pod} -c cilium-agent -- iptables-save | grep --silent ':AWS'; then\n              echo \"Expected AWS iptables chains are not present\"\n              exit 1\n            fi\n          done\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n          --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test (${{ join(matrix.*, ', ') }})\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }})\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-connectivity\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.installation-and-connectivity.result }}\n\n  cleanup:\n    name: Cleanup EKS Clusters\n    if: ${{ always() && needs.generate-matrix.outputs.empty == 'false' }}\n    continue-on-error: true\n    needs: [generate-matrix, installation-and-connectivity]\n    runs-on: ubuntu-24.04\n    timeout-minutes: 45\n    strategy:\n      fail-fast: false\n      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}\n\n    steps:\n      - name: Install eksctl CLI\n        run: |\n          curl -LO \"https://github.com/eksctl-io/eksctl/releases/download/${{ env.eksctl_version }}/eksctl_$(uname -s)_amd64.tar.gz\"\n          sudo tar -xzvf \"eksctl_$(uname -s)_amd64.tar.gz\" -C /usr/bin\n          rm \"eksctl_$(uname -s)_amd64.tar.gz\"\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: ${{ matrix.region }}\n\n      - name: Clean up EKS\n        run: |\n          eksctl delete cluster --name ${{ env.clusterName }} --region ${{ matrix.region }}\n"
						}
					},
					{
						"name": "conformance-clustermesh.yaml",
						"object": {
							"text": "name: Conformance Cluster Mesh (ci-clustermesh)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - push: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  clusterName1: cluster1-${{ github.run_id }}\n  clusterName2: cluster2-${{ github.run_id }}\n  ciliumClusterName1: c1\n  ciliumClusterName2: cluster2-with-long-name-01234567\n  contextName1: kind-cluster1-${{ github.run_id }}\n  contextName2: kind-cluster2-${{ github.run_id }}\n\n  # renovate: datasource=github-releases depName=cert-manager/cert-manager\n  CERT_MANAGER_VERSION: v1.18.2\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ${{ vars.UBUNTU_2404_2CPU_1GB || 'ubuntu-24.04' }}\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ${{ vars.UBUNTU_2404_2CPU_1GB || 'ubuntu-24.04' }}\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ${{ vars.UBUNTU_2404_2CPU_1GB || 'ubuntu-24.04' }}\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci hubble-relay-ci clustermesh-apiserver-ci cilium-cli-ci\n\n  installation-and-connectivity:\n    needs: [wait-for-images]\n    name: Installation and Connectivity Test\n    runs-on: ${{ vars.UBUNTU_2404_4CPU_16GB || 'ubuntu-24.04' }}\n    timeout-minutes: 60\n    env:\n      job_name: \"Installation and Connectivity Test\"\n\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - name: '1'\n            tunnel: 'disabled'\n            ipFamily: 'ipv4'\n            encryption: 'disabled'\n            kube-proxy: 'none'\n            mode: 'kvstoremesh'\n            tls-auto-method: helm\n            cm-auth-mode-1: 'legacy'\n            cm-auth-mode-2: 'legacy'\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'enabled'\n            policy-default-local-cluster: true\n            multipool-ipam: 'enabled'\n\n          - name: '2'\n            tunnel: 'disabled'\n            ipFamily: 'dual'\n            encryption: 'wireguard'\n            kube-proxy: 'none'\n            mode: 'clustermesh'\n            tls-auto-method: cronJob\n            cm-auth-mode-1: 'migration'\n            cm-auth-mode-2: 'migration'\n            maxConnectedClusters: '511'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: false\n            multipool-ipam: 'disabled'\n\n          - name: '3'\n            tunnel: 'disabled'\n            ipFamily: 'dual'\n            encryption: 'ipsec'\n            kube-proxy: 'none'\n            mode: 'kvstoremesh'\n            tls-auto-method: certmanager\n            cm-auth-mode-1: 'cluster'\n            cm-auth-mode-2: 'cluster'\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: true\n            multipool-ipam: 'disabled'\n\n          # IPsec encryption is currently not supported in case of ipv6-only clusters (#23553)\n          # Wireguard encryption is currently affected by a bug in case of ipv6-only clusters (#23917)\n          - name: '4'\n            tunnel: 'disabled'\n            ipFamily: 'ipv6'\n            encryption: 'disabled'\n            kube-proxy: 'none'\n            mode: 'clustermesh'\n            tls-auto-method: certmanager\n            cm-auth-mode-1: 'legacy'\n            cm-auth-mode-2: 'migration'\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: false\n            multipool-ipam: 'disabled'\n\n          - name: '5'\n            tunnel: 'disabled'\n            ipFamily: 'dual'\n            encryption: 'ipsec'\n            kube-proxy: 'iptables'\n            mode: 'external'\n            tls-auto-method: helm\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: true\n            multipool-ipam: 'disabled'\n\n          - name: '6'\n            tunnel: 'vxlan'\n            ipFamily: 'ipv4'\n            encryption: 'disabled'\n            kube-proxy: 'none'\n            mode: 'kvstoremesh'\n            tls-auto-method: helm\n            cm-auth-mode-1: 'cluster'\n            cm-auth-mode-2: 'cluster'\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'enabled'\n            policy-default-local-cluster: false\n            multipool-ipam: 'enabled'\n\n          - name: '7'\n            tunnel: 'geneve'\n            ipFamily: 'dual'\n            encryption: 'wireguard'\n            kube-proxy: 'iptables'\n            mode: 'kvstoremesh'\n            tls-auto-method: cronJob\n            cm-auth-mode-1: 'migration'\n            cm-auth-mode-2: 'cluster'\n            maxConnectedClusters: '511'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: true\n            multipool-ipam: 'disabled'\n\n          - name: '8'\n            tunnel: 'vxlan'\n            ipFamily: 'dual'\n            encryption: 'ipsec'\n            kube-proxy: 'iptables'\n            mode: 'clustermesh'\n            tls-auto-method: certmanager\n            cm-auth-mode-1: 'cluster'\n            cm-auth-mode-2: 'cluster'\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: false\n            multipool-ipam: 'disabled'\n\n          - name: '9'\n            tunnel: 'vxlan'\n            ipFamily: 'ipv6'\n            encryption: 'disabled'\n            kube-proxy: 'none'\n            mode: 'kvstoremesh'\n            tls-auto-method: certmanager\n            cm-auth-mode-1: 'cluster'\n            cm-auth-mode-2: 'cluster'\n            maxConnectedClusters: '255'\n            ciliumEndpointSlice: 'enabled'\n            policy-default-local-cluster: true\n            multipool-ipam: 'disabled'\n\n          - name: '10'\n            tunnel: 'vxlan'\n            ipFamily: 'dual'\n            encryption: 'wireguard'\n            kube-proxy: 'iptables'\n            mode: 'external'\n            tls-auto-method: helm\n            maxConnectedClusters: '511'\n            ciliumEndpointSlice: 'disabled'\n            policy-default-local-cluster: true\n            multipool-ipam: 'disabled'\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n          include-unsafe-tests: true\n          test-concurrency: 5\n\n      - name: Set up job variables for GHA environment\n        id: vars\n        run: |\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=kubeProxyReplacement=${{ matrix.kube-proxy == 'none' }} \\\n            --helm-set=bpf.masquerade=${{ matrix.kube-proxy == 'none' }} \\\n            --helm-set=hubble.enabled=true \\\n            --helm-set=hubble.relay.enabled=true \\\n            --helm-set=hubble.tls.auto.method=${{ matrix.tls-auto-method }} \\\n            --helm-set=hubble.tls.auto.certManagerIssuerRef.group=cert-manager.io \\\n            --helm-set=hubble.tls.auto.certManagerIssuerRef.kind=Issuer \\\n            --helm-set=hubble.tls.auto.certManagerIssuerRef.name=cilium \\\n            --helm-set=clustermesh.useAPIServer=${{ matrix.mode != 'external' }} \\\n            --helm-set=clustermesh.apiserver.kvstoremesh.enabled=${{ matrix.mode == 'kvstoremesh' }} \\\n            --helm-set=clustermesh.maxConnectedClusters=${{ matrix.maxConnectedClusters }} \\\n            --helm-set=clustermesh.enableEndpointSliceSynchronization=true \\\n            --helm-set=clustermesh.apiserver.tls.auto.method=${{ matrix.tls-auto-method }} \\\n            --helm-set=clustermesh.apiserver.tls.auto.certManagerIssuerRef.group=cert-manager.io \\\n            --helm-set=clustermesh.apiserver.tls.auto.certManagerIssuerRef.kind=Issuer \\\n            --helm-set=clustermesh.apiserver.tls.auto.certManagerIssuerRef.name=cilium \\\n            --helm-set=clustermesh.policyDefaultLocalCluster=${{ matrix.policy-default-local-cluster }} \\\n            --helm-set=ciliumEndpointSlice.enabled=${{ matrix.ciliumEndpointSlice == 'enabled'}} \\\n            --helm-set=extraConfig.clustermesh-sync-timeout=5m \\\n            --helm-set=extraConfig.lb-init-wait-timeout=4m \\\n            \"\n\n          CILIUM_INSTALL_TUNNEL=\" \\\n            --helm-set=tunnelProtocol=${{ matrix.tunnel }} \\\n            --helm-set=underlayProtocol=${{ matrix.ipFamily == 'ipv6' && 'ipv6' || 'ipv4' }} \\\n          \"\n          if [ \"${{ matrix.tunnel }}\" == \"disabled\" ]; then\n            CILIUM_INSTALL_TUNNEL=\"--helm-set-string=routingMode=native \\\n              --helm-set=autoDirectNodeRoutes=true \\\n              --helm-set=ipv4NativeRoutingCIDR=10.240.0.0/12 \\\n              --helm-set=ipv6NativeRoutingCIDR=fd00:10:240::/44\"\n          fi\n\n          case \"${{ matrix.ipFamily }}\" in\n            ipv4)\n              CILIUM_INSTALL_IPFAMILY=\"--helm-set=ipv4.enabled=true --helm-set=ipv6.enabled=false\"\n              KIND_POD_CIDR_1=\"10.242.0.0/16\"\n              KIND_SVC_CIDR_1=\"10.243.0.0/16\"\n              KIND_POD_CIDR_2=\"10.244.0.0/16\"\n              KIND_SVC_CIDR_2=\"10.245.0.0/16\"\n              ;;\n            ipv6)\n              CILIUM_INSTALL_IPFAMILY=\"--helm-set=ipv4.enabled=false --helm-set=ipv6.enabled=true\"\n              KIND_POD_CIDR_1=\"fd00:10:242::/48\"\n              KIND_SVC_CIDR_1=\"fd00:10:243::/112\"\n              KIND_POD_CIDR_2=\"fd00:10:244::/48\"\n              KIND_SVC_CIDR_2=\"fd00:10:245::/112\"\n              ;;\n            dual)\n              CILIUM_INSTALL_IPFAMILY=\"--helm-set=ipv4.enabled=true --helm-set=ipv6.enabled=true\"\n              KIND_POD_CIDR_1=\"10.242.0.0/16,fd00:10:242::/48\"\n              KIND_SVC_CIDR_1=\"10.243.0.0/16,fd00:10:243::/112\"\n              KIND_POD_CIDR_2=\"10.244.0.0/16,fd00:10:244::/48\"\n              KIND_SVC_CIDR_2=\"10.245.0.0/16,fd00:10:245::/112\"\n              ;;\n            *)\n              echo \"Unknown IP family '${{ matrix.ipFamily }}'\" && false\n              ;;\n          esac\n\n          CILIUM_INSTALL_ENCRYPTION=\"\"\n          if [ \"${{ matrix.encryption }}\" != \"disabled\" ]; then\n            CILIUM_INSTALL_ENCRYPTION=\"--helm-set=encryption.enabled=true \\\n              --helm-set=encryption.type=${{ matrix.encryption }}\"\n          fi\n\n          CILIUM_INSTALL_INGRESS=\"\"\n          if [ \"${{ matrix.kube-proxy }}\" == \"none\" ]; then\n            CILIUM_INSTALL_INGRESS=\"--helm-set=ingressController.enabled=true\"\n          fi\n\n          CILIUM_INSTALL_MULTIPOOL_IPAM=\"\"\n          CILIUM_INSTALL_MULTIPOOL_IPAM_CLUSTER1=\"\"\n          CILIUM_INSTALL_MULTIPOOL_IPAM_CLUSTER2=\"\"\n          if [ \"${{ matrix.multipool-ipam }}\" != \"disabled\" ]; then\n            CILIUM_INSTALL_MULTIPOOL_IPAM=\"--helm-set=endpointRoutes.enabled=true \\\n              --helm-set=bpf.hostLegacyRouting=true \\\n              --helm-set=ipam.mode=multi-pool \\\n              --helm-set=ipMasqAgent.config.nonMasqueradeCIDRs='{10.0.0.0/8,11.0.0.0/8,192.168.0.0/20,192.168.16.0/20}'\"\n\n            CILIUM_INSTALL_MULTIPOOL_IPAM_CLUSTER1=\"--helm-set=ipMasqAgent.enabled=true \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv4.cidrs='{10.10.0.0/16}' \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv4.maskSize=24 \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.cilium-test-pool.ipv4.cidrs='{10.20.0.0/16}' \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.cilium-test-pool.ipv4.maskSize=24 \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.client-pool.ipv4.cidrs='{192.168.0.0/24}' \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.client-pool.ipv4.maskSize=27\"\n\n            CILIUM_INSTALL_MULTIPOOL_IPAM_CLUSTER2=\"--helm-set=ipMasqAgent.enabled=true \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv4.cidrs='{11.10.0.0/16}' \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv4.maskSize=24 \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.echo-other-node-pool.ipv4.cidrs='{192.168.16.0/24}' \\\n              --helm-set=ipam.operator.autoCreateCiliumPodIPPools.echo-other-node-pool.ipv4.maskSize=27\"\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }} \\\n            --multi-cluster=${{ env.contextName2 }} \\\n            --sysdump-output-filename 'cilium-sysdump-${{ matrix.name }}-<ts>'\"\n\n          if [ \"${{ matrix.multipool-ipam }}\" != \"disabled\" ]; then\n            CONNECTIVITY_TEST_DEFAULTS=\"$CONNECTIVITY_TEST_DEFAULTS \\\n              --namespace-annotations=ipam.cilium.io/ip-pool=cilium-test-pool \\\n              --deployment-pod-annotations='{ \\\n                  \\\"client\\\":{\\\"ipam.cilium.io/ip-pool\\\":\\\"client-pool\\\"}, \\\n                  \\\"echo-other-node\\\":{\\\"ipam.cilium.io/ip-pool\\\":\\\"echo-other-node-pool\\\"} \\\n              }'\"\n          fi\n\n          # Skip external traffic (e.g. 1.1.1.1 and www.google.com) tests as IPv6 is not supported\n          # in GitHub runners: https://github.com/actions/runner-images/issues/668\n          if [[ \"${{ matrix.ipFamily }}\" == \"ipv6\" ]]; then\n            CONNECTIVITY_TEST_DEFAULTS=\"$CONNECTIVITY_TEST_DEFAULTS \\\n              --test='!/pod-to-world' \\\n              --test='!/pod-to-cidr'\"\n          fi\n\n          echo cilium_install_defaults=\"${CILIUM_INSTALL_DEFAULTS} ${CILIUM_INSTALL_TUNNEL} \\\n            ${CILIUM_INSTALL_IPFAMILY} ${CILIUM_INSTALL_ENCRYPTION} ${CILIUM_INSTALL_INGRESS} ${CILIUM_INSTALL_MULTIPOOL_IPAM}\" >> $GITHUB_OUTPUT\n          echo cilium_install_multipool_ipam_cluster1=\"${CILIUM_INSTALL_MULTIPOOL_IPAM_CLUSTER1}\" >> $GITHUB_OUTPUT\n          echo cilium_install_multipool_ipam_cluster2=\"${CILIUM_INSTALL_MULTIPOOL_IPAM_CLUSTER2}\" >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n          echo kind_pod_cidr_1=${KIND_POD_CIDR_1} >> $GITHUB_OUTPUT\n          echo kind_svc_cidr_1=${KIND_SVC_CIDR_1} >> $GITHUB_OUTPUT\n          echo kind_pod_cidr_2=${KIND_POD_CIDR_2} >> $GITHUB_OUTPUT\n          echo kind_svc_cidr_2=${KIND_SVC_CIDR_2} >> $GITHUB_OUTPUT\n\n      - name: Generate Kind configuration files\n        run: |\n          PODCIDR=${{ steps.vars.outputs.kind_pod_cidr_1 }} \\\n            SVCCIDR=${{ steps.vars.outputs.kind_svc_cidr_1 }} \\\n            IPFAMILY=${{ matrix.ipFamily }} \\\n            KUBEPROXYMODE=${{ matrix.kube-proxy }} \\\n            envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-cluster1.yaml\n\n          PODCIDR=${{ steps.vars.outputs.kind_pod_cidr_2 }} \\\n            SVCCIDR=${{ steps.vars.outputs.kind_svc_cidr_2 }} \\\n            IPFAMILY=${{ matrix.ipFamily }} \\\n            KUBEPROXYMODE=${{ matrix.kube-proxy }} \\\n            envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-cluster2.yaml\n\n      - name: Create Kind cluster 1\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          cluster_name: ${{ env.clusterName1 }}\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ./.github/kind-config-cluster1.yaml\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Create Kind cluster 2\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          cluster_name: ${{ env.clusterName2 }}\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ./.github/kind-config-cluster2.yaml\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Label one of the nodes as external to the cluster\n        run: |\n          kubectl --context ${{ env.contextName1 }} label node \\\n            ${{ env.clusterName1 }}-worker2 cilium.io/no-schedule=true\n\n      # Make sure that coredns uses IPv4-only upstream DNS servers also in case of clusters\n      # with IP family dual, since IPv6 ones are not reachable and cause spurious failures.\n      # Additionally, this is also required to workaround\n      # https://github.com/cilium/cilium/issues/23283#issuecomment-1597282247.\n      - name: Configure the coredns nameservers\n        run: |\n          COREDNS_PATCH=\"\n          spec:\n            template:\n              spec:\n                dnsPolicy: None\n                dnsConfig:\n                  nameservers:\n                  - 8.8.4.4\n                  - 8.8.8.8\n          \"\n\n          kubectl --context ${{ env.contextName1 }} -n kube-system get configmap coredns -o yaml | \\\n            sed '/loadbalance/a \\        log' | kubectl --context ${{ env.contextName1 }} replace -f -\n          kubectl --context ${{ env.contextName2 }} -n kube-system get configmap coredns -o yaml | \\\n            sed '/loadbalance/a \\        log' | kubectl --context ${{ env.contextName2 }} replace -f -\n\n          kubectl --context ${{ env.contextName1 }} patch deployment -n kube-system coredns --patch=\"$COREDNS_PATCH\"\n          kubectl --context ${{ env.contextName2 }} patch deployment -n kube-system coredns --patch=\"$COREDNS_PATCH\"\n\n      - name: Start kvstore clusters\n        id: kvstore\n        if: matrix.mode == 'external'\n        uses: ./.github/actions/kvstore\n        with:\n          clusters: 2\n\n      - name: Create the secret containing the kvstore credentials\n        if: matrix.mode == 'external'\n        run: |\n          kubectl --context ${{ env.contextName1 }} create -n kube-system -f ${{ steps.kvstore.outputs.cilium_etcd_secrets_path }}\n          kubectl --context ${{ env.contextName2 }} create -n kube-system -f ${{ steps.kvstore.outputs.cilium_etcd_secrets_path }}\n\n      - name: Install cert-manager CRDs and create Cilium's issuer\n        if: matrix.tls-auto-method == 'certmanager'\n        run: |\n          # Generate the Cilium CA key and certificate\n          openssl genrsa 4096 > cilium-ca-key.pem\n          openssl req -new -x509 -nodes -days 1 -key cilium-ca-key.pem -out cilium-ca-crt.pem -subj \"/CN=Cilium CA/\"\n\n          cat << EOF > issuer.yaml\n          apiVersion: cert-manager.io/v1\n          kind: Issuer\n          metadata:\n            name: cilium\n            namespace: kube-system\n          spec:\n            ca:\n              secretName: cilium-root-ca\n          EOF\n\n          for ctx in ${{ env.contextName1 }} ${{ env.contextName2 }}; do\n            # Install the cert-manager CRDs\n            CRD_URL=\"https://github.com/cert-manager/cert-manager/releases/download/${{ env.CERT_MANAGER_VERSION }}/cert-manager.crds.yaml\"\n            kubectl --context $ctx apply -f $CRD_URL\n\n            # Create the Cilium CA secret\n            kubectl --context $ctx create -n kube-system secret tls cilium-root-ca \\\n              --key=cilium-ca-key.pem --cert=cilium-ca-crt.pem\n\n            # Create the cert-manager issuer\n            kubectl --context $ctx apply -f issuer.yaml\n          done\n\n      - name: Set clustermesh connection parameters\n        if: matrix.mode == 'external'\n        id: clustermesh-vars\n        run: |\n          echo \"cilium_install_clustermesh= \\\n            --set=clustermesh.config.enabled=true \\\n            --set clustermesh.config.clusters[0].name=${{ env.ciliumClusterName1 }} \\\n            --set clustermesh.config.clusters[1].name=${{ env.ciliumClusterName2 }} \\\n            ${{ steps.kvstore.outputs.cilium_install_clustermesh }} \\\n          \" >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Create the IPSec secret in both clusters\n        if: matrix.encryption == 'ipsec'\n        run: |\n          SECRET=\"3+ rfc4106(gcm(aes)) $(openssl rand -hex 20) 128\"\n          kubectl --context ${{ env.contextName1 }} create -n kube-system secret generic cilium-ipsec-keys --from-literal=keys=\"${SECRET}\"\n          kubectl --context ${{ env.contextName2 }} create -n kube-system secret generic cilium-ipsec-keys --from-literal=keys=\"${SECRET}\"\n\n      - name: Install Cilium in cluster1\n        id: install-cilium-cluster1\n        env:\n          KVSTORE_ID: 1\n        run: |\n          # Explicitly configure the NodePort to make sure that it is different in\n          # each cluster, to workaround #24692\n          cilium --context ${{ env.contextName1 }} install \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            --helm-set cluster.name=${{ env.ciliumClusterName1 }} \\\n            --helm-set cluster.id=1 \\\n            --helm-set clustermesh.apiserver.service.nodePort=32379 \\\n            --helm-set clustermesh.apiserver.tls.authMode=${{ matrix.cm-auth-mode-1 }} \\\n            ${{ steps.vars.outputs.cilium_install_multipool_ipam_cluster1 }} \\\n            ${{ steps.kvstore.outputs.cilium_install_kvstore }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_clustermesh }} \\\n            --nodes-without-cilium\n\n      - name: Copy the Cilium CA secret to cluster2, as they must match\n        if: matrix.tls-auto-method != 'certmanager'\n        run: |\n          kubectl --context ${{ env.contextName1 }} get secret -n kube-system cilium-ca -o yaml |\n            kubectl --context ${{ env.contextName2 }} create -f -\n\n      - name: Install Cilium in cluster2\n        env:\n          KVSTORE_ID: 2\n        run: |\n          # Explicitly configure the NodePort to make sure that it is different in\n          # each cluster, to workaround #24692\n          cilium --context ${{ env.contextName2 }} install \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            --helm-set cluster.name=${{ env.ciliumClusterName2 }} \\\n            --helm-set cluster.id=${{ matrix.maxConnectedClusters }} \\\n            --helm-set clustermesh.apiserver.service.nodePort=32380 \\\n            --helm-set clustermesh.apiserver.tls.authMode=${{ matrix.cm-auth-mode-2 }} \\\n            ${{ steps.vars.outputs.cilium_install_multipool_ipam_cluster2 }} \\\n            ${{ steps.kvstore.outputs.cilium_install_kvstore }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_clustermesh }}\n\n      - name: Install cert-manager\n        if: matrix.tls-auto-method == 'certmanager'\n        run: |\n          helm repo add jetstack https://charts.jetstack.io\n          for ctx in ${{ env.contextName1 }} ${{ env.contextName2 }}; do\n            helm --kube-context $ctx install \\\n              cert-manager jetstack/cert-manager \\\n              --namespace cert-manager \\\n              --create-namespace \\\n              --version ${{ env.CERT_MANAGER_VERSION }}\n          done\n\n      - name: Wait for cluster mesh status to be ready\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait\n\n      - name: Connect clusters\n        if: matrix.mode != 'external'\n        run: |\n          cilium --context ${{ env.contextName1 }} clustermesh connect --destination-context ${{ env.contextName2 }}\n\n      - name: Wait for cluster mesh status to be ready\n        if: matrix.mode != 'external'\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Record \"No node ID found\" drops\n        id: no_nodeid_drops_prev\n        run: |\n          set -x\n          total_drops=0\n          for cilium_pod in $(kubectl -n kube-system --context ${{ env.contextName1 }} get po -l k8s-app=cilium -o jsonpath='{.items[*].metadata.name}'); do\n            drops=$(kubectl -n kube-system --context ${{ env.contextName1 }} exec $cilium_pod -- cilium metrics list -o json | jq '.[] | select((.name == \"cilium_drop_count_total\") and (.labels.reason == \"No node ID found\")) | .value')\n            total_drops=$((total_drops + drops))\n          done\n\n          echo \"No node ID found drops: $total_drops\"\n          echo \"total_drops=$total_drops\" >> $GITHUB_OUTPUT\n\n      - name: Run connectivity test (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium --context ${{ env.contextName1 }} connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n          --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test (${{ join(matrix.*, ', ') }})\" \\\n          --expected-drop-reasons='+No node ID found'\n\n      - name: Assert no \"No node ID found\" drops\n        run: |\n          set -x\n          total_drops=0\n          for cilium_pod in $(kubectl -n kube-system --context ${{ env.contextName1 }} get po -l k8s-app=cilium -o jsonpath='{.items[*].metadata.name}'); do\n            drops=$(kubectl -n kube-system --context ${{ env.contextName1 }} exec $cilium_pod -- cilium metrics list -o json | jq '.[] | select((.name == \"cilium_drop_count_total\") and (.labels.reason == \"No node ID found\")) | .value')\n            total_drops=$((total_drops + drops))\n          done\n\n          echo \"prev_drops: ${{ steps.no_nodeid_drops_prev.outputs.total_drops }}\"\n          echo \"current_drops: $total_drops\"\n          if [[ \"$total_drops\" != ${{ steps.no_nodeid_drops_prev.outputs.total_drops }} ]]; then\n            # run no-unexpected-packet-drops connectivity to collect sysdumps\n            cilium --context ${{ env.contextName1 }} connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run connectivity test (${{ join(matrix.*, ', ') }})\" \\\n            --test 'no-unexpected-packet-drops'\n          fi\n\n      - name: Features tested on cluster 1\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName1 }}\"\n          title: \"Summary of all features tested on cluster 1\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 1\"\n\n      - name: Features tested on cluster 2\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName2 }}\"\n          title: \"Summary of all features tested on cluster 2\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 2\"\n\n      - name: Post-test information gathering\n        if: ${{ !success() && steps.install-cilium-cluster1.outcome != 'skipped' }}\n        run: |\n          cilium --context ${{ env.contextName1 }} status\n          cilium --context ${{ env.contextName1 }} clustermesh status\n          cilium --context ${{ env.contextName2 }} status\n          cilium --context ${{ env.contextName2 }} clustermesh status\n\n          kubectl config use-context ${{ env.contextName1 }}\n          kubectl get pods --all-namespaces -o wide\n          cilium sysdump --output-filename cilium-sysdump-context1-final-${{ join(matrix.*, '-') }}\n\n          kubectl config use-context ${{ env.contextName2 }}\n          kubectl get pods --all-namespaces -o wide\n          cilium sysdump --output-filename cilium-sysdump-context2-final-${{ join(matrix.*, '-') }}\n\n          kubectl --context ${{ env.contextName1 }} logs -n kube-system -l k8s-app=kube-dns --prefix --timestamps --tail=-1\n          kubectl --context ${{ env.contextName2 }} logs -n kube-system -l k8s-app=kube-dns --prefix --timestamps --tail=-1\n\n          if [ \"${{ matrix.mode }}\" == \"external\" ]; then\n            for i in {1..2}; do\n              echo\n              echo \"# Retrieving logs from kvstore$i docker container\"\n              docker logs kvstore$i\n            done\n          fi\n        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n          capture_sysdump: false\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-connectivity\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.installation-and-connectivity.result }}\n"
						}
					},
					{
						"name": "conformance-delegated-ipam.yaml",
						"object": {
							"text": "name: Conformance Delegated IPAM (ci-delegated-ipam)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - push: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  timeout: 5m\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  delegated-ipam-conformance-test:\n    name: Install and Connectivity Test\n    env:\n      job_name: \"Install and Connectivity Test\"\n    runs-on: ubuntu-24.04\n    timeout-minutes: 120\n    strategy:\n      fail-fast: false\n      matrix:\n        ipFamily: [\"ipv4\", \"dual\"]\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n          test-concurrency: 5\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            CONTEXT_REF=\"${{ inputs.context-ref }}\"\n            OWNER=\"${{ inputs.PR-number }}\"\n          else\n            CONTEXT_REF=\"${{ github.sha }}\"\n            OWNER=\"${{ github.ref_name }}\"\n            OWNER=\"${OWNER//[.\\/]/-}\"\n          fi\n\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n          echo context-ref=${CONTEXT_REF} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n          # Cilium configured with delegated IPAM mode.\n          # * Set cni.customConf=true since conflist is configured using host mount into kind nodes.\n          # * Delegated IPAM requires direct routing mode.\n          # * Delegated IPAM is incompatible with all options that require cilium-agent to assign itself an IP address,\n          #    so set local-router-ipv4 and endpointHealthChecking.enabled=false.\n          # * Use BPF masquerade with ipMasqAgent.enabled=true because iptables masquerade (enable-ipv4-masquerade=true)\n          #    matches on source IP in the node pod CIDR, which isn't available to Cilium in delegated IPAM mode.\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=ipam.mode=delegated-plugin \\\n            --helm-set=cni.customConf=true \\\n            --helm-set=routingMode=native \\\n            --helm-set=ipv4NativeRoutingCIDR=10.244.0.0/16 \\\n            --helm-set=endpointRoutes.enabled=true \\\n            --helm-set=endpointHealthChecking.enabled=false \\\n            --helm-set=extraArgs[0]=\\\"--local-router-ipv4=169.254.23.0\\\" \\\n            --helm-set=enableIPv4Masquerade=true \\\n            --helm-set=bpf.masquerade=true \\\n            --helm-set=ipMasqAgent.enabled=true\"\n\n          if [ \"${{ matrix.ipFamily }}\" = \"dual\" ]; then\n            CILIUM_INSTALL_DEFAULTS=\"${CILIUM_INSTALL_DEFAULTS} \\\n              --helm-set=ipv6.enabled=true \\\n              --helm-set=ipv6NativeRoutingCIDR=fd00:10:244::/56 \\\n              --helm-set=extraArgs[1]=\\\"--local-router-ipv6=fe80::\\\" \\\n              --helm-set=enableIPv6Masquerade=true\"\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n\n      - name: Generate conflist for each node\n        run: |\n          createConflist() {\n            file=$1\n            ipv4Subnet=$2\n            ipv6Subnet=$3\n\n            ranges=\"[{\\\"subnet\\\": \\\"$ipv4Subnet\\\"}]\"\n            if [ \"${{ matrix.ipFamily }}\" = \"dual\" ]; then\n              ranges=\"${ranges}, [{\\\"subnet\\\": \\\"$ipv6Subnet\\\"}]\"\n            fi\n\n            cat <<EOF > $file\n            {\n              \"cniVersion\": \"0.3.1\",\n              \"name\": \"cilium\",\n              \"plugins\": [\n                {\n                  \"type\": \"cilium-cni\",\n                  \"enable-debug\": true,\n                  \"log-file\": \"/var/log/cilium-cni.log\",\n                  \"ipam\": {\n                    \"type\": \"host-local\",\n                    \"ranges\": [$ranges]\n                  }\n                }\n              ]\n            }\n          EOF\n          }\n\n          createConflist \"kind-control-plane-delegated-ipam.conflist\" \"10.244.1.0/24\" \"fd00:10:244:1::/64\"\n          createConflist \"kind-worker-delegated-ipam.conflist\" \"10.244.2.0/24\" \"fd00:10:244:2::/64\"\n          createConflist \"kind-worker2-delegated-ipam.conflist\" \"10.244.3.0/24\" \"fd00:10:244:3::/64\"\n\n      - name: Generate kind config\n        run: |\n          ipFamily=\"ipv4\"\n          podSubnet=\"10.244.0.0/16\"\n          serviceSubnet=\"10.245.0.0/16\"\n          if [ \"${{ matrix.ipFamily }}\" = \"dual\" ]; then\n            ipFamily=\"dual\"\n            podSubnet=\"${podSubnet},fd00:10:244::/56\"\n            serviceSubnet=\"${serviceSubnet},fd00:10:96::/112\"\n          fi\n\n          cat <<EOF > kind-config-delegated-ipam.yaml\n          kind: Cluster\n          apiVersion: kind.x-k8s.io/v1alpha4\n          nodes:\n            - role: control-plane\n              # Disable kube-controller-manager allocate-node-cidrs to avoid mismatch between\n              # the node podCIDR assigned by KCM and the CIDR configured for the host-local IPAM plugin.\n              kubeadmConfigPatches:\n                - |\n                  apiVersion: kubeadm.k8s.io/v1beta3\n                  kind: ClusterConfiguration\n                  controllerManager:\n                    extraArgs:\n                      allocate-node-cidrs: \"false\"\n              extraMounts:\n                - hostPath: kind-control-plane-delegated-ipam.conflist\n                  containerPath: /etc/cni/net.d/05-cilium.conflist\n\n            - role: worker\n              extraMounts:\n                - hostPath: kind-worker-delegated-ipam.conflist\n                  containerPath: /etc/cni/net.d/05-cilium.conflist\n\n            - role: worker\n              extraMounts:\n                - hostPath: kind-worker2-delegated-ipam.conflist\n                  containerPath: /etc/cni/net.d/05-cilium.conflist\n\n          networking:\n            disableDefaultCNI: true\n            ipFamily: \"$ipFamily\"\n            podSubnet: \"$podSubnet\"\n            serviceSubnet: \"$serviceSubnet\"\n          EOF\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          cluster_name: \"kind\"\n          config: kind-config-delegated-ipam.yaml # created by earlier step\n          wait: 0\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Wait for nodes to become ready\n        run: |\n          kubectl wait --for=condition=Ready nodes --all --timeout=300s\n          kubectl get nodes -oyaml\n\n      # Delegated IPAM requires direct routing, and we can't use autoDirectNodeRoutes or BGP because\n      # Cilium isn't aware of the pod CIDR for each node.\n      # So use `ip route add` to ensure pod traffic is routed to the correct node.\n      - name: Configure routes\n        run: |\n          addPodCIDRRoutesToNode() {\n            node=$1\n            ipv4Subnet=$2\n            ipv6Subnet=$3\n\n            nodeIPv4=$(kubectl get node $node -o json | jq -r '.status.addresses[] | select(.type==\"InternalIP\") | .address' | head -n 1)\n            echo \"adding route from $ipv4Subnet via $nodeIPv4\"\n            sudo ip route add $ipv4Subnet via $nodeIPv4\n\n            if [ \"${{ matrix.ipFamily }}\" = \"dual\" ]; then\n              nodeIPv6=$(kubectl get node $node -o json | jq -r '.status.addresses[] | select(.type==\"InternalIP\") | .address' | tail -n 1)\n              echo \"adding route from $ipv6Subnet via $nodeIPv6\"\n              sudo ip -6 route add $ipv6Subnet via $nodeIPv6\n            fi\n          }\n\n          echo \"Current routes:\"\n          ip route\n          ip -6 route\n\n          echo \"Configuring routes from podCIDR to node:\"\n\n          addPodCIDRRoutesToNode kind-control-plane \"10.244.1.0/24\" \"fd00:10:244:1::/64\"\n          addPodCIDRRoutesToNode kind-worker \"10.244.2.0/24\" \"fd00:10:244:2::/64\"\n          addPodCIDRRoutesToNode kind-worker2 \"10.244.3.0/24\" \"fd00:10:244:3::/64\"\n\n          echo \"Updated routes:\"\n          ip route\n          ip -6 route\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl -n kube-system get pods -owide\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Cilium connectivity test\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.*, ', ') }}).xml\" --junit-property github_job_step=\"Run connectivity test\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }})\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: delegated-ipam-conformance-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.delegated-ipam-conformance-test.result }}\n"
						}
					},
					{
						"name": "conformance-eks.yaml",
						"object": {
							"text": "name: Conformance EKS (ci-eks)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 1/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  test_concurrency: 3\n  clusterName: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-${{ github.run_attempt }}\n  # renovate: datasource=github-releases depName=eksctl-io/eksctl\n  eksctl_version: v0.214.0\n  # renovate: datasource=github-releases depName=kubernetes/kubernetes\n  kubectl_version: v1.34.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-aws-ci hubble-relay-ci cilium-cli-ci\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      empty: ${{ steps.set-matrix.outputs.empty }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/eks\"\n          destination_directory=\"/tmp/generated/eks\"\n          mkdir -p \"${destination_directory}\"\n\n          yq -o=json \"${work_dir}/k8s-versions.yaml\" | jq . > \"${destination_directory}/eks.json\"\n\n      - name: Generate Matrix\n        run: |\n          cd /tmp/generated/eks\n\n          # Use complete matrix in case of scheduled run\n          # main -> event_name = schedule\n          # other stable branches -> PR-number starting with v (e.g. v1.14)\n          # shellcheck disable=SC2193\n          if [[ \"${{ github.event_name }}\" == \"schedule\" || \"${{ inputs.PR-number }}\" == v* ]];then\n            cp eks.json /tmp/matrix.json\n          else\n            jq '{ \"include\": [ .include[] | select(.default) ] }' eks.json > /tmp/matrix.json\n          fi\n\n          echo \"Generated matrix:\"\n          cat /tmp/matrix.json\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: us-west-1\n\n      - name: Filter Matrix\n        id: set-matrix\n        run: |\n          cp /tmp/matrix.json /tmp/result.json\n          jq -c '.include[]' /tmp/matrix.json | while read i; do\n            VERSION=$(echo $i | jq -r '.version')\n            aws eks describe-cluster-versions | jq -r '.clusterVersions[].clusterVersion' > /tmp/output\n            if grep -q -F $VERSION /tmp/output; then\n              echo \"Version $VERSION is supported\"\n            else\n              echo \"::notice::Removing version $VERSION as it's not supported\"\n              jq 'del(.include[] | select(.version == \"'$VERSION'\"))' /tmp/result.json > /tmp/result.json.tmp\n              mv /tmp/result.json.tmp /tmp/result.json\n            fi\n          done\n          echo \"Filtered matrix:\"\n          cat /tmp/result.json\n          echo \"matrix=$(jq -c . < /tmp/result.json)\" >> $GITHUB_OUTPUT\n          echo \"empty=$(jq '(.include | length) == 0' /tmp/result.json)\" >> $GITHUB_OUTPUT\n\n  installation-and-connectivity:\n    name: Installation and Connectivity Test\n    needs: [generate-matrix, wait-for-images]\n    if: ${{ needs.generate-matrix.outputs.empty == 'false' }}\n    runs-on: ubuntu-24.04\n    timeout-minutes: 90\n    env:\n      job_name: \"Installation and Connectivity Test\"\n    strategy:\n      fail-fast: false\n      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          external-target: 'amazon.com.'\n          hubble: false\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            OWNER=\"${{ inputs.PR-number }}\"\n          else\n            OWNER=\"${{ github.ref_name }}\"\n            OWNER=\"${OWNER//[.\\/]/-}\"\n          fi\n\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cluster.name=${{ env.clusterName }} \\\n            --helm-set=hubble.relay.enabled=true \\\n            --helm-set loadBalancer.l7.backend=envoy \\\n            --wait=false\"\n          if [[ \"${{ matrix.ipsec }}\" == \"true\" ]]; then\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set encryption.enabled=true --helm-set encryption.type=ipsec\"\n          fi\n          if [[ \"${{ matrix.kpr }}\" == \"true\" ]]; then\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set kubeProxyReplacement=true\"\n          fi\n          if [[ \"${{ matrix.aws-eni-pd }}\" == \"true\" ]]; then\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set eni.awsEnablePrefixDelegation=true\"\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n      - name: Install kubectl\n        run: |\n          curl -sLO \"https://dl.k8s.io/release/${{ env.kubectl_version }}/bin/linux/amd64/kubectl\"\n          curl -sLO \"https://dl.k8s.io/${{ env.kubectl_version }}/bin/linux/amd64/kubectl.sha256\"\n          echo \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check\n          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n          kubectl version --client\n\n      - name: Install eksctl CLI\n        run: |\n          curl -LO \"https://github.com/eksctl-io/eksctl/releases/download/${{ env.eksctl_version }}/eksctl_$(uname -s)_amd64.tar.gz\"\n          sudo tar -xzvf \"eksctl_$(uname -s)_amd64.tar.gz\" -C /usr/bin\n          rm \"eksctl_$(uname -s)_amd64.tar.gz\"\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: ${{ matrix.region }}\n          role-duration-seconds: 28800 # 8h\n\n      - name: Create EKS cluster\n        uses: ./.github/actions/setup-eks-cluster\n        with:\n          cluster_name: ${{ env.clusterName }}\n          region: ${{ matrix.region }}\n          owner: \"${{ steps.vars.outputs.owner }}\"\n          version: ${{ matrix.version }}\n          addons: \"coredns kube-proxy\"\n\n      - name: Generate cilium-cli kubeconfig\n        id: gen-kubeconfig\n        uses: ./.github/actions/get-cloud-kubeconfig\n        with:\n          kubeconfig: \"~/.kube/config\"\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n          kubeconfig: ${{ steps.gen-kubeconfig.outputs.kubeconfig_path }}\n\n      - name: Create IPsec key\n        if: ${{ matrix.ipsec == true }}\n        shell: bash\n        run: |\n          cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Create EKS nodegroups\n        uses: ./.github/actions/setup-eks-nodegroup\n        with:\n          cluster_name: ${{ env.clusterName }}\n          region: ${{ matrix.region }}\n          owner: \"${{ steps.vars.outputs.owner }}\"\n          version: ${{ matrix.version }}\n          spot: false\n\n      - name: Wait for Cilium to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods -n kube-system\n\n      - name: Check that AWS leftover iptables chains have been removed\n        run: |\n          for pod in $(kubectl get po -n kube-system -l app.kubernetes.io/name=cilium-agent -o name); do\n            echo \"Checking ${pod}\"\n            if kubectl exec -n kube-system  ${pod} -c cilium-agent -- iptables-save | grep --silent ':AWS'; then\n              echo \"Unexpected AWS leftover iptables chains\"\n              kubectl exec -n kube-system ds/cilium -- iptables-save | grep ':AWS'\n              exit 1\n            fi\n          done\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n          --test-concurrency=${{ env.test_concurrency }} \\\n          --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - 1.xml\" \\\n          --junit-property github_job_step=\"Run connectivity test (${{ join(matrix.*, ', ') }})\"\n\n      - name: Features tested\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - 1\"\n\n      - name: Setup conn-disrupt-test before rotating (${{ join(matrix.*, ', ') }})\n        if: ${{ matrix.ipsec == true }}\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Run IPsec key rotation tests (${{ join(matrix.*, ', ') }})\n        if: ${{ matrix.ipsec == true }}\n        uses: ./.github/actions/ipsec-key-rotate\n        with:\n          key-algo: \"rfc4106-gcm-aes\"\n\n      - name: Check conn-disrupt-test after rotating (${{ join(matrix.*, ', ') }})\n        if: ${{ matrix.ipsec == true }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: ${{ env.job_name }}-${{ matrix.version }}-post-rotate\n          full-test: 'true'\n          test-concurrency: ${{ env.test_concurrency }}\n          extra-connectivity-test-flags: ${{ steps.vars.outputs.connectivity_test_defaults }}\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ join(matrix.*, '-') }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-connectivity\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.installation-and-connectivity.result }}\n\n  cleanup:\n    name: Cleanup EKS Clusters\n    if: ${{ always() && needs.generate-matrix.outputs.empty == 'false' }}\n    continue-on-error: true\n    needs: [generate-matrix, installation-and-connectivity]\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    strategy:\n      fail-fast: false\n      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}\n\n    steps:\n      - name: Install eksctl CLI\n        run: |\n          curl -LO \"https://github.com/eksctl-io/eksctl/releases/download/${{ env.eksctl_version }}/eksctl_$(uname -s)_amd64.tar.gz\"\n          sudo tar -xzvf \"eksctl_$(uname -s)_amd64.tar.gz\" -C /usr/bin\n          rm \"eksctl_$(uname -s)_amd64.tar.gz\"\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: ${{ matrix.region }}\n\n      - name: Clean up EKS\n        run: |\n          eksctl delete cluster --name ${{ env.clusterName }} --region ${{ matrix.region }}\n        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently\n"
						}
					},
					{
						"name": "conformance-gateway-api.yaml",
						"object": {
							"text": "name: Conformance Gateway API (ci-gateway-api)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  kind_config: .github/kind-config.yaml\n  timeout: 5m\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci\n\n  gateway-api-conformance-test:\n    name: Gateway API Conformance Test\n    env:\n      job_name: \"Gateway API Conformance Test\"\n    needs: [wait-for-images]\n    runs-on: ubuntu-24.04\n    timeout-minutes: 120\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - crd-channel: experimental\n          conformance-profile: false\n        - crd-channel: standard\n          conformance-profile: false\n        - crd-channel: experimental\n          conformance-profile: true\n        - crd-channel: standard\n          conformance-profile: false\n          encryption: ipsec\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Set image tag\n        id: vars\n        run: |\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n          EXEMPT_FEATURES=\"HTTPRouteParentRefPort,MeshConsumerRoute\"\n          if [ \"${{ matrix.crd-channel }}\" == \"standard\" ]; then\n            EXEMPT_FEATURES+=\",HTTPRouteDestinationPortMatching,HTTPRouteRequestTimeout,HTTPRouteBackendTimeout,GatewayInfrastructurePropagation\"\n          fi\n\n          if [ \"${{ matrix.conformance-profile }}\" == \"true\" ]; then\n            SKIPPED_TESTS+=\"MeshConsumerRoute,HTTPRouteListenerPortMatching\"\n          fi\n\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=kubeProxyReplacement=true \\\n            --helm-set=gatewayAPI.enabled=true \\\n            --helm-set=l2announcements.enabled=true\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo skipped_tests=${SKIPPED_TESTS} >> $GITHUB_OUTPUT\n          echo exempt-features=${EXEMPT_FEATURES} >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n            examples\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.kind_config }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Install tparse\n        timeout-minutes: 15\n        run: |\n          # renovate: datasource=github-releases depName=mfridman/tparse\n          go install github.com/mfridman/tparse@28967170dce4f9f13de77ec857f7aed4c4294a5f # v0.12.3 (main) with -progress\n\n      - name: Install Gateway API CRDs\n        run: |\n          gateway_api_version=$(grep -m 1 \"sigs.k8s.io/gateway-api\" go.mod | awk '{print $2}' | awk -F'-' '{print (NF>2)?$NF:$0}')\n          # Install Gateway CRDs\n          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/$gateway_api_version/config/crd/${{ matrix.crd-channel }}/gateway.networking.k8s.io_gatewayclasses.yaml\n          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/$gateway_api_version/config/crd/${{ matrix.crd-channel }}/gateway.networking.k8s.io_gateways.yaml\n          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/$gateway_api_version/config/crd/${{ matrix.crd-channel }}/gateway.networking.k8s.io_httproutes.yaml\n          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/$gateway_api_version/config/crd/${{ matrix.crd-channel }}/gateway.networking.k8s.io_referencegrants.yaml\n          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/$gateway_api_version/config/crd/${{ matrix.crd-channel }}/gateway.networking.k8s.io_grpcroutes.yaml\n          ## TLSRoute is only available in experimental channel in v0.7.0\n          kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/$gateway_api_version/config/crd/experimental/gateway.networking.k8s.io_tlsroutes.yaml\n\n          # To make sure that Gateway API CRs are available\n          kubectl wait --for condition=Established crd/gatewayclasses.gateway.networking.k8s.io --timeout=${{ env.timeout }}\n          kubectl wait --for condition=Established crd/gateways.gateway.networking.k8s.io --timeout=${{ env.timeout }}\n          kubectl wait --for condition=Established crd/httproutes.gateway.networking.k8s.io --timeout=${{ env.timeout }}\n          kubectl wait --for condition=Established crd/tlsroutes.gateway.networking.k8s.io --timeout=${{ env.timeout }}\n          kubectl wait --for condition=Established crd/grpcroutes.gateway.networking.k8s.io --timeout=${{ env.timeout }}\n          kubectl wait --for condition=Established crd/referencegrants.gateway.networking.k8s.io --timeout=${{ env.timeout }}\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium_install_defaults=\"${{ steps.vars.outputs.cilium_install_defaults }}\"\n          if [ \"${{ matrix.encryption }}\" == \"ipsec\" ]; then\n            cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n            cilium_install_defaults+=\" --helm-set=encryption.enabled=true \\\n              --helm-set=encryption.type=ipsec\"\n          fi\n\n          cilium install $cilium_install_defaults\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl -n kube-system get pods\n\n      - name: Install Cilium LB IPPool and L2 Announcement Policy\n        timeout-minutes: 10\n        run: |\n          KIND_NET_CIDR=$(docker network inspect kind -f '{{json .IPAM.Config}}' | jq -r '.[] | select(.Subnet | test(\"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+\\\\.[0-9]+\")) | .Subnet')\n          echo \"KIND_NET_CIDR: $KIND_NET_CIDR\"\n          LB_CIDR=$(echo ${KIND_NET_CIDR} | sed \"s@0.0/16@255.200/28@\")\n          echo \"LB_CIDR: $LB_CIDR\"\n\n          echo \"Deploying LB-IPAM Pool...\"\n          cat << EOF > pool.yaml\n          apiVersion: \"cilium.io/v2\"\n          kind: CiliumLoadBalancerIPPool\n          metadata:\n            name: \"pool\"\n          spec:\n            blocks:\n              - cidr: \"$LB_CIDR\"\n          EOF\n          cat pool.yaml\n          kubectl apply -f pool.yaml\n\n          echo \"Deploying L2-Announcement Policy...\"\n          cat << 'EOF' > l2policy.yaml\n          apiVersion: \"cilium.io/v2alpha1\"\n          kind: CiliumL2AnnouncementPolicy\n          metadata:\n            name: l2policy\n          spec:\n            loadBalancerIPs: true\n            interfaces:\n              - eth0\n            nodeSelector:\n              matchExpressions:\n                - key: node-role.kubernetes.io/control-plane\n                  operator: DoesNotExist\n          EOF\n          cat l2policy.yaml\n          kubectl apply -f l2policy.yaml\n\n      - name: Run Gateway API conformance test\n        timeout-minutes: 30\n        run: |\n          KIND_NET_CIDR=$(docker network inspect kind -f '{{json .IPAM.Config}}' | jq -r '.[] | select(.Subnet | test(\"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+\\\\.[0-9]+\")) | .Subnet')\n          echo \"KIND_NET_CIDR: $KIND_NET_CIDR\"\n          GATEWAY_API_CONFORMANCE_USABLE_NETWORK_ADDRESSES=$(echo ${KIND_NET_CIDR} | sed \"s@0.0/16@255.206@\")\n          GATEWAY_API_CONFORMANCE_UNUSABLE_NETWORK_ADDRESSES=$(echo ${KIND_NET_CIDR} | sed \"s@0.0/16@255.216@\")\n          echo \"GATEWAY_API_CONFORMANCE_USABLE_NETWORK_ADDRESSES: $GATEWAY_API_CONFORMANCE_USABLE_NETWORK_ADDRESSES\"\n          echo \"GATEWAY_API_CONFORMANCE_UNUSABLE_NETWORK_ADDRESSES: $GATEWAY_API_CONFORMANCE_UNUSABLE_NETWORK_ADDRESSES\"\n          # Build test flags based on matrix\n          GATEWAY_TEST_FLAGS=\"--gateway-class cilium --all-features --allow-crds-mismatch\"\n          if [ \"${{ matrix.conformance-profile }}\" == \"true\" ]; then\n            GATEWAY_TEST_FLAGS=\"$GATEWAY_TEST_FLAGS --skip-tests \\\"${{ steps.vars.outputs.skipped_tests }}\\\" --conformance-profiles GATEWAY-HTTP,GATEWAY-TLS,GATEWAY-GRPC,MESH-HTTP,MESH-GRPC --organization cilium --project cilium --url github.com/cilium/cilium --version main --contact https://github.com/cilium/community/blob/main/roles/Maintainers.md --report-output report.yaml\"\n          else\n            GATEWAY_TEST_FLAGS=\"$GATEWAY_TEST_FLAGS --exempt-features \\\"${{ steps.vars.outputs.exempt-features }}\\\" -test.skip \\\"${{ steps.vars.outputs.skipped_tests }}\\\"\"\n          fi\n          GATEWAY_API_CONFORMANCE_USABLE_NETWORK_ADDRESSES=\"$GATEWAY_API_CONFORMANCE_USABLE_NETWORK_ADDRESSES\" \\\n          GATEWAY_API_CONFORMANCE_UNUSABLE_NETWORK_ADDRESSES=\"$GATEWAY_API_CONFORMANCE_UNUSABLE_NETWORK_ADDRESSES\" \\\n          GATEWAY_TEST_FLAGS=\"$GATEWAY_TEST_FLAGS\" \\\n          make gateway-api-conformance\n\n      - name: Run basic CLI tests (${{ join(matrix.*, ', ') }})\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n          cilium connectivity test --include-unsafe-tests --collect-sysdump-on-failure \\\n            --sysdump-hubble-flows-count=1000000 --sysdump-hubble-flows-timeout=5m \\\n            --sysdump-output-filename \"cilium-sysdump-${{ join(matrix.*, '-') }}-<ts>\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests (${{ join(matrix.*, ', ') }})\" \\\n            --log-code-owners --code-owners=${CILIUM_CLI_CODE_OWNERS_PATHS} \\\n            --exclude-code-owners=${CILIUM_CLI_EXCLUDE_OWNERS} \\\n            --test 'allow-all-except-world,encryption,packet-drops'\n\n      - name: Upload report artifacts\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: report-${{ matrix.conformance-profile }}-${{ matrix.crd-channel }}.yaml\n          path: operator/pkg/gateway-api/report.yaml\n          retention-days: 5\n          if-no-files-found: ignore\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }})\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: gateway-api-conformance-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.gateway-api-conformance-test.result }}\n"
						}
					},
					{
						"name": "conformance-ginkgo.yaml",
						"object": {
							"text": "name: Conformance Ginkgo (ci-ginkgo)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 1/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  setup-vars:\n    name: Setup Vars\n    runs-on: ubuntu-24.04\n    outputs:\n      SHA: ${{ steps.vars.outputs.SHA }}\n      context-ref: ${{ steps.vars.outputs.context-ref }}\n      owner: ${{ steps.vars.outputs.owner }}\n    steps:\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n            CONTEXT_REF=\"${{ inputs.context-ref }}\"\n            OWNER=\"${{ inputs.PR-number }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n            CONTEXT_REF=\"${{ github.sha }}\"\n            OWNER=\"${{ github.ref_name }}\"\n            OWNER=\"${OWNER//[.\\/]/-}\"\n          fi\n\n          echo SHA=${SHA} >> $GITHUB_OUTPUT\n          echo context-ref=${CONTEXT_REF} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  # Pre-build the ginkgo binary so that we don't have to build it for all\n  # runners.\n  build-ginkgo-binary:\n    runs-on: ubuntu-24.04\n    name: Build Ginkgo E2E\n    timeout-minutes: 30\n    steps:\n      # If any of these steps are modified, please update the copy of these\n      # steps further down under the 'setup-and-test' jobs.\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.SHA || github.sha }}\n          persist-credentials: false\n\n      # Load Ginkgo build from GitHub\n      - name: Load ginkgo E2E from GH cache\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: cache\n        with:\n          path: /tmp/.ginkgo-build/\n          key: ${{ runner.os }}-ginkgo-e2e-${{ hashFiles('**/*.go') }}\n\n      - name: Install Go\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Build Ginkgo\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          go install github.com/onsi/ginkgo/ginkgo@v1.16.5\n          mkdir -p /tmp/.ginkgo-build\n\n      - name: Build Test\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd test\n          /home/runner/go/bin/ginkgo build\n          strip test.test\n          tar -cz test.test -f test.tgz\n\n      - name: Store Ginkgo Test in GitHub cache path\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.ginkgo-build/\n          if [ -f test/test.tgz ]; then\n            cp test/test.tgz /tmp/.ginkgo-build/\n            echo \"file copied\"\n          fi\n\n  wait-for-images:\n    needs: setup-vars\n    runs-on: ubuntu-24.04\n    name: Wait for images\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Job Matrix from YAMLs\n    needs: setup-vars\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/ginkgo\"\n          destination_directory=\"/tmp/generated/ginkgo\"\n          mkdir -p \"${destination_directory}\"\n          for file in \"${work_dir}\"/main*.yaml; do\n              if [[ -f \"$file\" ]]; then\n                  filename=$(basename \"$file\")\n                  new_filename=\"${filename%.yaml}.json\"\n\n                  yq -o=json \"${file}\" | jq . > \"${destination_directory}/${new_filename}\"\n              fi\n          done\n\n      - name: Generate Matrix\n        id: set-matrix\n        run: |\n          if ${{ github.event_name == 'schedule' }}; then\n            k8s_versions_to_run='main-scheduled.json'\n          else\n            k8s_versions_to_run='main-prs.json'\n          fi\n\n          # Generate a Matrix from all k8s versions defined in '${k8s_versions_to_run}'\n          # combined with 'main-focus.yaml'.\n          # Use 'main-k8s-versions.yaml' to\n          # retrieve which kernel versions should be used for which k8s version.\n\n          dir=\"/tmp/generated/ginkgo\"\n          cd ${dir}\n          jq --argjson prs \"$(jq '.[\"k8s-version\"]' ${k8s_versions_to_run})\" \\\n            --slurpfile focus main-focus.json \\\n            '.include |= map(select(.[\"k8s-version\"] as $k | $prs[] | select($k == .))) + $focus[0].include |\n            . + {\"k8s-version\": $prs} |\n            .focus = $focus[0].focus | .exclude = $focus[0].exclude' \\\n            main-k8s-versions.json> /tmp/merged.json\n          echo \"Generated matrix:\"\n          cat /tmp/merged.json\n          echo \"matrix=$(jq -c . < /tmp/merged.json)\" >> $GITHUB_OUTPUT\n\n  setup-and-test:\n    needs: [setup-vars, build-ginkgo-binary, generate-matrix, wait-for-images]\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    timeout-minutes: 45\n    name: \"E2E Test (${{ matrix.k8s-version }}, ${{matrix.focus}})\"\n    env:\n      job_name: \"E2E Test (${{ matrix.k8s-version }}, ${{matrix.focus}})\"\n    strategy:\n      fail-fast: false\n      max-parallel: 60\n      matrix: ${{ fromJSON(needs.generate-matrix.outputs.matrix) }}\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.SHA || github.sha }}\n          persist-credentials: false\n\n      - name: Install cilium-cli\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ needs.setup-vars.outputs.SHA }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Copy cilium-cli from CI docker image\n        if: ${{ env.CILIUM_CLI_VERSION == '' }}\n        shell: bash\n        run: |\n          cid=$(docker create ${{ env.CILIUM_CLI_IMAGE_REPO }}:${{ needs.setup-vars.outputs.SHA }} ls)\n          docker cp $cid:/usr/local/bin/cilium \"$PWD/cilium-cli-bin\"\n          docker rm $cid\n\n      - name: Copy cilium-cli from released binary\n        if: ${{ env.CILIUM_CLI_VERSION != '' }}\n        shell: bash\n        run: |\n          cp /usr/local/bin/cilium \"$PWD/cilium-cli-bin\"\n\n      - name: Install helm\n        shell: bash\n        run: |\n          # renovate: datasource=github-releases depName=helm/helm\n          HELM_VERSION=v3.13.1\n          wget \"https://get.helm.sh/helm-${HELM_VERSION}-linux-amd64.tar.gz\"\n          tar -xf \"helm-${HELM_VERSION}-linux-amd64.tar.gz\"\n          mv ./linux-amd64/helm ./helm\n\n      - name: Provision LVH VMs\n        id: provision-vh-vms\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          test-name: datapath-conformance\n          install-dependencies: true\n          image-version: ${{ matrix.kernel }}\n          images-folder-parent: \"/tmp\"\n          host-mount: ./\n          cpu: 4\n          mem: 12G\n          # renovate: datasource=github-tags depName=cilium/little-vm-helper\n          lvh-version: \"v0.0.26\"\n          cmd: |\n            git config --global --add safe.directory /host\n            mv /host/helm /usr/bin\n            cp /host/cilium-cli-bin /usr/bin/cilium-cli\n\n      - name: Provision kind\n        timeout-minutes: 5\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            cd /host/\n            if [[ \"${{ matrix.kernel-type }}\" == latest ]]; then\n              ./contrib/scripts/kind.sh \"\" 2 \"\" \"${{ matrix.kube-image }}\" \"none\" \"${{ matrix.ip-family }}\"\n              kubectl label node kind-worker2 cilium.io/ci-node=kind-worker2\n              # Avoid re-labeling this node by setting \"node-role.kubernetes.io/controlplane\"\n              kubectl label node kind-worker2 node-role.kubernetes.io/controlplane=\n            else\n              ./contrib/scripts/kind.sh \"\" 1 \"\" \"${{ matrix.kube-image }}\" \"iptables\" \"${{ matrix.ip-family }}\"\n            fi\n            git config --add safe.directory /cilium\n\n      # Load Ginkgo build from GitHub\n      - name: Load ${{ matrix.name }} Ginkgo build from GitHub\n        uses: actions/cache/restore@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: cache\n        with:\n          path: /tmp/.ginkgo-build/\n          key: ${{ runner.os }}-ginkgo-e2e-${{ hashFiles('**/*.go') }}\n\n      # Re-build the tests if it was a cache miss.\n      - name: Install Go\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Build Ginkgo\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          go install github.com/onsi/ginkgo/ginkgo@v1.16.5\n          mkdir -p /tmp/.ginkgo-build\n\n      - name: Build Test\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd test\n          /home/runner/go/bin/ginkgo build\n          strip test.test\n          tar -cz test.test -f test.tgz\n\n      - name: Store Ginkgo Test in GitHub cache path\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.ginkgo-build/\n          if [ -f test/test.tgz ]; then\n            cp test/test.tgz /tmp/.ginkgo-build/\n            echo \"file copied\"\n          fi\n\n      - name: Copy Ginkgo binary\n        shell: bash\n        run: |\n          cd test/\n          tar -xf /tmp/.ginkgo-build/test.tgz\n\n      - name: Run tests\n        id: run-tests\n        timeout-minutes: 40\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            cd /host/test/\n            kubectl get ns -A -o wide\n            kubectl get pods -A -o wide\n            export K8S_NODES=2\n            export NETNEXT=0\n            if [[ \"${{ matrix.kernel-type }}\" == latest ]]; then\n               export KERNEL=net-next\n               export NETNEXT=1\n               export KUBEPROXY=0\n               export K8S_NODES=3\n               export NO_CILIUM_ON_NODES=kind-worker2\n            elif [[ \"${{ matrix.kernel-type }}\" == stable ]]; then\n               export KERNEL=54\n            fi\n            export K8S_VERSION=${{ matrix.k8s-version }}\n            export CNI_INTEGRATION=kind\n            export INTEGRATION_TESTS=true\n            # GitHub actions do not support IPv6 connectivity to outside\n            # world.\n            export CILIUM_NO_IPV6_OUTSIDE=true\n            echo \"/root/go/bin/ginkgo \\\n             --focus=\\\"${{ matrix.cliFocus }}\\\" \\\n             --skip=\\\"${{ matrix.cliSkip }}\\\" \\\n             --seed=1679952881 \\\n             -v -- \\\n             -cilium.image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n             -cilium.tag=${{ needs.setup-vars.outputs.SHA }}  \\\n             -cilium.operator-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n             -cilium.operator-tag=${{ needs.setup-vars.outputs.SHA }} \\\n             -cilium.hubble-relay-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci \\\n             -cilium.hubble-relay-tag=${{ needs.setup-vars.outputs.SHA }} \\\n             -cilium.kubeconfig=/root/.kube/config \\\n             -cilium.operator-suffix=-ci ${{ env.CILIUM_GINKGO_EXTRA_ARGS }}\"\n\n              ./test.test \\\n               --ginkgo.focus=\"${{ matrix.cliFocus }}\" \\\n               --ginkgo.skip=\"${{ matrix.cliSkip }}\" \\\n               --ginkgo.seed=1679952881 \\\n               --ginkgo.v -- \\\n               -cilium.image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n               -cilium.tag=${{ needs.setup-vars.outputs.SHA }}  \\\n               -cilium.operator-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n               -cilium.operator-tag=${{ needs.setup-vars.outputs.SHA }} \\\n               -cilium.hubble-relay-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci \\\n               -cilium.hubble-relay-tag=${{ needs.setup-vars.outputs.SHA }} \\\n               -cilium.kubeconfig=/root/.kube/config \\\n               -cilium.operator-suffix=-ci ${{ env.CILIUM_GINKGO_EXTRA_ARGS }}\n\n      - name: Fetch artifacts\n        if: ${{ !success() && steps.provision-vh-vms.outcome == 'success' }}\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            cd /host\n            kubectl get pods --all-namespaces -o wide\n            tar -zcf \"test_results-${{ env.job_name }}.tar.gz\" /host/test/test_results\n\n      - name: Fetch tested features\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        shell: bash\n        run: |\n          sudo chown $USER:$USER -R ./test\n          find . -type f -iname 'feature-status-*.json' | while IFS= read -r file; do\n            basename_file=$(basename \"$file\")\n            suffix=\"${basename_file#feature-status-}\"\n            new_filename=\"features-tested-${{ env.job_name }}-${suffix}\"\n            # Truncate filename to 250 characters max\n            if [ ${#new_filename} -gt 250 ]; then\n              new_filename=\"${new_filename:0:250}\"\n            fi\n            # Check if file already exists and fail if it does\n            if [ -f \"./${new_filename}\" ]; then\n              echo \"Error: File ./${new_filename} already exists. Aborting to prevent overwrite.\"\n              exit 1\n            fi\n            mv \"$file\" \"./${new_filename}\"\n          done\n\n      - name: Fetch JUnits\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n          cd test/\n          junit_filename=\"${{ env.job_name }}.xml\"\n          for filename in *.xml; do cp \"${filename}\" \"../cilium-junits/${junit_filename}\"; done;\n\n      - name: Upload artifacts\n        if: ${{ !success() }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: cilium-sysdumps-bugtool-${{ matrix.k8s-version }}-${{matrix.focus}}\n          path: |\n            bugtool-*.tar.gz\n            test_results-*.tar.gz\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          capture_features_tested: 'false'\n          capture_sysdump: 'false'\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: setup-and-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "conformance-gke.yaml",
						"object": {
							"text": "name: Conformance GKE (ci-gke)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 2/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  clusterName: ${{ github.repository_owner }}-${{ github.event.repository.name }}-${{ github.run_id }}-${{ github.run_attempt }}\n  USE_GKE_GCLOUD_AUTH_PLUGIN: True\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      empty: ${{ steps.set-matrix.outputs.empty }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/gke\"\n          destination_directory=\"/tmp/generated/gke\"\n          mkdir -p \"${destination_directory}\"\n\n          # shellcheck disable=SC2010\n          ls ${work_dir}/*.yaml | grep -v 'schema\\|classic' | while read file;do\n            filename=$(basename \"$file\")\n            new_filename=\"${filename%.yaml}.json\"\n            yq -o=json \"${file}\" | jq . > \"${destination_directory}/${new_filename}\"\n          done\n\n          # Merge 2 files into one\n          jq -s \"add\" ${destination_directory}/*.json > \"${destination_directory}/gke.json\"\n\n      - name: Generate Matrix\n        run: |\n          cd /tmp/generated/gke\n\n          # Use complete matrix in case of scheduled run\n          # main -> event_name = schedule\n          # other stable branches -> PR-number starting with v (e.g. v1.14)\n          VERSIONS=$(echo ${{ inputs.extra-args }} | awk -F'=' '{print $2}')\n          # shellcheck disable=SC2193\n          if [[ \"${{ github.event_name }}\" == \"schedule\" || \"${{ inputs.PR-number }}\" == v* || \"$VERSIONS\" == \"all\" ]];then\n            cp gke.json /tmp/matrix.json\n          else\n            jq '{ \"k8s\": [ .k8s[] | select(.default) ], \"config\": .config}' gke.json > /tmp/matrix.json\n          fi\n\n          echo \"Generated matrix:\"\n          cat /tmp/matrix.json\n\n      - name: Set up gcloud credentials\n        id: 'auth'\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PR_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PR_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Set up gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Filter Matrix\n        id: set-matrix\n        run: |\n          CHANNEL=$(echo ${{ inputs.extra-args }} | grep \"channel\" | awk -F'=' '{print $2}' | tr '[:lower:]' '[:upper:]')\n          if [ \"$CHANNEL\" == \"\" ];then\n            FILTER=\"channels.channel=REGULAR\"\n          elif [ \"$CHANNEL\" == \"NONE\" ];then\n            FILTER=\"\"\n          else\n            FILTER=\"channels.channel=$CHANNEL\"\n          fi\n          cp /tmp/matrix.json /tmp/result.json\n          jq -c '.k8s[]' /tmp/matrix.json | while read i; do\n            VERSION=$(echo $i | jq -r '.version')\n            ZONE=$(echo $i | jq -r '.zone')\n            gcloud --quiet container get-server-config \\\n              --flatten=\"channels\" --filter=\"$FILTER\" \\\n              --format=\"yaml(channels.validVersions)\" --zone $ZONE > /tmp/output\n            if grep -q -F $VERSION /tmp/output; then\n              echo \"Version $VERSION is valid for zone $ZONE\"\n            else\n              echo \"::notice::Removing version $VERSION as it's not valid for zone $ZONE\"\n              jq 'del(.k8s[] | select(.version == \"'$VERSION'\"))' /tmp/result.json > /tmp/result.json.tmp\n              mv /tmp/result.json.tmp /tmp/result.json\n            fi\n          done\n          echo \"Filtered matrix:\"\n          cat /tmp/result.json\n\n          echo \"matrix=$(jq -c . < /tmp/result.json)\" >> $GITHUB_OUTPUT\n          echo \"empty=$(jq '(.k8s | length) == 0' /tmp/result.json)\" >> $GITHUB_OUTPUT\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci hubble-relay-ci\n\n  installation-and-connectivity:\n    name: Installation and Connectivity Test\n    needs: [generate-matrix, wait-for-images]\n    if: ${{ needs.generate-matrix.outputs.empty == 'false' }}\n    runs-on: ubuntu-24.04\n    timeout-minutes: 75\n    env:\n      job_name: \"Installation and Connectivity Test\"\n    strategy:\n      fail-fast: false\n      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Truncate owner label for GKE\n        id: truncate-owner\n        uses: ./.github/actions/truncate-label\n        with:\n          label: ${{ github.event_name == 'workflow_dispatch' && inputs.PR-number || github.ref_name }}\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          external-target: 'google.com.'\n          external-cidr: '8.0.0.0/8'\n          external-ip: '8.8.8.8'\n          external-other-ip: '8.8.4.4'\n          hubble: false\n          test-concurrency: 5\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          OWNER=\"${{ steps.truncate-owner.outputs.truncated_label }}\"\n\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cluster.name=${{ env.clusterName }}-${{ matrix.config.index }} \\\n            --helm-set=hubble.relay.enabled=true \\\n            --helm-set=agentNotReadyTaintKey=ignore-taint.cluster-autoscaler.kubernetes.io/cilium-agent-not-ready \\\n            --helm-set loadBalancer.l7.backend=envoy \\\n            --wait=false\"\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo hubble_enable_defaults=${HUBBLE_ENABLE_DEFAULTS} >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n      - name: Set up gcloud credentials\n        id: 'auth'\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PR_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PR_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Set up gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Install gke-gcloud-auth-plugin\n        run: |\n          gcloud components install gke-gcloud-auth-plugin\n\n      - name: Display gcloud CLI info\n        run: |\n          gcloud info\n\n      - name: Create GKE cluster\n        id: create-cluster\n        uses: ./.github/actions/setup-gke-cluster\n        with:\n          cluster-name: ${{ env.clusterName }}-${{ matrix.config.index }}\n          zone: ${{ matrix.k8s.zone }}\n          cluster-version: ${{ matrix.k8s.version }}\n          nodes: ${{ matrix.config.nodes || 2 }}\n          machine-type: e2-custom-2-4096\n          labels: \"usage=${{ github.repository_owner }}-${{ github.event.repository.name }},owner=${{ steps.vars.outputs.owner }}\"\n\n      - name: Create ESP allow firewall rule\n        if: ${{ matrix.config.type == 'tunnel-ipsec' }}\n        uses: ./.github/actions/gke-create-esp-rule\n        with:\n          cluster_name: ${{ env.clusterName }}-${{ matrix.config.index }}\n          cluster_zone: ${{ matrix.k8s.zone }}\n\n      - name: Get cluster credentials\n        run: |\n          gcloud container clusters get-credentials ${{ env.clusterName }}-${{ matrix.config.index }} --zone ${{ matrix.k8s.zone }}\n\n      - name: Generate cilium-cli kubeconfig\n        id: gen-kubeconfig\n        uses: ./.github/actions/get-cloud-kubeconfig\n        with:\n          kubeconfig: \"~/.kube/config\"\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n          kubeconfig: ${{ steps.gen-kubeconfig.outputs.kubeconfig_path }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Create custom IPsec secret\n        if: ${{ matrix.config.type == 'ipsec' || matrix.config.type == 'tunnel-ipsec' }}\n        run: |\n          cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }} ${{ matrix.config.cilium-install-opts }} \\\n          --helm-set=ipv4NativeRoutingCIDR=${{ steps.create-cluster.outputs.native_cidr }}\n\n      - name: Wait for Cilium to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods -n kube-system\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test (${{ matrix.k8s.version }}, ${{ matrix.config.index }}, ${{ matrix.config.type }})\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n          --junit-file \"cilium-junits/${{ env.job_name }} (${{ join(matrix.k8s.*, ', ') }}, ${{ join(matrix.config.*, ', ') }}).xml\" \\\n          --junit-property github_job_step=\"Run connectivity test (${{ matrix.k8s.version }}, ${{ matrix.config.index }}, ${{ matrix.config.type }})\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} (${{ join(matrix.k8s.*, ', ') }}, ${{ join(matrix.config.*, ', ') }})\"\n          job_status: \"${{ job.status }}\"\n\n      - name: Clean up ESP allow firewall rule\n        if: ${{ always() && matrix.config.type == 'tunnel-ipsec' }}\n        uses: ./.github/actions/gke-clean-esp-rule\n        with:\n          cluster_name: ${{ env.clusterName }}-${{ matrix.config.index }}\n          cluster_zone: ${{ matrix.k8s.zone }}\n\n      - name: Clean up GKE\n        if: ${{ always() }}\n        run: |\n          while [ \"$(gcloud container operations list --zone ${{ matrix.k8s.zone }} --filter=\"status=RUNNING AND targetLink~${{ env.clusterName }}-${{ matrix.config.index }}\" --format=\"value(name)\")\" ];do\n            echo \"cluster has an ongoing operation, waiting for all operations to finish\"; sleep 15\n          done\n          gcloud container clusters delete ${{ env.clusterName }}-${{ matrix.config.index }} --zone ${{ matrix.k8s.zone }} --quiet --async\n        shell: bash {0} # Disable default fail-fast behavior so that all commands run independently\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-connectivity\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.installation-and-connectivity.result }}\n"
						}
					},
					{
						"name": "conformance-ingress.yaml",
						"object": {
							"text": "name: Conformance Ingress (ci-ingress)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  kind_config: .github/kind-config.yaml\n  timeout: 5m\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci\n\n  ingress-conformance-test:\n    name: Ingress Conformance Test\n    env:\n      job_name: \"Ingress Conformance Test\"\n    needs: [wait-for-images]\n    runs-on: ubuntu-24.04\n    timeout-minutes: 120\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - name: Without_XDP\n          kube-proxy-replacement: true\n          bpf-lb-acceleration: disabled\n          loadbalancer-mode: dedicated\n          default-ingress-controller: false\n        - name: With_XDP\n          kube-proxy-replacement: true\n          bpf-lb-acceleration: native\n          loadbalancer-mode: dedicated\n          default-ingress-controller: false\n        - name: With_Shared_LB\n          kube-proxy-replacement: true\n          bpf-lb-acceleration: disabled\n          loadbalancer-mode: shared\n          default-ingress-controller: false\n        - name: With_Default_Ingress_Controller\n          kube-proxy-replacement: true\n          bpf-lb-acceleration: disabled\n          loadbalancer-mode: dedicated\n          default-ingress-controller: true\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Set image tag\n        id: vars\n        run: |\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set kubeProxyReplacement=${{ matrix.kube-proxy-replacement }} \\\n            --helm-set=ingressController.enabled=true \\\n            --helm-set=ingressController.loadbalancerMode=${{ matrix.loadbalancer-mode }} \\\n            --helm-set=ingressController.default=${{ matrix.default-ingress-controller }} \\\n            --helm-set=extraConfig.bpf-lb-acceleration=${{ matrix.bpf-lb-acceleration }} \\\n            --helm-set=l2announcements.enabled=true\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n            examples\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.kind_config }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Checkout ingress-controller-conformance\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          # Use the forked repo with retry mechanism\n          # Please refer to https://github.com/kubernetes-sigs/ingress-controller-conformance/pull/101 for more details.\n          repository: cilium/ingress-controller-conformance\n          path: ingress-controller-conformance\n          ref: 6a193b3f73d8b1201a818bb7c8f204059b064857\n          persist-credentials: false\n\n      - name: Install Ingress conformance test tool\n        timeout-minutes: 10\n        run: |\n          cd ingress-controller-conformance\n          make build\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl get pods -n kube-system\n\n      - name: Install Cilium LB IPPool and L2 Announcement Policy\n        timeout-minutes: 10\n        run: |\n          KIND_NET_CIDR=$(docker network inspect kind -f '{{json .IPAM.Config}}' | jq -r '.[] | select(.Subnet | test(\"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+\\\\.[0-9]+\")) | .Subnet')\n          echo \"KIND_NET_CIDR: $KIND_NET_CIDR\"\n          LB_CIDR=$(echo ${KIND_NET_CIDR} | sed \"s@0.0/16@255.200/28@\")\n          echo \"LB_CIDR: $LB_CIDR\"\n          echo \"Deploying LB-IPAM Pool...\"\n          cat << EOF > pool.yaml\n          apiVersion: \"cilium.io/v2\"\n          kind: CiliumLoadBalancerIPPool\n          metadata:\n            name: \"pool\"\n          spec:\n            blocks:\n              - cidr: \"$LB_CIDR\"\n          EOF\n          cat pool.yaml\n          kubectl apply -f pool.yaml\n\n          echo \"Deploying L2-Announcement Policy...\"\n          cat << 'EOF' > l2policy.yaml\n          apiVersion: \"cilium.io/v2alpha1\"\n          kind: CiliumL2AnnouncementPolicy\n          metadata:\n            name: l2policy\n          spec:\n            loadBalancerIPs: true\n            interfaces:\n              - eth0\n            nodeSelector:\n              matchExpressions:\n                - key: node-role.kubernetes.io/control-plane\n                  operator: DoesNotExist\n          EOF\n          cat l2policy.yaml\n          kubectl apply -f l2policy.yaml\n\n      - name: Create sample workload\n        timeout-minutes: 5\n        run: |\n          kubectl apply -n default -f https://raw.githubusercontent.com/istio/istio/release-1.11/samples/bookinfo/platform/kube/bookinfo.yaml\n          if [ \"${{ matrix.default-ingress-controller }}\" = \"true\" ]; then\n            # remove ingressClassName line from basic-ingress.yaml\n            sed -i '/ingressClassName/d' untrusted/examples/kubernetes/servicemesh/basic-ingress.yaml\n            kubectl apply -n default -f untrusted/examples/kubernetes/servicemesh/basic-ingress.yaml\n            kubectl wait -n default --for=condition=Ready --all pod --timeout=${{ env.timeout }}\n          fi\n\n          kubectl apply -n default -f untrusted/examples/kubernetes/servicemesh/basic-ingress.yaml\n          kubectl wait -n default --for=condition=Ready --all pod --timeout=${{ env.timeout }}\n\n      - name: Run Sanity check (external)\n        timeout-minutes: 5\n        run: |\n          lb=$(kubectl get ingress basic-ingress -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n          curl -s -v --connect-timeout 5 --max-time 20 --retry 3 --retry-all-errors --retry-delay 5 --fail -- http://\"$lb\"\n\n          # By now the service should be up, no need to do the manual retries for the second request\n          curl -s -v --connect-timeout 5 --max-time 20 --retry 3 --fail -- http://\"$lb\"/details/1\n\n      - name: Run Sanity check (internal to NodePort)\n        if: ${{ matrix.kube-proxy-replacement == true }}\n        timeout-minutes: 5\n        run: |\n          if [ \"${{ matrix.loadbalancer-mode }}\" = \"dedicated\" ]; then\n            node_port=$(kubectl get svc cilium-ingress-basic-ingress -o jsonpath='{.spec.ports[?(@.port==80)].nodePort}')\n          else\n            node_port=$(kubectl get -n kube-system svc cilium-ingress -o jsonpath='{.spec.ports[?(@.port==80)].nodePort}')\n          fi\n          docker exec -i chart-testing-control-plane curl -s -v --connect-timeout 5 --max-time 20 --retry 3 --fail http://localhost:$node_port/details/1\n\n      - name: Run Sanity check (headless service)\n        timeout-minutes: 5\n        run: |\n          BACKEND_IP=$(kubectl get pod -l app=details -o jsonpath=\"{.items[*].status.podIP}\")\n          cat << EOF > ingress-with-headless-service.yaml\n          apiVersion: v1\n          kind: Endpoints\n          metadata:\n            name: details-headless\n          subsets:\n          - addresses:\n            - ip: ${BACKEND_IP}\n            ports:\n            - name: http\n              port: 9080\n              protocol: TCP\n          ---\n          apiVersion: v1\n          kind: Service\n          metadata:\n            name: details-headless\n          spec:\n            ports:\n            - name: http\n              port: 9080\n              protocol: TCP\n              targetPort: 9080\n            clusterIP: None\n            ipFamilies:\n            - IPv4\n            ipFamilyPolicy: SingleStack\n          ---\n          apiVersion: discovery.k8s.io/v1\n          kind: EndpointSlice\n          metadata:\n            name: details-headless-endpoint-slice\n            labels:\n              kubernetes.io/service-name: details-headless-endpoint-slice\n          addressType: IPv4\n          endpoints:\n            - addresses:\n                - ${BACKEND_IP}\n          ports:\n            - name: http\n              port: 9080\n              protocol: TCP\n          ---\n          apiVersion: v1\n          kind: Service\n          metadata:\n            name: details-headless-endpoint-slice\n          spec:\n            ports:\n              - name: http\n                port: 9082\n                protocol: TCP\n                targetPort: 9080\n            clusterIP: None\n            ipFamilies:\n              - IPv4\n            ipFamilyPolicy: SingleStack\n          ---\n          apiVersion: networking.k8s.io/v1\n          kind: Ingress\n          metadata:\n            name: basic-ingress-headless\n          spec:\n            ingressClassName: cilium\n            rules:\n            - http:\n                paths:\n                - backend:\n                    service:\n                      name: details-headless\n                      port:\n                        number: 9080\n                  path: /details/1\n                  pathType: Prefix\n                - backend:\n                    service:\n                      name: details-headless-endpoint-slice\n                      port:\n                        number: 9082\n                  path: /details/2\n                  pathType: Prefix\n          EOF\n          kubectl apply -n default -f ingress-with-headless-service.yaml\n          until [ -n \"$(kubectl get ingress basic-ingress-headless -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\" ]; do\n            sleep 3\n          done\n          lb=$(kubectl get ingress basic-ingress-headless -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n          curl -s -v --connect-timeout 2 --max-time 20 --retry 3 --retry-all-errors --retry-delay 3 --fail -- http://\"$lb\"/details/1\n          curl -s -v --connect-timeout 2 --max-time 20 --retry 3 --retry-all-errors --retry-delay 3 --fail -- http://\"$lb\"/details/2\n\n      - name: Cleanup Sanity check\n        timeout-minutes: 5\n        run: |\n          # Clean up after sanity check to avoid any conflicts with the conformance test\n          kubectl delete -n default -f untrusted/examples/kubernetes/servicemesh/basic-ingress.yaml\n          kubectl delete -n default -f ingress-with-headless-service.yaml\n          kubectl delete -n default -f https://raw.githubusercontent.com/istio/istio/release-1.11/samples/bookinfo/platform/kube/bookinfo.yaml\n          kubectl wait ingress basic-ingress --for=delete\n          kubectl wait ingress basic-ingress-headless --for=delete\n\n      - name: Run Ingress conformance test\n        timeout-minutes: 30\n        run: |\n          cd ingress-controller-conformance\n          ./ingress-controller-conformance \\\n            -ingress-class cilium \\\n            -wait-time-for-ingress-status 60s \\\n            -wait-time-for-ready 60s \\\n            -http-client-timeout 60s \\\n            -enable-http-debug \\\n            -stop-on-failure\n\n      - name: Run basic CLI tests\n        shell: bash\n        run: |\n          cilium connectivity test --include-unsafe-tests --collect-sysdump-on-failure \\\n            --log-code-owners --code-owners=${CILIUM_CLI_CODE_OWNERS_PATHS} \\\n            --exclude-code-owners=${CILIUM_CLI_EXCLUDE_OWNERS} \\\n            --sysdump-hubble-flows-count=1000000 --sysdump-hubble-flows-timeout=5m \\\n            --sysdump-output-filename \"cilium-sysdump-${{ matrix.name }}-<ts>\" \\\n            --test 'packet-drops'\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} ${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: ingress-conformance-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.ingress-conformance-test.result }}\n"
						}
					},
					{
						"name": "conformance-ipsec-e2e.yaml",
						"object": {
							"text": "name: Conformance IPsec E2E (ci-ipsec-e2e)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 5/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  test_concurrency: 5\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.generate-matrix.outputs.matrix }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/e2e\"\n          destination_directory=\"/tmp/generated/ipsec\"\n          mkdir -p \"${destination_directory}\"\n\n          yq -o=json \"${work_dir}/ipsec_configs.yaml\" | jq . > \"${destination_directory}/matrix.json\"\n\n      - name: Generate Matrix\n        id: generate-matrix\n        run: |\n          cd /tmp/generated/ipsec\n          echo \"Generated matrix:\"\n          cat /tmp/generated/ipsec/matrix.json\n          echo \"matrix=$(jq -c . < /tmp/generated/ipsec/matrix.json)\" >> $GITHUB_OUTPUT\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  setup-and-test:\n    needs: [wait-for-images, generate-matrix]\n    name: 'Setup & Test'\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    env:\n      job_name: 'Setup & Test'\n    strategy:\n      fail-fast: false\n      max-parallel: 100\n      matrix:\n        include: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}\n\n    timeout-minutes: 75\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          include-unsafe-tests: true\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n          echo sha=${SHA} >> $GITHUB_OUTPUT\n\n      - name: Derive Cilium installation config and junit type\n        id: cilium-config\n        uses: ./.github/actions/cilium-config\n        with:\n          image-tag: ${{ steps.vars.outputs.sha }}\n          chart-dir: './untrusted/install/kubernetes/cilium'\n          tunnel: ${{ matrix.tunnel }}\n          devices: ${{ matrix.devices }}\n          endpoint-routes: ${{ matrix.endpoint-routes }}\n          ipv4: ${{ matrix.ipv4 }}\n          ipv6: ${{ matrix.ipv6 }}\n          underlay: ${{ matrix.underlay }}\n          kpr: ${{ matrix.kpr }}\n          lb-mode: ${{ matrix.lb-mode }}\n          lb-acceleration: ${{ matrix.lb-acceleration }}\n          encryption: 'ipsec'\n          encryption-node: ${{ matrix.encryption-node }}\n          egress-gateway: ${{ matrix.egress-gateway }}\n          host-fw: ${{ matrix.host-fw }}\n          ingress-controller: ${{ matrix.ingress-controller }}\n          mutual-auth: false\n          misc: ${{ matrix.misc }}\n\n      - name: Set Kind params\n        id: kind-params\n        shell: bash\n        run: |\n          IP_FAM=\"dual\"\n          if [ \"${{ matrix.ipv6 }}\" == \"false\" ]; then\n            IP_FAM=\"ipv4\"\n          fi\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            IP_FAM=\"ipv6\"\n          fi\n          echo params=\"--xdp --secondary-network \\\"\\\" 3 \\\"\\\" \\\"\\\" ${{ matrix.kube-proxy }} $IP_FAM\" >> $GITHUB_OUTPUT\n\n      - name: Provision K8s on LVH VM\n        id: lvh-kind\n        uses: ./.github/actions/lvh-kind\n        with:\n          test-name: e2e-conformance\n          kernel: ${{ matrix.kernel }}\n          kind-params: \"${{ steps.kind-params.outputs.params }}\"\n          kind-image: ${{ env.KIND_K8S_IMAGE }}\n\n      - name: Set up job variables for connectivity tests\n        id: vars-conn\n        run: |\n          EXTRA_CLI_FLAGS=(\n            \"--external-target=${{ steps.lvh-kind.outputs.external_target_name }}\"\n            \"--external-other-target=${{ steps.lvh-kind.outputs.other_external_target_name }}\"\n            \"--external-cidr=${{ steps.lvh-kind.outputs.ipv4_external_cidr }}\"\n            \"--external-cidrv6=${{ steps.lvh-kind.outputs.ipv6_external_cidr }}\"\n            \"--external-ip=${{ steps.lvh-kind.outputs.ipv4_external_target }}\"\n            \"--external-ipv6=${{ steps.lvh-kind.outputs.ipv6_external_target }}\"\n            \"--external-other-ip=${{ steps.lvh-kind.outputs.ipv4_other_external_target }}\"\n            \"--external-other-ipv6=${{ steps.lvh-kind.outputs.ipv6_other_external_target }}\"\n            \"--external-target-ca-namespace=external-target-secrets\"\n            \"--external-target-ca-name=custom-ca\"\n            \"--external-target-ipv6-capable\"\n          )\n          if [ \"${{ matrix.secondary-network }}\" = \"true\" ]; then\n            EXTRA_CLI_FLAGS+=(\"--secondary-network-iface=eth1\")\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }} \\\n                                      --sysdump-hubble-flows-count=1000000 \\\n                                      --sysdump-hubble-flows-timeout=5m \\\n                                      --flush-ct \\\n                                      ${EXTRA_CLI_FLAGS[*]@Q}\"\n\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo \"test default: ${CONNECTIVITY_TEST_DEFAULTS}\"\n\n      - name: Setup bootid file\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            set -ex\n            for container in \\$(docker ps -q); do\n              docker exec \\$container mkdir -p /var/run/cilium/\n              docker exec \\$container sh -c 'cat /proc/sys/kernel/random/uuid > /var/run/cilium/boot_id'\n            done\n\n      - name: Start Cilium KVStore\n        id: kvstore\n        if: matrix.kvstore == 'true'\n        run: |\n          make kind-kvstore-start KVSTORE_POD_NAME=kvstore KVSTORE_POD_PORT=2378\n\n          IP=$(kubectl --namespace kube-system get pod kvstore -o jsonpath='{.status.hostIP}')\n          echo \"config= \\\n            --set=etcd.enabled=true \\\n            --set=identityAllocationMode=kvstore \\\n            --set=etcd.endpoints[0]=http://${IP}:2378 \\\n          \" >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium\n        shell: bash\n        run: |\n          kubectl patch node kind-worker3 --type=json -p='[{\"op\":\"add\",\"path\":\"/metadata/labels/cilium.io~1no-schedule\",\"value\":\"true\"}]'\n\n          cilium encrypt create-key --auth-algo ${{ matrix.key-one }}\n\n          cilium install ${{ steps.cilium-config.outputs.config }} ${{ steps.kvstore.outputs.config }} --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n\n          cilium status --wait --interactive=false\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Prepare the bpftrace parameters\n        id: bpftrace-params\n        run: |\n          CILIUM_INTERNAL_IPS=$(kubectl get ciliumnode -o jsonpath='{.items[*].spec.addresses[?(@.type==\"CiliumInternalIP\")].ip}')\n          if [[ \"${{ matrix.ipv6 }}\" == \"false\" ]]; then\n            CILIUM_INTERNAL_IPS=\"${CILIUM_INTERNAL_IPS// / ::1 } ::1\"\n          fi\n          if [[ \"${{ matrix.ipv4 }}\" == \"false\" ]]; then\n            CILIUM_INTERNAL_IPS=\"0.0.0.1 ${CILIUM_INTERNAL_IPS// / 0.0.0.1 }\"\n          fi\n\n          echo \"params=$CILIUM_INTERNAL_IPS\" >> $GITHUB_OUTPUT\n\n      - name: Start unencrypted packets check\n        uses: ./.github/actions/bpftrace/start\n        with:\n          # Only check for DNS proxy traffic if IPv4 is enabled.\n          # If it isn't, we will skip the proxy tests and won't have any such traffic.\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"${{ matrix.ipv4 != 'false' }}\" \"ipsec\"\n\n      - name: Run sequential tests (${{ join(matrix.*, ', ') }})\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n\n          TEST='\"seq-.*\"'\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            TEST='\"seq-.*,!pod-to-world.*\"'\n          fi\n\n          cilium connectivity test ${{ steps.vars-conn.outputs.connectivity_test_defaults }} \\\n            --sysdump-output-filename \"cilium-sysdump-${{ matrix.name }}-<ts>\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }}-sequential-pre-rotate (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests (${{ join(matrix.*, ', ') }})\" \\\n            --test $TEST\n\n      - name: Run concurrent tests (${{ join(matrix.*, ', ') }})\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n\n          TEST='\"!seq-.*\"'\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            TEST='\"!(seq-.*|pod-to-world.*|pod-to-cidr)\"'\n          fi\n\n          cilium connectivity test ${{ steps.vars-conn.outputs.connectivity_test_defaults }} \\\n            --sysdump-output-filename \"cilium-sysdump-${{ matrix.name }}-<ts>\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }}-concurrent-pre-rotate (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests (${{ join(matrix.*, ', ') }})\" \\\n            --test $TEST \\\n            --test-concurrency=${{ env.test_concurrency }}\n\n      - name: Features tested\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }})\"\n\n      - name: Assert that no unencrypted packets are leaked\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Start unencrypted packets check for key rotation\n        uses: ./.github/actions/bpftrace/start\n        with:\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          # As we are not testing with proxy connections during key rotation,\n          # disable the check for proxy traffic.\n          args: ${{ steps.bpftrace-params.outputs.params }} \"false\" \"ipsec\"\n\n      - name: Setup conn-disrupt-test before rotating (${{ join(matrix.*, ', ') }})\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Rotate IPsec Key (${{ join(matrix.*, ', ') }})\n        uses: ./.github/actions/ipsec-key-rotate\n        with:\n          key-algo: ${{ matrix.key-two }}\n\n      - name: Assert that no unencrypted packets are leaked during key rotation\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Check conn-disrupt-test after rotating (${{ join(matrix.*, ', ') }})\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: ${{ env.job_name }}-${{ matrix.name }}-post-rotate\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Start unencrypted packets check for tests\n        uses: ./.github/actions/bpftrace/start\n        with:\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"${{ matrix.ipv4 != 'false' }}\" \"ipsec\"\n\n      - name: Run sequential tests (${{ join(matrix.*, ', ') }})\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n\n          TEST='\"seq-.*\"'\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            TEST='\"seq-.*,!pod-to-world.*\"'\n          fi\n\n          cilium connectivity test ${{ steps.vars-conn.outputs.connectivity_test_defaults }} \\\n            --sysdump-output-filename \"cilium-sysdump-${{ matrix.name }}-<ts>\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }}-sequential-post-rotate (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests (${{ join(matrix.*, ', ') }})\" \\\n            --test $TEST\n\n      - name: Run concurrent tests (${{ join(matrix.*, ', ') }})\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n\n          TEST='\"!seq-.*\"'\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            TEST='\"!(seq-.*|pod-to-world.*|pod-to-cidr)\"'\n          fi\n\n          cilium connectivity test ${{ steps.vars-conn.outputs.connectivity_test_defaults }} \\\n            --sysdump-output-filename \"cilium-sysdump-${{ matrix.name }}-<ts>\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }}-concurrent-post-rotate (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests (${{ join(matrix.*, ', ') }})\" \\\n            --test $TEST \\\n            --test-concurrency=${{ env.test_concurrency }}\n\n      - name: Features tested\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested after all other tests after rotating ipsec keys\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - after rotating keys\"\n\n      - name: Assert that no unencrypted packets are leaked during tests\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Fetch artifacts\n        if: ${{ !success() }}\n        shell: bash\n        run: |\n          if [ \"${{ matrix.kvstore }}\" == \"true\" ]; then\n            echo\n            echo \"# Retrieving Cilium etcd logs\"\n            kubectl -n kube-system logs kvstore\n          fi\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: setup-and-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "conformance-k8s-network-policies.yaml",
						"object": {
							"text": "name: Cyclonus Network Policy Test\n\non:\n  push:\n    branches:\n      - main\n      - ft/main/**\n    paths-ignore:\n      - 'Documentation/**'\n\npermissions: read-all\n\nenv:\n  KIND_CONFIG: .github/kind-config.yaml\n  CONFORMANCE_TEMPLATE: examples/kubernetes/connectivity-check/connectivity-check.yaml\n  TIMEOUT: 2m\n  LOG_TIME: 30m\n\njobs:\n  preflight-clusterrole:\n    name: Preflight Clusterrole Check\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n      - name: Check pre-flight clusterrole\n        run: |\n          cd install/kubernetes/cilium/templates\n          echo \"Checking for differences between preflight and agent clusterrole\"\n          diff \\\n             -I '^[ ]\\{2\\}name: cilium.*' \\\n             -I '^Keep file in sync with.*' \\\n             -I '^  {{- with .Values.annotations }}$' \\\n             -I '^  {{- with .Values.preflight.annotations }}$' \\\n             -I '{{- if.*' \\\n             cilium-agent/clusterrole.yaml \\\n             cilium-preflight/clusterrole.yaml\n\n  cyclonus-test:\n    name: Cyclonus Test\n    env:\n      job_name: \"Cyclonus Test\"\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout target branch to access local actions\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.base_ref || github.ref }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Precheck generated connectivity manifest files\n        run: |\n          make -C examples/kubernetes/connectivity-check fmt\n          make -C examples/kubernetes/connectivity-check all\n          test -z \"$(git status --porcelain)\" || (echo \"please run 'make -C examples/kubernetes/connectivity-check fmt all' and submit your changes\"; exit 1)\n\n      - name: Set image tag\n        id: vars\n        run: |\n          if [ \"${{ github.event.pull_request.head.sha }}\" != \"\" ]; then\n            echo tag=${{ github.event.pull_request.head.sha }} >> $GITHUB_OUTPUT\n          else\n            echo tag=${{ github.sha }} >> $GITHUB_OUTPUT\n          fi\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci:${{ steps.vars.outputs.tag }} &> /dev/null; do sleep 45s; done\n          until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator-generic-ci:${{ steps.vars.outputs.tag }} &> /dev/null; do sleep 45s; done\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.KIND_CONFIG }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Install cilium chart\n        id: install-cilium\n        run: |\n          HELM_ARGS=\"\\\n            --wait \\\n            --namespace kube-system \\\n            --set debug.enabled=true \\\n            --set debug.verbose=envoy \\\n            --set-string=extraEnv[0].name=CILIUM_FEATURE_METRICS_WITH_DEFAULTS \\\n            --set-string=extraEnv[0].value=true \\\n            --set-string=extraEnv[1].name=CILIUM_INVALID_METRIC_VALUE_DETECTOR \\\n            --set-string=extraEnv[1].value=true \\\n            --set-string=extraEnv[2].name=CILIUM_SLOG_DUP_ATTR_DETECTOR \\\n            --set-string=extraEnv[2].value=true \\\n            --set-string=extraEnv[3].name=KUBE_CACHE_MUTATION_DETECTOR \\\n            --set-string=extraEnv[3].value=true \\\n            --set-string=operator.extraEnv[0].name=CILIUM_FEATURE_METRICS_WITH_DEFAULTS \\\n            --set-string=operator.extraEnv[0].value=true \\\n            --set-string=operator.extraEnv[1].name=CILIUM_INVALID_METRIC_VALUE_DETECTOR \\\n            --set-string=operator.extraEnv[1].value=true \\\n            --set-string=operator.extraEnv[2].name=CILIUM_SLOG_DUP_ATTR_DETECTOR \\\n            --set-string=operator.extraEnv[2].value=true \\\n            --set-string=operator.extraEnv[3].name=KUBE_CACHE_MUTATION_DETECTOR \\\n            --set-string=operator.extraEnv[3].value=true \\\n            --set nodeinit.enabled=true \\\n            --set kubeProxyReplacement=true \\\n            --set bpf.masquerade=false \\\n            --set ipam.mode=kubernetes \\\n            --set image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n            --set image.tag=${{ steps.vars.outputs.tag }} \\\n            --set image.pullPolicy=IfNotPresent \\\n            --set image.useDigest=false \\\n            --set operator.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n            --set operator.image.suffix=-ci \\\n            --set operator.image.tag=${{ steps.vars.outputs.tag }} \\\n            --set operator.image.pullPolicy=IfNotPresent \\\n            --set operator.image.useDigest=false \\\n            --set prometheus.enabled=true \\\n            --set operator.prometheus.enabled=true \\\n            --set hubble.enabled=true \\\n            --set=hubble.metrics.enabled={dns,drop,tcp,flow,port-distribution,icmp,http}\"\n\n          helm install cilium ./install/kubernetes/cilium $HELM_ARGS\n\n          kubectl wait -n kube-system --for=condition=Ready -l app.kubernetes.io/part-of=cilium pod --timeout=5m\n          kubectl rollout -n kube-system status deploy/coredns --timeout=5m\n\n          # To make sure that cilium CRD is available (default timeout is 5m)\n          # https://github.com/cilium/cilium/blob/main/operator/crd.go#L34\n          kubectl wait --for condition=Established crd/ciliumnetworkpolicies.cilium.io --timeout=5m\n\n      - name: Run cyclonus network policy test\n        working-directory: test/k8s/manifests/netpol-cyclonus\n        run: ./test-cyclonus.sh\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.tag }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n          junits-directory: 'test/k8s/manifests/netpol-cyclonus/cyclonus-results'\n"
						}
					},
					{
						"name": "conformance-kind-proxy-embedded.yaml",
						"object": {
							"text": "name: Conformance Kind Envoy Embedded\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request:\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n  push:\n    branches:\n      - main\n      - ft/main/**\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\nenv:\n  kind_config: .github/kind-config-dual.yaml\n\njobs:\n  installation-and-connectivity:\n    name: \"Installation and Connectivity Test\"\n    runs-on: ubuntu-24.04\n    timeout-minutes: 60\n    env:\n      job_name: \"Installation and Connectivity Test\"\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ github.event.pull_request.head.sha || github.sha }}\n\n      - name: Add external docker network\n        uses: ./.github/actions/kind-external-network\n        id: external_network\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.kind_config }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Add external targets to kind cluster\n        uses: ./.github/actions/kind-external-targets\n        id: external_targets\n        with:\n          kind_network: ${{ steps.external_network.outputs.kind_network }}\n          ipv4_external_target: ${{ steps.external_network.outputs.ipv4_external_target }}\n          ipv4_other_external_target: ${{ steps.external_network.outputs.ipv4_other_external_target }}\n          ipv6_external_target: ${{ steps.external_network.outputs.ipv6_external_target }}\n          ipv6_other_external_target: ${{ steps.external_network.outputs.ipv6_other_external_target }}\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n          include-unsafe-tests: true\n          test-concurrency: 5\n          external-cidr: ${{ steps.external_network.outputs.ipv4_external_cidr }}\n          external-cidrv6: ${{ steps.external_network.outputs.ipv6_external_cidr }}\n          external-ip: ${{ steps.external_network.outputs.ipv4_external_target }}\n          external-ipv6: ${{ steps.external_network.outputs.ipv6_external_target }}\n          external-other-ip: ${{ steps.external_network.outputs.ipv4_other_external_target }}\n          external-other-ipv6: ${{ steps.external_network.outputs.ipv6_other_external_target }}\n          external-other-target: ${{ steps.external_targets.outputs.other_external_target_name }}\n          external-target: ${{ steps.external_targets.outputs.external_target_name }}\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          # Note: On Kind, we install Cilium with HostPort (portmap CNI chaining) enabled,\n          # to ensure coverage of that feature in cilium connectivity test\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=hubble.relay.enabled=true\n            --helm-set=cni.chainingMode=portmap \\\n            --helm-set-string=kubeProxyReplacement=true \\\n            --helm-set=loadBalancer.l7.backend=envoy \\\n            --helm-set=tls.readSecretsOnlyFromSecretsNamespace=true \\\n            --helm-set=tls.secretSync.enabled=true \\\n            --helm-set=envoy.enabled=false \\\n            --helm-set=ipv6.enabled=true \\\n            --wait=false\"\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }} \\\n            --external-target-ca-namespace=external-target-secrets --external-target-ca-name=custom-ca \\\n            --external-target-ipv6-capable\"\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo \"test default: ${CONNECTIVITY_TEST_DEFAULTS}\"\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl -n kube-system get pods\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --curl-parallel 3 \\\n            --junit-file \"cilium-junits/${{ env.job_name }}.xml\" --junit-property github_job_step=\"Run connectivity test\"\n\n      - name: Features tested\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested\"\n          json-filename: \"${{ env.job_name }}\"\n\n      - name: Install Cilium with secret sync disabled\n        id: install-cilium-secret-sync-disabled\n        run: |\n          helm upgrade cilium ./install/kubernetes/cilium \\\n            --namespace kube-system \\\n            --reuse-values \\\n            --set=tls.readSecretsOnlyFromSecretsNamespace=false \\\n            --set=tls.secretSync.enabled=false\n\n          kubectl -n kube-system rollout restart ds/cilium deployment/cilium-operator\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl -n kube-system get pods\n\n      - name: Run L7 related connectivity test\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --curl-parallel 3 \\\n            --junit-file \"cilium-junits/${{ env.job_name }}-without-secret-sync.xml\" \\\n            --junit-property github_job_step=\"Run connectivity test with secret sync disabled\" \\\n            --test=\"l7|sni|check-log-errors\"\n\n      - name: Features tested\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested\"\n          json-filename: \"${{ env.job_name }}-without-secret-sync\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n"
						}
					},
					{
						"name": "conformance-kubespray.yaml",
						"object": {
							"text": "name: Conformance Kubespray (ci-kubespray)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - '.github/workflows/conformance-kubespray.yaml'\n  schedule:\n    - cron: '0 0 * * 0'\n\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  clusterName: kubespray-ci-${{ github.run_id }}-${{ github.run_attempt }}\n  KUBESPRAY_SHA: 63cdf87915421dda5955281f38401fd1b55b230b # v2.28.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.event.pull_request.head.sha || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.event.pull_request.head.sha || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.event.pull_request.head.sha || github.sha }}\n          images: cilium-ci operator-generic-ci\n\n  installation-and-connectivity:\n    name: Installation and Connectivity Test\n    runs-on: ubuntu-24.04\n    needs: wait-for-images\n    timeout-minutes: 60\n    env:\n      job_name: \"Installation and Connectivity Test\"\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.event.pull_request.head.sha || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.event.pull_request.head.sha || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Set up Python\n        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0\n        with:\n          python-version: '3.10'\n\n      - name: Checkout Kubespray\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes-sigs/kubespray\n          ref: ${{ env.KUBESPRAY_SHA }}\n          path: kubespray\n          fetch-depth: 1\n          persist-credentials: false\n\n      - name: Setup Kubespray\n        run: |\n          python -m venv kubespray-venv\n          source kubespray-venv/bin/activate\n          cd kubespray\n          pip install -r requirements.txt\n\n      - name: Configure inventory\n        run: |\n          cd kubespray/\n          cp -rfp inventory/sample inventory/mycluster\n\n          cat > inventory/mycluster/inventory.ini << EOF\n          [all]\n          localhost ansible_connection=local\n\n          [kube_control_plane]\n          localhost\n\n          [etcd]\n          localhost\n\n          [kube_node]\n          localhost\n\n          [k8s_cluster:children]\n          kube_control_plane\n          kube_node\n          EOF\n\n      - name: Deploy Kubernetes cluster\n        run: |\n          source kubespray-venv/bin/activate\n          cd kubespray/\n          ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b -v \\\n            -e '{\"container_manager\":\"docker\",\"docker_package_info\":{\"pkgs\":[]}}' \\\n            -e '{\"kube_network_plugin\":\"cni\",\"kube_owner\":\"root\"}'\n\n          mkdir -p $HOME/.kube\n          sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n          sudo chown \"$(id -u)\":\"$(id -g)\" $HOME/.kube/config\n\n          kubectl wait --for=condition=Ready pods --all -n kube-system --timeout=300s\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n          include-unsafe-tests: true\n          test-concurrency: 5\n          tests: '!/pod-to-world'\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cluster.name=${{ env.clusterName }}\"\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium to be ready\n        run: |\n          cilium status --wait --interactive=false --wait-duration=2m\n          kubectl get pods --all-namespaces -o wide\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --junit-file \"cilium-junits/${{ env.job_name }}.xml\" --junit-property github_job_step=\"Run connectivity test\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-connectivity\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.event.pull_request.head.sha || github.sha }}\n      sha: ${{ inputs.SHA || github.event.pull_request.head.sha || github.sha }}\n      result: ${{ needs.installation-and-connectivity.result }}\n"
						}
					},
					{
						"name": "conformance-multi-pool.yaml",
						"object": {
							"text": "name: Conformance Multi Pool IPAM (ci-multi-pool)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - push: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  timeout: 5m\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.generate-matrix.outputs.matrix }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/multi-pool\"\n          destination_directory=\"/tmp/generated/multi-pool\"\n          mkdir -p \"${destination_directory}\"\n\n          yq -o=json \"${work_dir}/configs.yaml\" | jq . > \"${destination_directory}/matrix.json\"\n\n      - name: Generate Matrix\n        id: generate-matrix\n        run: |\n          cd /tmp/generated/multi-pool\n          echo \"Generated matrix:\"\n          cat /tmp/generated/multi-pool/matrix.json\n          echo \"matrix=$(jq -c . < /tmp/generated/multi-pool/matrix.json)\" >> $GITHUB_OUTPUT\n\n  multi-pool-ipam-conformance-test:\n    needs: [wait-for-images, generate-matrix]\n    strategy:\n      fail-fast: false\n      matrix:\n        include: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}\n\n    name: Install and Connectivity Test\n    env:\n      job_name: \"Install and Connectivity Test\"\n    runs-on: ubuntu-24.04\n    timeout-minutes: 120\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n          include-unsafe-tests: true\n          test-concurrency: 5\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            CONTEXT_REF=\"${{ inputs.context-ref }}\"\n            OWNER=\"${{ inputs.PR-number }}\"\n          else\n            CONTEXT_REF=\"${{ github.sha }}\"\n            OWNER=\"${{ github.ref_name }}\"\n            OWNER=\"${OWNER//[.\\/]/-}\"\n          fi\n\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n          echo context-ref=${CONTEXT_REF} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n\n          # Notes:\n          #  - iptables-based masquerading does not support multiple non-masquerade\n          #    CIDRs. Thus, we enable BPF masquerading where we can add multiple\n          #    non-masquerade CIDRs.\n          #  - helm/kind-action does not support BPF host routing, so we fall\n          #    back on legacy host routing\n          #    (https://github.com/cilium/cilium/issues/23283#issuecomment-1597282247)\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=hubble.relay.enabled=true \\\n            --helm-set=kubeProxyReplacement=true \\\n            --helm-set=bpf.masquerade=true \\\n            --helm-set=bpf.hostLegacyRouting=true\\\n            --helm-set=ipMasqAgent.enabled=true \\\n            --helm-set=ipam.mode=multi-pool\"\n\n          if [ \"${{ matrix.endpoint-routes }}\" == \"enabled\" ]; then\n            CILIUM_INSTALL_ROUTES=\"--helm-set=endpointRoutes.enabled=true\"\n          fi\n\n          if [ \"${{ matrix.tunnel }}\" == \"disabled\" ]; then\n            CILIUM_INSTALL_TUNNEL=\"--helm-set-string=routingMode=native \\\n            --helm-set=autoDirectNodeRoutes=true\"\n          fi\n\n          CILIUM_INSTALL_ENCRYPTION=\"\"\n          if [ \"${{ matrix.encryption }}\" != \"disabled\" ]; then\n            CILIUM_INSTALL_ENCRYPTION=\"--helm-set=encryption.enabled=true --helm-set=encryption.type=${{ matrix.encryption }}\"\n          fi\n\n          CILIUM_INSTALL_MULTIPOOL_IPAM=\"--helm-set=ipMasqAgent.config.nonMasqueradeCIDRs='{10.0.0.0/8,192.168.0.0/16,fd00::/104}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv4.cidrs='{10.10.0.0/16}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv4.maskSize=24 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.cilium-test-pool.ipv4.cidrs='{10.20.0.0/16}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.cilium-test-pool.ipv4.maskSize=24 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.client-pool.ipv4.cidrs='{192.168.0.0/20}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.client-pool.ipv4.maskSize=27 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.echo-other-node-pool.ipv4.cidrs='{192.168.16.0/20}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.echo-other-node-pool.ipv4.maskSize=27 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv6.cidrs='{fd00::/120}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.default.ipv6.maskSize=122 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.cilium-test-pool.ipv6.cidrs='{fd00::100/120}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.cilium-test-pool.ipv6.maskSize=122 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.client-pool.ipv6.cidrs='{fd00::200/120}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.client-pool.ipv6.maskSize=122 \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.echo-other-node-pool.ipv6.cidrs='{fd00::300/120}' \\\n            --helm-set=ipam.operator.autoCreateCiliumPodIPPools.echo-other-node-pool.ipv6.maskSize=122\"\n          CILIUM_INSTALL_IPFAMILY=\"--helm-set=ipv4.enabled=true --helm-set=ipv6.enabled=true\"\n          KIND_SVC_CIDR=\"10.243.0.0/16,fd00:10:243::/112\"\n\n          CONNECTIVITY_TEST_DEFAULTS=\" ${{ steps.e2e_config.outputs.test_flags }} \\\n            --sysdump-output-filename \\\"cilium-sysdump-${{ matrix.name }}-<ts>\\\" \\\n            --junit-file \\\"cilium-junits/${{ env.job_name }} ${{ matrix.name }}.xml\\\" \\\n            --junit-property github_job_step=\\\"Run tests ${{ matrix.name }}\\\" \\\n            --namespace-annotations=ipam.cilium.io/ip-pool=cilium-test-pool \\\n            --deployment-pod-annotations='{ \\\n                \\\"client\\\":{\\\"ipam.cilium.io/ip-pool\\\":\\\"client-pool\\\"}, \\\n                \\\"echo-other-node\\\":{\\\"ipam.cilium.io/ip-pool\\\":\\\"echo-other-node-pool\\\"} \\\n            }'\"\n\n          echo cilium_install_defaults=\"${CILIUM_INSTALL_DEFAULTS} ${CILIUM_INSTALL_IPFAMILY} ${CILIUM_INSTALL_ROUTES} ${CILIUM_INSTALL_TUNNEL} ${CILIUM_INSTALL_ENCRYPTION} ${CILIUM_INSTALL_MULTIPOOL_IPAM}\" >> $GITHUB_OUTPUT\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n\n          echo kind_svc_cidr=${KIND_SVC_CIDR} >> $GITHUB_OUTPUT\n\n      - name: Generate Kind configuration files\n        run: |\n          SVCCIDR=${{ steps.vars.outputs.kind_svc_cidr }} \\\n            IPFAMILY=dual \\\n            KUBEPROXYMODE=none \\\n            envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-multi-pool.yaml\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ./.github/kind-config-multi-pool.yaml\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Start Cilium KVStore\n        id: kvstore\n        if: matrix.kvstore == 'true'\n        run: |\n          make kind-kvstore-start KVSTORE_POD_NAME=kvstore KVSTORE_POD_PORT=2378\n\n          IP=$(kubectl --namespace kube-system get pod kvstore -o jsonpath='{.status.hostIP}')\n          echo config=\"--set=etcd.enabled=true --set=identityAllocationMode=kvstore --set=etcd.endpoints[0]=http://${IP}:2378\" >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      # Make sure that coredns uses IPv4-only upstream DNS servers also in case of clusters\n      # with IP family dual, since IPv6 ones are not reachable and cause spurious failures.\n      # Additionally, this is also required to workaround\n      # https://github.com/cilium/cilium/issues/23283#issuecomment-1597282247.\n      - name: Configure the coredns nameservers\n        run: |\n          COREDNS_PATCH=\"\n          spec:\n            template:\n              spec:\n                dnsPolicy: None\n                dnsConfig:\n                  nameservers:\n                  - 8.8.4.4\n                  - 8.8.8.8\n          \"\n\n          kubectl -n kube-system get configmap coredns -o yaml | \\\n            sed '/loadbalance/a \\        log' | kubectl replace -f -\n\n          kubectl patch deployment -n kube-system coredns --patch=\"$COREDNS_PATCH\"\n\n      - name: Create the IPSec secret\n        if: matrix.encryption == 'ipsec'\n        run: |\n          SECRET=\"3+ rfc4106(gcm(aes)) $(openssl rand -hex 20) 128\"\n          kubectl create -n kube-system secret generic cilium-ipsec-keys --from-literal=keys=\"${SECRET}\"\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }} ${{ steps.kvstore.outputs.config }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl -n kube-system get pods\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test\n        run: |\n          cilium connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }}\n\n      - name: Collect Pod and Pool IPs\n        id: ips\n        run: |\n          for pod in client client2 echo-same-node echo-other-node; do\n            kubectl get pod -A -l \"name=${pod}\" -o jsonpath=\"${pod}={.items[*].status.podIP}{'\\n'}\" >> \"$GITHUB_OUTPUT\"\n          done\n\n          for pool in cilium-test-pool client-pool echo-other-node-pool; do\n            kubectl get ciliumpodippool \"${pool}\" -o \"jsonpath=${pool}={.spec.ipv4.cidrs[0]}{'\\n'}\" >> \"$GITHUB_OUTPUT\"\n          done\n\n      - name: Validate Pod IPs\n        shell: python\n        run: |\n          from ipaddress import ip_address, ip_network\n\n          for ip in \"${{ steps.ips.outputs.client }}\".split():\n            assert ip_address(ip) in ip_network(\"${{ steps.ips.outputs.client-pool }}\"), \"client pool mismatch\"\n\n          for ip in \"${{ steps.ips.outputs.client2 }}\".split():\n            assert ip_address(ip) in ip_network(\"${{ steps.ips.outputs.cilium-test-pool }}\"), \"client2 pool mismatch\"\n\n          for ip in \"${{ steps.ips.outputs.echo-same-node }}\".split():\n            assert ip_address(ip) in ip_network(\"${{ steps.ips.outputs.cilium-test-pool }}\"), \"echo-same-node pool mismatch\"\n\n          for ip in \"${{ steps.ips.outputs.echo-other-node }}\".split():\n            assert ip_address(ip) in ip_network(\"${{ steps.ips.outputs.echo-other-node-pool }}\"), \"echo-other-node pool mismatch\"\n\n      - name: Fetch artifacts\n        if: ${{ !success() }}\n        shell: bash\n        run: |\n          if [ \"${{ matrix.kvstore }}\" == \"true\" ]; then\n            echo\n            echo \"# Retrieving Cilium etcd logs\"\n            kubectl -n kube-system logs kvstore\n          fi\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }} ${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: multi-pool-ipam-conformance-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.multi-pool-ipam-conformance-test.result }}\n"
						}
					},
					{
						"name": "conformance-runtime.yaml",
						"object": {
							"text": "name: Conformance Runtime (ci-runtime)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 3/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go-version: 1.25.1\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  # Pre-build the ginkgo binary so that we don't have to build it for all\n  # runners.\n  build-ginkgo-binary:\n    runs-on: ubuntu-24.04\n    name: Build Ginkgo Runtime\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          echo \"sha=${SHA}\" >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n\n      # If any of these steps are modified, please update the copy of these\n      # steps further down under the 'setup-and-test' jobs.\n\n      # Load Ginkgo build from GitHub\n      - name: Load ginkgo runtime from GH cache\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: cache\n        with:\n          path: /tmp/.ginkgo-build/\n          key: ${{ runner.os }}-ginkgo-runtime-${{ hashFiles('**/*.go') }}\n\n      - name: Install Go\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Build Ginkgo\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          go install github.com/onsi/ginkgo/ginkgo@v1.16.5\n          mkdir -p /tmp/.ginkgo-build\n\n      - name: Build Test\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd test\n          /home/runner/go/bin/ginkgo build\n          strip test.test\n          tar -cz test.test -f test.tgz\n\n      - name: Store Ginkgo Test in GitHub cache path\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.ginkgo-build/\n          if [ -f test/test.tgz ]; then\n            cp test/test.tgz /tmp/.ginkgo-build/\n            echo \"file copied\"\n          fi\n\n      - name: Waiting for images\n        timeout-minutes: 20\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n  setup-and-test:\n    needs: build-ginkgo-binary\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    name: \"Runtime Test (${{matrix.focus}})\"\n    env:\n      # GitHub doesn't provide a way to retrieve the name of a job, so we have\n      # to repeated it here.\n      job_name: \"Runtime Test (${{matrix.focus}})\"\n    strategy:\n      fail-fast: false\n      max-parallel: 3\n      matrix:\n        focus:\n          - \"agent\"\n          - \"datapath\"\n          - \"privileged\"\n\n        include:\n          ###\n          # RuntimeAgentFQDNPolicies Can update L7 DNS policy rules\n          # RuntimeAgentFQDNPolicies DNS proxy policy works if Cilium stops\n          # RuntimeAgentFQDNPolicies Interaction with other ToCIDR rules\n          # RuntimeAgentFQDNPolicies toFQDNs populates toCIDRSet (data from proxy) Policy addition after DNS lookup\n          # RuntimeAgentFQDNPolicies Validate dns-proxy monitor information\n          # RuntimeAgentPolicies Init Policy Default Drop Test tests egress\n          # RuntimeAgentPolicies Init Policy Default Drop Test tests ingress\n          # RuntimeAgentPolicies Init Policy Default Drop Test With PolicyAuditMode tests egress\n          # RuntimeAgentPolicies Init Policy Default Drop Test With PolicyAuditMode tests ingress\n          # RuntimeAgentPolicies Init Policy Test Init Egress Policy Test\n          # RuntimeAgentPolicies Init Policy Test Init Ingress Policy Test\n          # RuntimeAgentPolicies TestsEgressToHost Tests Egress To Host\n          # RuntimeAgentPolicies TestsEgressToHost Tests egress with CIDR+L4 policy\n          # RuntimeAgentPolicies TestsEgressToHost Tests egress with CIDR+L4 policy to external https service\n          # RuntimeAgentPolicies TestsEgressToHost Tests egress with CIDR+L7 policy\n          # RuntimeAgentPolicies Tests Endpoint Connectivity Functions After Daemon Configuration Is Updated\n          # RuntimeAgentPolicies Tests EntityNone as a deny-all\n          - focus: \"agent\"\n            cliFocus: \"RuntimeAgent\"\n            # TODO: not updated by by renovate, investigate why the tests fail on newer images\n            lvhImage: \"6.12-20241218.004849\"\n\n          ###\n          # RuntimeDatapathMonitorTest With Sample Containers checks container ids match monitor output\n          # RuntimeDatapathMonitorTest With Sample Containers cilium-dbg monitor check --from\n          # RuntimeDatapathMonitorTest With Sample Containers cilium-dbg monitor check --related-to\n          # RuntimeDatapathMonitorTest With Sample Containers cilium-dbg monitor check --to\n          # RuntimeDatapathMonitorTest With Sample Containers Cilium monitor event types\n          # RuntimeDatapathMonitorTest With Sample Containers delivers the same information to multiple monitors\n          - focus: \"datapath\"\n            cliFocus: \"RuntimeDatapathMonitorTest\"\n            # TODO: not updated by by renovate, investigate why the tests fail on newer images\n            lvhImage: \"6.12-20241218.004849\"\n\n          - focus: \"privileged\"\n            # renovate: datasource=docker depName=quay.io/lvh-images/kind\n            lvhImage: \"6.12-20250807.134150\"\n\n    timeout-minutes: 50\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          echo \"sha=${SHA}\" >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n\n      - name: Provision LVH VMs\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          test-name: runtime-tests\n          install-dependencies: true\n          image-version: \"${{ matrix.lvhImage }}\"\n          host-mount: ./\n          images-folder-parent: \"/tmp\"\n          cpu: 4\n          # renovate: datasource=github-tags depName=cilium/little-vm-helper\n          lvh-version: \"v0.0.26\"\n          mem: 14G\n\n      # Load Ginkgo build from GitHub\n      - name: Load ${{ matrix.focus }} Ginkgo build from GitHub\n        uses: actions/cache/restore@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: cache\n        with:\n          path: /tmp/.ginkgo-build/\n          key: ${{ runner.os }}-ginkgo-runtime-${{ hashFiles('**/*.go') }}\n\n      - name: Install Go\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Build Ginkgo\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          go install github.com/onsi/ginkgo/ginkgo@v1.16.5\n          mkdir -p /tmp/.ginkgo-build\n\n      - name: Build Test\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd test\n          /home/runner/go/bin/ginkgo build\n          strip test.test\n          tar -cz test.test -f test.tgz\n\n      - name: Store Ginkgo Test in GitHub cache path\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.ginkgo-build/\n          if [ -f test/test.tgz ]; then\n            cp test/test.tgz /tmp/.ginkgo-build/\n            echo \"file copied\"\n          fi\n\n      - name: Copy Ginkgo binary\n        shell: bash\n        run: |\n          cd test/\n          tar -xf /tmp/.ginkgo-build/test.tgz\n\n      # Load Golang cache build from GitHub\n      - name: Load Golang cache build from GitHub\n        if: ${{ matrix.focus == 'privileged' }}\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-unit-tests-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-unit-tests-cache-\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' && matrix.focus == 'privileged' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/go/.cache/go-build\n          mkdir -p /tmp/.cache/go/pkg\n\n      - name: Move Go cache to local directories\n        if: ${{ steps.go-cache.outputs.cache-hit == 'true' && matrix.focus == 'privileged' }}\n        env:\n          GOCACHE: \"/tmp/.cache/go/.cache/go-build\"\n          GOMODCACHE: \"/tmp/.cache/go/pkg\"\n        run: |\n          mv \"${GOCACHE}/go-build-cache.tar.zst\" ./go-build-cache.tar.zst || true\n          mv \"${GOMODCACHE}/go-mod-cache.tar.zst\" ./go-mod-cache.tar.zst || true\n\n      - name: Setup runtime\n        timeout-minutes: 10\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            mkdir -p /root/go/src/github.com/cilium/\n            ln -s /host /root/go/src/github.com/cilium/cilium\n            mkdir -p /home/root/go/src/github.com/cilium/\n            ln -s /host /home/root/go/src/github.com/cilium/cilium\n            cp -r /host/test/provision /tmp\n            git config --global --add safe.directory /host\n            export CILIUM_IMAGE=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci:${{ steps.vars.outputs.sha }}\n            export CILIUM_DOCKER_PLUGIN_IMAGE=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/docker-plugin-ci:${{ steps.vars.outputs.sha }}\n            export PROVISION_EXTERNAL_WORKLOAD=false\n            export VMUSER=root\n            echo '127.0.0.1 localhost' >> /etc/hosts\n            echo '::1 localhost' >> /etc/hosts\n            /tmp/provision/runtime_install.sh ${{ env.CILIUM_RUNTIME_EXTRA_ARGS }}\n            service docker restart\n\n      - name: Runtime tests\n        if: ${{ matrix.focus == 'agent' || matrix.focus == 'datapath' }}\n        timeout-minutes: 20\n        shell: bash\n        run: |\n          cat > test/cilium-ssh-config.txt << EOF\n          Host runtime\n            HostName 127.0.0.1\n            User root\n            Port 2222\n            UserKnownHostsFile /dev/null\n            StrictHostKeyChecking no\n            PasswordAuthentication no\n            LogLevel FATAL\n          EOF\n          cd test\n          export INTEGRATION_TESTS=true\n          ./test.test \\\n          --ginkgo.focus=\"${{ matrix.cliFocus }}\" \\\n          --ginkgo.skip=\"${{ matrix.cliSkip }}\" \\\n          --ginkgo.seed=1679952881 \\\n          --ginkgo.v -- \\\n          -cilium.image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n          -cilium.tag=${{ steps.vars.outputs.sha }}  \\\n          -cilium.operator-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n          -cilium.operator-tag=${{ steps.vars.outputs.sha }} \\\n          -cilium.hubble-relay-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci \\\n          -cilium.hubble-relay-tag=${{ steps.vars.outputs.sha }} \\\n          -cilium.operator-suffix=-ci \\\n          -cilium.SSHConfig=\"cat ./cilium-ssh-config.txt\" \\\n          -cilium.extra-opts=\"${{ env.CILIUM_RUNTIME_EXTRA_ARGS }}\"\n\n      - name: Prepare privileged tests\n        id: prepare-tests\n        if: ${{ matrix.focus == 'privileged' }}\n        timeout-minutes: 10\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            apt-get update\n            apt-get install zstd -y\n            cd /host\n            # The LVH image might ship with an arbitrary Go toolchain version,\n            # install the same Go toolchain version as current HEAD.\n            go install golang.org/dl/go${{ env.go-version }}@latest\n            go${{ env.go-version }} download\n            # renovate: datasource=github-releases depName=mfridman/tparse\n            go${{ env.go-version}} install github.com/mfridman/tparse@baf229e8494613f134bc0e1f4cb9dc9b12f66442\n            # renovate: datasource=github-releases depName=cilium/go-junit-report/v2/cmd/go-junit-report\n            go${{ env.go-version}} install github.com/cilium/go-junit-report/v2/cmd/go-junit-report@cc2d3acf69eeefab6f9a23ad61b175cd1d570623 # v2.3.0\n            # Use go cache and module cache from the host that is shared with the VM.\n            mkdir -p /go-caches\n            tar --use-compress-program=zstd -xpf /host/go-build-cache.tar.zst --same-owner -C /go-caches || true\n            tar --use-compress-program=zstd -xpf /host/go-mod-cache.tar.zst --same-owner -C /go-caches || true\n            ls -la /go-caches/go-build || true\n\n      - name: Privileged unit tests\n        id: run-tests\n        if: ${{ matrix.focus == 'privileged' }}\n        timeout-minutes: 40\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            cd /host\n            make GOCACHE=\"/go-caches/go-build\" GOMODCACHE=\"/go-caches/pkg\" SKIP_COVERAGE=1 LOG_CODEOWNERS=1 JUNIT_PATH=\"test/${{ env.job_name }}.xml\" tests-privileged-only GO=go${{ env.go-version }}\n\n      - name: Copy Go cache to host\n        id: copy-go-cache\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' && matrix.focus == 'privileged' }}\n        timeout-minutes: 10\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            cd /host\n            tar --use-compress-program=zstd -cpf /host/go-build-cache.tar.zst -C /go-caches go-build || true\n            tar --use-compress-program=zstd -cpf /host/go-mod-cache.tar.zst -C /go-caches pkg || true\n\n      - name: Move Go cache to local directories\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' && matrix.focus == 'privileged' }}\n        env:\n          GOCACHE: \"/tmp/.cache/go/.cache/go-build\"\n          GOMODCACHE: \"/tmp/.cache/go/pkg\"\n        run: |\n          ls -lah \"./go-build-cache.tar.zst\" || true\n          ls -lah \"./go-mod-cache.tar.zst\" || true\n          mv ./go-build-cache.tar.zst \"${GOCACHE}\" || true\n          mv ./go-mod-cache.tar.zst \"${GOMODCACHE}\" || true\n          ls -lah \"${GOCACHE}\" || true\n          ls -lah \"${GOMODCACHE}\" || true\n\n      - name: Copy tested features\n        if: ${{ matrix.focus == 'agent' || matrix.focus == 'datapath' }}\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            docker create --name cilium-dbg quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci:${{ steps.vars.outputs.sha }}\n            docker cp cilium-dbg:/usr/bin/cilium-dbg /usr/local/bin/cilium-dbg\n            docker rm cilium-dbg\n            cilium-dbg metrics list -p cilium_feature -o json > '/host/features-tested-${{ env.job_name }} (${{ matrix.focus }}).json'\n\n      - name: Debug failure on VM\n        # Only debug the failure on the LVH that have Cilium running as a service,\n        # which is 'agent' and 'datapath' focus.\n        if:  ${{ !success() && (matrix.focus == 'agent' || matrix.focus == 'datapath') }}\n        timeout-minutes: 10\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            journalctl --no-pager -xeu cilium.service\n            systemctl status cilium.service\n\n      - name: Fetch artifacts\n        if: ${{ !success() && (matrix.focus == 'agent' || matrix.focus == 'datapath') }}\n        shell: bash\n        run: |\n          if [ -e ./test/test_results ];then\n            tar -zcf 'test_results-${{ matrix.focus }}.tar.gz' ./test/test_results\n          else\n            echo \"::warning::test results directory is not exist!\"\n          fi\n\n      - name: Upload artifacts\n        if: ${{ !success() && (matrix.focus == 'agent' || matrix.focus == 'datapath') }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: cilium-sysdumps-${{ matrix.focus }}\n          path: |\n            test_results-*.tar.gz\n\n      - name: Fetch JUnits\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n          cd test/\n          # junit_filename needs to be the same as the Job Name presented on the\n          # GH web UI - In the Summary page of a workflow run, left column\n          # \"Jobs\" - so that we can map the junit file to the right job - step\n          # pair on datastudio.\n          junit_filename=\"${{ env.job_name }}.xml\"\n          for filename in *.xml; do cp \"${filename}\" \"../cilium-junits/${junit_filename}\"; done;\n\n      - name: Upload JUnits [junit]\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: cilium-junits-${{ matrix.focus }}\n          path: cilium-junits/*.xml\n\n      - name: Upload features tested\n        if: ${{ always() && (matrix.focus == 'agent' || matrix.focus == 'datapath') }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: features-tested-${{ matrix.focus }}\n          path: features-tested-${{ env.job_name }}*.json\n\n      - name: Publish Test Results As GitHub Summary\n        if: ${{ always() && runner.arch != 'ARM64' }}\n        uses: aanm/junit2md@332ebf0fddd34e91b03a832cfafaa826306558f9 # v0.0.3\n        with:\n          junit-directory: \"cilium-junits\"\n\n  merge-upload:\n    if: ${{ always() }}\n    name: Merge and Upload Artifacts\n    runs-on: ubuntu-24.04\n    needs: setup-and-test\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Merge JUnits\n        uses: ./.github/actions/merge-artifacts\n        with:\n          name: cilium-junits\n          pattern: cilium-junits-*\n          token: ${{ secrets.GITHUB_TOKEN }}\n      - name: Merge Features tested\n        uses: ./.github/actions/merge-artifacts\n        with:\n          name: features-tested\n          pattern: features-tested-*\n          token: ${{ secrets.GITHUB_TOKEN }}\n          separate-directories: true\n\n  commit-status-final:\n    if: ${{ always() }}\n    name: Commit Status Final\n    needs: setup-and-test\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set final commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n          status: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "documentation.yaml",
						"object": {
							"text": "name: Documentation Updates\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n  merge_group:\n    types: [checks_requested]\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after || github.event.merge_group && github.run_id }}\n  cancel-in-progress: ${{ !github.event.merge_group }}\n\njobs:\n  check_changes:\n    name: Deduce required tests from code changes\n    runs-on: ubuntu-24.04\n    outputs:\n      docs-tree: ${{ steps.docs-tree.outputs.src }}\n    steps:\n      - name: Checkout code\n        if: ${{ !github.event.pull_request }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Check code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: docs-tree\n        with:\n          # For `push` events, compare against the `ref` base branch\n          # For `pull_request` events, this is ignored and will compare against the pull request base branch\n          base: ${{ github.ref }}\n          filters: |\n            src:\n              - .github/workflows/documentation.yaml\n              - 'Documentation/**'\n              - 'bugtool/cmd/**'\n              - 'cilium/cmd/**'\n              - 'cilium-health/cmd/**'\n              - 'daemon/cmd/**'\n              - 'hubble-relay/cmd/**'\n              - 'install/kubernetes/**'\n              - 'operator/cmd/**'\n              - README.rst\n\n  # Runs only if code under Documentation or */cmd/ is changed as the docs\n  # should be unaffected otherwise.\n  build-html:\n    needs: check_changes\n    if: ${{ needs.check_changes.outputs.docs-tree == 'true' }}\n    name: Validate & Build HTML\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # Needed to detect missing redirects\n          fetch-depth: 0\n      - name: Build HTML\n        uses: docker://quay.io/cilium/docs-builder:e008fa4f700ec5b9043f1bf2f77099b72483de23@sha256:15aa5b59ae73e66eda9de7d68e98ac3143a5ec583bc7ad738e1be3b70984f0f9\n        with:\n          entrypoint: ./Documentation/check-build.sh\n          args: html\n\n  check-generated-documentation:\n    name: Check generated documentation\n    if: ${{ github.event_name != 'merge_group' }}\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # Needed to detect missing redirects\n          fetch-depth: 0\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      # Building Cilium as precondition to generate documentation artifacts.\n      - name: Build Cilium\n        run: |\n          make -C Documentation cilium-build\n\n      - name: Check generated documentation\n        run: |\n          SKIP_BUILD=true make -C Documentation check\n"
						}
					},
					{
						"name": "feature-summary-report.yaml",
						"object": {
							"text": "name: Feature Summary Report Generator\n\non:\n  workflow_dispatch:\n    inputs:\n      SHA:\n        description: \"Commit SHA to generate the summary from.\"\n        required: true\n  # Run every day\n  schedule:\n    - cron: '0 0 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\njobs:\n  summary_report:\n    name: \"Summary Report\"\n    env:\n      job_name: \"Summary Report\"\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          ci-version: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Generate Features Summary\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          cilium features summary \\\n            --commit=${{ inputs.SHA || github.sha }} \\\n            --repo=${{ github.repository }} \\\n            --metrics-directory=${{ inputs.SHA || github.sha }} \\\n            --anchor \\\n            --output-file=summary-features.md\n          printf \"\\n\\nEnd Of Report\\n\" >> summary-features.md\n\n      # There's a limitation with GITHUB_STEP_SUMMARY which only accepts 1024K\n      # at a time, so we need to use split uploading the file into multiple\n      # steps.\n      - name: Generate 1st part of GitHub step summary\n        run: |\n          skip_size=\"0\"\n\n          block_size=$(numfmt --from=iec 1023K)\n          chunk=$(dd if=summary-features.md bs=$block_size skip=$skip_size count=1 2>/dev/null)\n          echo -n \"$chunk\" >> $GITHUB_STEP_SUMMARY\n\n      - name: Generate 2nd part of GitHub step summary\n        run: |\n          skip_size=\"1\"\n\n          block_size=$(numfmt --from=iec 1023K)\n          chunk=$(dd if=summary-features.md bs=$block_size skip=$skip_size count=1 2>/dev/null)\n          echo \"$chunk\" >> $GITHUB_STEP_SUMMARY\n\n  commit-status-final:\n    if: ${{ always() }}\n    name: Commit Status Final\n    needs: summary_report\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set final commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n          status: ${{ needs.summary_report.result }}\n"
						}
					},
					{
						"name": "fqdn-perf.yaml",
						"object": {
							"text": "name: FQDN perf test (fqdn-perf)\n\non:\n  schedule:\n    - cron: '39 6 * * 1-5'\n\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\npermissions:\n  # To be able to retrieve artifacts information\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  test_name: perf-fqdn\n  cluster_name: ${{ github.run_id }}-${{ github.run_attempt }}\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  install-and-fqdn-perf-test:\n    runs-on: ubuntu-24.04\n    name: Install and FQDN Perf Test\n    timeout-minutes: 60\n    env:\n      job_name: \"Install and FQDN Perf Test\"\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ] ; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          CILIUM_INSTALL_DEFAULTS=\"--chart-directory=install/kubernetes/cilium \\\n            --set pprof.enabled=true \\\n            --helm-set=prometheus.enabled=true \\\n            --helm-set=dnsProxy.proxyResponseMaxDelay=100s \\\n            --helm-set=cluster.name=${{ env.cluster_name }} \\\n            --wait=false\"\n\n          # only add SHA to the image tags if it was set\n          if [ -n \"${SHA}\" ]; then\n            echo sha=${SHA} >> $GITHUB_OUTPUT\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set=image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n            --helm-set=image.useDigest=false \\\n            --helm-set=image.tag=${SHA} \\\n            --helm-set=operator.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n            --helm-set=operator.image.suffix=-ci \\\n            --helm-set=operator.image.tag=${SHA} \\\n            --helm-set=operator.image.useDigest=false \\\n            --helm-set=clustermesh.apiserver.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/clustermesh-apiserver-ci \\\n            --helm-set=clustermesh.apiserver.image.tag=${SHA} \\\n            --helm-set=clustermesh.apiserver.image.useDigest=false \\\n            --helm-set=hubble.relay.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci \\\n            --helm-set=hubble.relay.image.tag=${SHA} \\\n            --helm-set=hubble.relay.image.useDigest=false\"\n          fi\n\n          # Adding k8s.local to the end makes kops happy\n          # has stricter DNS naming requirements.\n          CLUSTER_NAME=\"${{ env.test_name }}-${{ env.cluster_name }}.k8s.local\"\n\n          echo SHA=${SHA} >> $GITHUB_OUTPUT\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo CLUSTER_NAME=${CLUSTER_NAME} >> $GITHUB_OUTPUT\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.SHA }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version: ${{ env.go_version }}\n\n      - name: Install Kops\n        uses: cilium/scale-tests-action/install-kops@082339e175a65c282c44c13bf875822e23911359 # main\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: \"405.0.0\"\n\n      - name: Clone ClusterLoader2\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes/perf-tests\n          # Avoid using renovate to update this dependency because: (1)\n          # perf-tests does not tag or release, so renovate will pull\n          # all updates to the default branch and (2) continually\n          # updating CL2 may impact the stability of the scale test\n          # results.\n          ref: 6eb52ac89d5de15a0ad13cfeb2b2026e57ce4f64\n          persist-credentials: false\n          sparse-checkout: clusterloader2\n          path: perf-tests\n\n      - name: Deploy cluster\n        id: deploy-cluster\n        uses: cilium/scale-tests-action/create-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          control_plane_size: n1-standard-4\n          control_plane_count: 1\n          node_size: e2-standard-8\n          node_count: 2\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Display version info of installed tools\n        run: |\n          echo \"--- go ---\"\n          go version\n          echo \"--- cilium-cli ---\"\n          cilium version --client\n          echo \"--- kops ---\"\n          ./kops version\n          echo \"--- gcloud ---\"\n          gcloud version\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n\n      - name: Install Cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for cluster to be ready\n        uses: cilium/scale-tests-action/validate-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 20\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n\n      - name: Run CL2\n        id: run-cl2\n        working-directory: ./perf-tests/clusterloader2\n        shell: bash\n        timeout-minutes: 30\n        run: |\n          mkdir ./report\n          export CL2_PROMETHEUS_PVC_ENABLED=false\n          export CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR=true\n          export CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT=true\n          export CL2_ENABLE_DNSTESTS=true\n\n          # CL2 needs ssh access to control plane nodes\n          gcloud compute config-ssh\n\n          cp -r ../../.github/actions/cl2-modules/fqdn ./testing/\n\n          go run ./cmd/clusterloader.go \\\n            -v=2 \\\n            --testconfig=./testing/fqdn/config.yaml \\\n            --provider=gce \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --report-dir=./report \\\n            --experimental-prometheus-snapshot-to-report-dir=true \\\n            --kubeconfig=$HOME/.kube/config \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            2>&1 | tee cl2-output.txt\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n          junits-directory: 'report'\n\n      - name: Cleanup cluster\n        if: ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        uses: cilium/scale-tests-action/cleanup-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-cl2.outcome != 'skipped' && steps.run-cl2.outcome != 'cancelled' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ env.test_name }}\n          tested_sha: ${{ steps.vars.outputs.SHA }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          artifacts: ./perf-tests/clusterloader2/report/\n          other_files: cilium-sysdump-final.zip ./perf-tests/clusterloader2/cl2-output.txt\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: install-and-fqdn-perf-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.install-and-fqdn-perf-test.result }}\n"
						}
					},
					{
						"name": "hubble-cli-integration-test.yaml",
						"object": {
							"text": "name: Hubble CLI integration tests\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n    - main\n    - ft/main/**\n    - 'renovate/main-**'\n    paths-ignore:\n    - 'Documentation/**'\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  kind_config: .github/kind-config.yaml\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  integration-test:\n    runs-on: ubuntu-24.04\n    env:\n      job_name: \"Integration Test\"\n    name: Hubble CLI Integration Test\n    timeout-minutes: 20\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n\n      - name: Set image tag\n        id: vars\n        run: |\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=hubble.relay.enabled=true\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n            examples\n\n      # Build hubble CLI before setting up the cluster and waiting on images to\n      # save time on failures.\n      - name: Setup go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version-file: 'go.mod'\n\n      - name: Build hubble CLI\n        run: |\n          make -C hubble\n          ./hubble/hubble version\n\n      # Setup the cluster\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0 -C hubble\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.KIND_CONFIG }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl -n kube-system get pods\n\n      - name: Wait for hubble-relay to be running\n        run: |\n          kubectl -n kube-system rollout status deployment/hubble-relay\n\n      - name: Run Hubble CLI integration test\n        timeout-minutes: 5\n        run: |\n          set -ex\n          ./hubble/hubble --version\n\n          cilium hubble port-forward&\n          echo \"wait until the port-forward is running\"\n          sleep 10s\n          nc -nvz 127.0.0.1 4245\n\n          ./hubble/hubble status\n\n          echo \"query hubble until we receive flows, or timeout\"\n          flowCount=0\n          until [ $flowCount -gt 0 ]; do\n            ./hubble/hubble observe -n kube-system -o jsonpb  | tee flows.json\n            flowCount=$(jq -r --slurp 'length' flows.json)\n            sleep 5\n          done\n\n          echo \"verify we got some flows\"\n          test \"$(jq -r --slurp 'length' flows.json)\" -gt 0\n          echo \"test piping flows into the CLI\"\n          test \"$(./hubble/hubble observe --input-file flows.json -o json | jq -r --slurp 'length')\" -eq \"$(jq -r --slurp 'length' flows.json)\"\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: integration-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.integration-test.result }}\n"
						}
					},
					{
						"name": "integration-test.yaml",
						"object": {
							"text": "name: Integration Tests (ci-integration)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n    - main\n    - ft/main/**\n    - 'renovate/main-**'\n    paths-ignore:\n    - 'Documentation/**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 3/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  integration-test:\n    name: Integration Test\n    env:\n      # GitHub doesn't provide a way to retrieve the name of a job, so we have\n      # to repeated it here.\n      job_name: \"Integration Test (${{matrix.arch}})\"\n    strategy:\n      fail-fast: false\n      matrix:\n        arch: [\"${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\", ubuntu-24.04-arm64]\n    runs-on: ${{ matrix.arch }}\n    timeout-minutes: 45\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Setup additional repositories\n        if: ${{ startsWith(matrix.arch, 'ubuntu-latest') || startsWith(matrix.arch, 'ubuntu-24.04') }}\n        shell: bash\n        run: |\n          # This is required for libtinfo5\n          uri=\"http://security.ubuntu.com/ubuntu\"\n          arch=\"amd64\"\n          if [ ${{ runner.arch }} == \"ARM64\" ]; then\n            uri=\"http://ports.ubuntu.com/ubuntu-ports\"\n            arch=\"arm64\"\n          fi\n\n          sudo tee -a /etc/apt/sources.list.d/jammy-security.sources <<EOF\n          Types: deb\n          URIs: $uri\n          Suites: jammy-updates\n          Components: main universe restricted multiverse\n          Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg\n          Architectures: $arch\n          EOF\n\n      - name: Install Dependencies\n        shell: bash\n        run: |\n          sudo apt update && sudo apt install -y --no-install-recommends build-essential make libtinfo5\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set image tag\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n          echo sha=${SHA} >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      # Load Golang cache build from GitHub\n      - name: Load Golang cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-integration-test-cache-${{ runner.arch }}-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-integration-test-cache-${{ runner.arch }}-\n\n      - name: Set clang directory\n        id: set_clang_dir\n        run: echo \"clang_dir=$HOME/.clang\" >> $GITHUB_OUTPUT\n\n      - name: Install LLVM and Clang\n        uses: KyleMayes/install-llvm-action@a7a1a882e2d06ebe05d5bb97c3e1f8c984ae96fc # v2.0.7\n        with:\n          version: \"19.1.7\"\n          directory: ${{ steps.set_clang_dir.outputs.clang_dir }}\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' }}\n        env:\n          GOCACHE: \"/tmp/.cache/go/.cache/go-build\"\n          GOMODCACHE: \"/tmp/.cache/go/pkg\"\n        shell: bash\n        run: |\n          mkdir -p \"${GOCACHE}\"\n          mkdir -p \"${GOMODCACHE}\"\n\n      - name: Prepare environment\n        timeout-minutes: 15\n        env:\n          GOCACHE: \"/tmp/.cache/go/.cache/go-build\"\n          GOMODCACHE: \"/tmp/.cache/go/pkg\"\n        shell: bash\n        run: |\n          # renovate: datasource=github-releases depName=mfridman/tparse\n          go install github.com/mfridman/tparse@baf229e8494613f134bc0e1f4cb9dc9b12f66442 # v0.14.0\n          # renovate: datasource=github-releases depName=cilium/go-junit-report/v2/cmd/go-junit-report\n          go install github.com/cilium/go-junit-report/v2/cmd/go-junit-report@cc2d3acf69eeefab6f9a23ad61b175cd1d570623 # v2.3.0\n\n      - name: Run integration tests\n        id: run-tests\n        timeout-minutes: 60\n        env:\n          GOCACHE: \"/tmp/.cache/go/.cache/go-build\"\n          GOMODCACHE: \"/tmp/.cache/go/pkg\"\n        run: |\n          export V=0\n          export DOCKER_BUILD_FLAGS=--quiet\n          export CFLAGS=\"-Werror\"\n          make integration-tests LOG_CODEOWNERS=1 JUNIT_PATH=\"test/${{ env.job_name }}.xml\"\n\n      - name: Fetch JUnits\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n          cd test/\n          # junit_filename needs to be the same as the Job Name presented on the\n          # GH web UI - In the Summary page of a workflow run, left column\n          # \"Jobs\" - so that we can map the junit file to the right job - step\n          # pair on datastudio.\n          junit_filename=\"${{ env.job_name }}.xml\"\n          for filename in *.xml; do cp \"${filename}\" \"../cilium-junits/${junit_filename}\"; done;\n\n      - name: Upload JUnits [junit]\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: cilium-junits-${{ env.job_name }}\n          path: cilium-junits/*.xml\n\n      - name: Publish Test Results As GitHub Summary\n        if: ${{ always() && runner.arch != 'ARM64' }}\n        uses: aanm/junit2md@332ebf0fddd34e91b03a832cfafaa826306558f9 # v0.0.3\n        with:\n          junit-directory: \"cilium-junits\"\n\n  merge-upload:\n    if: ${{ always() }}\n    name: Merge and Upload Artifacts\n    runs-on: ubuntu-24.04\n    needs: integration-test\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Merge JUnits\n        uses: ./.github/actions/merge-artifacts\n        with:\n          name: cilium-junits\n          pattern: cilium-junits-*\n          token: ${{ secrets.GITHUB_TOKEN }}\n\n  commit-status-final:\n    if: ${{ always() }}\n    name: Commit Status Final\n    needs: integration-test\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set final commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n          status: ${{ needs.integration-test.result }}\n"
						}
					},
					{
						"name": "k8s-kind-network-e2e.yaml",
						"object": {
							"text": "name: K8s Network E2E tests and kube-apiserver HA\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\nenv:\n  cluster_name: cilium-testing\n\njobs:\n  check_changes:\n    name: Deduce required tests from code changes\n    runs-on: ubuntu-24.04\n    outputs:\n      tested: ${{ steps.tested-tree.outputs.src }}\n    steps:\n      - name: Checkout code\n        if: ${{ !github.event.pull_request }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Check code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: tested-tree\n        with:\n          # For `push` events, compare against the `ref` base branch\n          # For `pull_request` events, this is ignored and will compare against the pull request base branch\n          base: ${{ github.ref }}\n          filters: |\n            src:\n              - '!(test|Documentation)/**'\n\n  kubernetes-e2e:\n    name: K8s Network E2E tests\n    needs: check_changes\n    if: ${{ needs.check_changes.outputs.tested == 'true' }}\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    timeout-minutes: 90\n    strategy:\n      fail-fast: false\n      matrix:\n        # TODO add \"ipv6\", \"ipv6\" fails to install cilium\n        ipFamily: [\"dual\"]\n    env:\n      IP_FAMILY: ${{ matrix.ipFamily }}\n      job_name: \"Installation and Conformance Test\"\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Enable ipv4 and ipv6 forwarding\n        run: |\n          sudo sysctl -w net.ipv6.conf.all.forwarding=1\n          sudo sysctl -w net.ipv4.ip_forward=1\n\n      - name: Set up environment (download Kubernetes dependencies)\n        run: |\n          TMP_DIR=$(mktemp -d)\n          # Test binaries\n          curl -L https://dl.k8s.io/${{ env.KIND_K8S_VERSION }}/kubernetes-test-linux-amd64.tar.gz -o ${TMP_DIR}/kubernetes-test-linux-amd64.tar.gz\n          tar -xvzf ${TMP_DIR}/kubernetes-test-linux-amd64.tar.gz \\\n            --directory ${TMP_DIR} \\\n            --strip-components=3 kubernetes/test/bin/ginkgo kubernetes/test/bin/e2e.test\n          # kubectl\n          curl -L https://dl.k8s.io/${{ env.KIND_K8S_VERSION }}/bin/linux/amd64/kubectl -o ${TMP_DIR}/kubectl\n          # kind\n          curl -Lo ${TMP_DIR}/kind https://kind.sigs.k8s.io/dl/${{ env.KIND_VERSION }}/kind-linux-amd64\n          # Install\n          sudo cp ${TMP_DIR}/ginkgo /usr/local/bin/ginkgo\n          sudo cp ${TMP_DIR}/e2e.test /usr/local/bin/e2e.test\n          sudo cp ${TMP_DIR}/kubectl /usr/local/bin/kubectl\n          sudo cp ${TMP_DIR}/kind /usr/local/bin/kind\n          sudo chmod +x /usr/local/bin/ginkgo /usr/local/bin/e2e.test /usr/local/bin/kubectl /usr/local/bin/kind\n          sudo rm -rf ${TMP_DIR}\n\n      - name: Create multi node cluster\n        run: |\n          cat <<EOF | /usr/local/bin/kind create cluster \\\n            --name ${{ env.cluster_name}}           \\\n            --image ${{ env.KIND_K8S_IMAGE }}  \\\n            -v7 --retain --config=-\n          kind: Cluster\n          apiVersion: kind.x-k8s.io/v1alpha4\n          networking:\n            ipFamily: ${IP_FAMILY}\n            kubeProxyMode: \"none\"\n            disableDefaultCNI: true\n          nodes:\n          - role: control-plane\n          - role: control-plane\n          - role: worker\n          - role: worker\n          EOF\n\n      - name: Workaround CoreDNS for IPv6 airgapped\n        if: ${{ matrix.ipFamily == 'ipv6' }}\n        run: |\n          # Patch CoreDNS to work in Github CI\n          # 1. Github CI doesnt offer IPv6 connectivity, so CoreDNS should be configured\n          # to work in an offline environment:\n          # https://github.com/coredns/coredns/issues/2494#issuecomment-457215452\n          # 2. Github CI adds following domains to resolv.conf search field:\n          # .net.\n          # CoreDNS should handle those domains and answer with NXDOMAIN instead of SERVFAIL\n          # otherwise pods stops trying to resolve the domain.\n          # Get the current config\n          original_coredns=$(/usr/local/bin/kubectl get -oyaml -n=kube-system configmap/coredns)\n          echo \"Original CoreDNS config:\"\n          echo \"${original_coredns}\"\n          # Patch it\n          fixed_coredns=$(\n            printf '%s' \"${original_coredns}\" | sed \\\n              -e 's/^.*kubernetes cluster\\.local/& net/' \\\n              -e '/^.*upstream$/d' \\\n              -e '/^.*fallthrough.*$/d' \\\n              -e '/^.*forward . \\/etc\\/resolv.conf$/d' \\\n              -e '/^.*loop$/d' \\\n          )\n          echo \"Patched CoreDNS config:\"\n          echo \"${fixed_coredns}\"\n          printf '%s' \"${fixed_coredns}\" | /usr/local/bin/kubectl apply -f -\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ github.event.pull_request.head.sha || github.sha }}\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          # Note: On Kind, we install Cilium with HostPort (portmap CNI chaining) enabled,\n          # to ensure coverage of that feature in cilium connectivity test\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cni.chainingMode=portmap \\\n            --helm-set-string=kubeProxyReplacement=true\"\n          if [ \"${IP_FAMILY}\" == \"dual\" ]; then\n            CILIUM_INSTALL_DEFAULTS=\"${CILIUM_INSTALL_DEFAULTS} --helm-set=ipv6.enabled=true\"\n          fi\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          getKubeApiServerAddress() {\n            nodev4=$(kubectl get node $1 -o json | jq -r '.status.addresses[] | select(.type==\"InternalIP\") | .address' | head -n 1)\n            echo $nodev4\n          }\n          node1=$(getKubeApiServerAddress ${{ env.cluster_name }}-control-plane)\n          node2=$(getKubeApiServerAddress ${{ env.cluster_name }}-control-plane2)\n\n          cilium install --wait ${{ steps.vars.outputs.cilium_install_defaults }} \\\n          --helm-set kubeProxyReplacement=true \\\n          --helm-set k8s.apiServerURLs=\"https://$node1:6443 https://$node2:6443\"\n\n      - name: Create LB IPAM pool\n        run: |\n          # Needed so that Cilium can allocate LoadBalancer service IPs\n          # needed for the tests\n          kubectl apply -f - <<EOF\n          apiVersion: \"cilium.io/v2\"\n          kind: CiliumLoadBalancerIPPool\n          metadata:\n            name: \"test-lb-pool\"\n          spec:\n            blocks:\n            - cidr: \"10.0.10.0/24\"\n          EOF\n\n      - name: Run Kubernetes sig-network test\n        run: |\n          # output_dir\n          mkdir -p _artifacts\n\n          # get kubeconfig to pass to the e2e binary\n          kind get kubeconfig --name ${{ env.cluster_name }} > _artifacts/kubeconfig.conf\n\n          # Kubernetes e2e tests use ginkgo and tags to select the tests that should run based on two regex, focus and skip:\n          # Focus tests:\n          # \\[sig-network\\]: sig-network tests are defined by sig-network to guarantee a consistent behavior on all the the k8s network implementations\n          # Skipped tests:\n          # Disruptive|Serial : require to run in serial and perform disruptive operations on clusters (reboots, ...)\n          # Federation|PerformanceDNS : unrelated sig-network tests\n          # Alpha|Beta|Experimental : skip features that are not GA\n          # KubeProxy|kube-proxy : kube-proxy specifics\n          # LoadBalancer|GCE|ExternalIP : require a cloud provider, some of them are GCE specifics\n          # Netpol|NetworkPolicy : network policies, demand significant resources and use to be slow, better to run in a different job\n          # rejected : Kubernetes expect Services without endpoints associated to REJECT the connection to notify the client, Cilium silently drops the packet\n          # externalTrafficPolicy : Cilium fails externalTrafficPolicy=local test, see https://github.com/cilium/cilium/issues/37613\n          # DualStack : tests that are dual stack specific\n          # IPv6 : tests that are IPv6 specific\n\n          SKIP_FLAG=\"Alpha|Beta|Experimental|Federation|PerformanceDNS|Disruptive|Serial|KubeProxy|kube-proxy|ExternalIP|LoadBalancer|GCE|Netpol|NetworkPolicy|rejected|externalTrafficPolicy|SCTPConnectivity|IPv6DualStack|Conntrack.proxy.implementation.should.not.be.vulnerable.to.the.invalid.conntrack.state.bug|Services.should.fallback.to.local.terminating.endpoints.when.there.are.no.ready.endpoints.with.internalTrafficPolicy=Local|Networking.IPerf2.\\[Feature:Networking\\-Performance\\].should.run.iperf2|Networking.Granular.Checks:.Services.should.update.endpoints\"\n          if [ \"${IP_FAMILY}\" != \"dual\" ]; then\n            SKIP_FLAG=\"${SKIP_FLAG}|DualStack\"\n          fi\n          if [ \"${IP_FAMILY}\" == \"ipv4\" ]; then\n            SKIP_FLAG=\"${SKIP_FLAG}|IPv6\"\n          fi\n\n          # Run tests\n          export KUBERNETES_CONFORMANCE_TEST='y'\n          export E2E_REPORT_DIR=${PWD}/_artifacts\n          /usr/local/bin/ginkgo --nodes=25                \\\n            --focus=\"\\[sig-network\\]\"     \\\n            --skip=\"${SKIP_FLAG}\"   \\\n            /usr/local/bin/e2e.test                       \\\n            --                                            \\\n            --kubeconfig=${PWD}/_artifacts/kubeconfig.conf     \\\n            --provider=local                              \\\n            --dump-logs-on-failure=true                   \\\n            --report-dir=${E2E_REPORT_DIR}                \\\n            --disable-log-dump=true\n\n      # Sequentially kill kube-apiserver pods to verify cilium agent pods fail over to an active instance.\n      - name: Test kube-apiserver high availability\n        run: |\n          PORT=6443\n          NAMESPACE=\"kube-system\"\n          # Get kube-apiserver pods.\n          declare -A pods\n          entries=$(kubectl -n \"$NAMESPACE\" get pods -l component=kube-apiserver -o json | jq -r '.items[] | \"\\(.metadata.name) \\(.status.podIP)\"')\n          while read -r pod ip; do\n            pods[\"$pod\"]=\"$ip\"\n            done <<< \"$entries\"\n          for pod in \"${!pods[@]}\"; do\n            echo \"$pod => ${pods[$pod]}\"\n          done\n          # Sequentially delete kube-apiserver pods by connecting via an active kube-apiserver instance.\n          for pod in \"${!pods[@]}\"; do\n            # Find an active kube-apiserver pod\n            for active_pod in \"${!pods[@]}\"; do\n              if [[ \"$active_pod\" != \"$pod\" ]]; then\n                active_ip=\"${pods[$active_pod]}\"\n                break\n              fi\n            done\n            echo \"Deleting $pod\"\n            kubectl -n \"$NAMESPACE\" --server \"https://${active_ip}:${PORT}\" delete pod \"$pod\"\n            sleep 120\n          done\n          cilium status --wait --wait-duration=5m\n          kubectl get pods -n kube-system\n\n      - name: Gather metrics\n        uses: ./.github/actions/gather-metrics\n        with:\n          job: \"${{ env.job_name }}-${{ matrix.ipFamily }}\"\n\n      - name: Create Cilium JUnits Directory\n        if: ${{ steps.install-cilium.outcome != 'skipped' }}\n        run: |\n          # Move the all artifacts to cilium-junits directory since that's the\n          # directory used in the common post steps.\n          mv _artifacts cilium-junits\n\n      - name: Post-test information gathering\n        if: ${{ !success() && steps.install-cilium.outcome != 'skipped' }}\n        run: |\n          mkdir -p ./_artifacts/logs\n          /usr/local/bin/kind export logs --name  ${{ env.cluster_name }} --verbosity=3 ./_artifacts/logs\n        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently\n\n      - name: Upload cluster logs\n        if: ${{ !success() }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: \"kind-logs-${{ matrix.ipFamily }}\"\n          path: ./_artifacts/logs\n          retention-days: 5\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.ipFamily }}\"\n          job_status: \"${{ job.status }}\"\n"
						}
					},
					{
						"name": "k8s-kind-network-policies-e2e.yaml",
						"object": {
							"text": "name: K8s Network Policy E2E tests\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request:\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n  push:\n    branches:\n      - main\n      - ft/main/**\n    paths-ignore:\n      - 'Documentation/**'\n      - 'test/**'\n  # Run every 8 hours\n  schedule:\n    - cron: '0 4/8 * * *'\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\nenv:\n  cluster_name: cilium-testing\n\njobs:\n  kubernetes-e2e-net:\n    name: K8s Network Policy E2E tests\n    runs-on: ubuntu-24.04\n    timeout-minutes: 45\n    strategy:\n      fail-fast: false\n      matrix:\n        # TODO add \"ipv6\", \"ipv6\" fails to install cilium\n        ipFamily: [\"dual\"]\n    env:\n      IP_FAMILY: ${{ matrix.ipFamily }}\n      job_name: \"K8s network policy tests\"\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Enable ipv4 and ipv6 forwarding\n        run: |\n          sudo sysctl -w net.ipv6.conf.all.forwarding=1\n          sudo sysctl -w net.ipv4.ip_forward=1\n\n      - name: Set up environment (download Kubernetes dependencies)\n        run: |\n          TMP_DIR=$(mktemp -d)\n          # Test binaries\n          curl -L https://dl.k8s.io/${{ env.KIND_K8S_VERSION }}/kubernetes-test-linux-amd64.tar.gz -o ${TMP_DIR}/kubernetes-test-linux-amd64.tar.gz\n          tar -xvzf ${TMP_DIR}/kubernetes-test-linux-amd64.tar.gz \\\n            --directory ${TMP_DIR} \\\n            --strip-components=3 kubernetes/test/bin/ginkgo kubernetes/test/bin/e2e.test\n          # kubectl\n          curl -L https://dl.k8s.io/${{ env.KIND_K8S_VERSION }}/bin/linux/amd64/kubectl -o ${TMP_DIR}/kubectl\n          # kind\n          curl -Lo ${TMP_DIR}/kind https://kind.sigs.k8s.io/dl/${{ env.KIND_VERSION }}/kind-linux-amd64\n          # Install\n          sudo cp ${TMP_DIR}/ginkgo /usr/local/bin/ginkgo\n          sudo cp ${TMP_DIR}/e2e.test /usr/local/bin/e2e.test\n          sudo cp ${TMP_DIR}/kubectl /usr/local/bin/kubectl\n          sudo cp ${TMP_DIR}/kind /usr/local/bin/kind\n          sudo chmod +x /usr/local/bin/ginkgo /usr/local/bin/e2e.test /usr/local/bin/kubectl /usr/local/bin/kind\n          sudo rm -rf ${TMP_DIR}\n\n      - name: Create multi node cluster\n        run: |\n          cat <<EOF | /usr/local/bin/kind create cluster \\\n            --name ${{ env.cluster_name}}           \\\n            --image ${{ env.KIND_K8S_IMAGE }}  \\\n            -v7 --retain --config=-\n          kind: Cluster\n          apiVersion: kind.x-k8s.io/v1alpha4\n          networking:\n            ipFamily: ${IP_FAMILY}\n            kubeProxyMode: \"none\"\n            disableDefaultCNI: true\n          nodes:\n          - role: control-plane\n          - role: worker\n          - role: worker\n          EOF\n\n      - name: Workaround CoreDNS for IPv6 airgapped\n        if: ${{ matrix.ipFamily == 'ipv6' }}\n        run: |\n          # Patch CoreDNS to work in Github CI\n          # 1. Github CI doesnt offer IPv6 connectivity, so CoreDNS should be configured\n          # to work in an offline environment:\n          # https://github.com/coredns/coredns/issues/2494#issuecomment-457215452\n          # 2. Github CI adds following domains to resolv.conf search field:\n          # .net.\n          # CoreDNS should handle those domains and answer with NXDOMAIN instead of SERVFAIL\n          # otherwise pods stops trying to resolve the domain.\n          # Get the current config\n          original_coredns=$(/usr/local/bin/kubectl get -oyaml -n=kube-system configmap/coredns)\n          echo \"Original CoreDNS config:\"\n          echo \"${original_coredns}\"\n          # Patch it\n          fixed_coredns=$(\n            printf '%s' \"${original_coredns}\" | sed \\\n              -e 's/^.*kubernetes cluster\\.local/& net/' \\\n              -e '/^.*upstream$/d' \\\n              -e '/^.*fallthrough.*$/d' \\\n              -e '/^.*forward . \\/etc\\/resolv.conf$/d' \\\n              -e '/^.*loop$/d' \\\n          )\n          echo \"Patched CoreDNS config:\"\n          echo \"${fixed_coredns}\"\n          printf '%s' \"${fixed_coredns}\" | /usr/local/bin/kubectl apply -f -\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ github.event.pull_request.head.sha || github.sha }}\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          # Note: On Kind, we install Cilium with HostPort (portmap CNI chaining) enabled,\n          # to ensure coverage of that feature in cilium connectivity test\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cni.chainingMode=portmap \\\n            --helm-set=kubeProxyReplacement=true \\\n            --helm-set=identityChangeGracePeriod=\\\"0s\\\" \\\n            --helm-set=sctp.enabled=true\"\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install --wait ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Run Kubernetes sig-network network policy tests\n        run: |\n          # output_dir\n          mkdir -p _artifacts\n\n          # get kubeconfig to pass to the e2e binary\n          kind get kubeconfig --name ${{ env.cluster_name }} > _artifacts/kubeconfig.conf\n\n          # Kubernetes e2e tests use ginkgo and tags to select the tests that should run based on two regex, focus and skip:\n          # Focus tests:\n          # Netpol|NetworkPolicy : NetworkPolicy tests ignored by the other workflow\n          # Skipped tests:\n          # should.allow.egress.access.to.server.in.CIDR.block - https://github.com/cilium/cilium/issues/9209\n          # should.ensure.an.IP.overlapping.both.IPBlock.CIDR.and.IPBlock.Except.is.allowed - https://github.com/cilium/cilium/issues/9209\n          # should.enforce.except.clause.while.egress.access.to.server.in.CIDR.block - https://github.com/cilium/cilium/issues/9209\n\n          SKIP_FLAG=\"should.allow.egress.access.to.server.in.CIDR.block|should.ensure.an.IP.overlapping.both.IPBlock.CIDR.and.IPBlock.Except.is.allowed|should.enforce.except.clause.while.egress.access.to.server.in.CIDR.block\"\n          if [ \"${IP_FAMILY}\" != \"dual\" ]; then\n            SKIP_FLAG=\"${SKIP_FLAG}|DualStack\"\n          fi\n          if [ \"${IP_FAMILY}\" == \"ipv4\" ]; then\n            SKIP_FLAG=\"${SKIP_FLAG}|IPv6\"\n          fi\n\n          # Run tests\n          export KUBERNETES_CONFORMANCE_TEST='y'\n          export E2E_REPORT_DIR=${PWD}/_artifacts\n          /usr/local/bin/ginkgo --nodes=10                \\\n            --focus=\"(Netpol|NetworkPolicy)\"     \\\n            --skip=\"${SKIP_FLAG}\" \\\n            /usr/local/bin/e2e.test                       \\\n            --                                            \\\n            --kubeconfig=${PWD}/_artifacts/kubeconfig.conf     \\\n            --provider=local                              \\\n            --dump-logs-on-failure=true                   \\\n            --report-dir=${E2E_REPORT_DIR}                \\\n            --disable-log-dump=true\n\n      # Check for file-descriptor leaks from the cilium-agent process.\n      # There's no particular reason why we are checking it here, but\n      # it is a good idea to check for leaks in a CI job as this was migrated\n      # from the runtime tests' framework.\n      - name: File-descriptor leak detector\n        run: |\n          for p in $(pidof cilium-agent); do\n            num=$(sudo lsof -p $p | wc -l)\n            echo \"cilium-agent($p) has $num file descriptors open\"\n            if [ \"$num\" -gt \"5000\" ]; then\n              echo \"cilium-agent($p) has more than 5000 file descriptors (potential leak)\"\n              sudo lsof -p $p\n              exit 1\n            fi\n          done\n\n      - name: Create Cilium JUnits Directory\n        if: ${{ steps.install-cilium.outcome != 'skipped' }}\n        run: |\n          # Move the all artifacts to cilium-junits directory since that's the\n          # directory used in the common post steps.\n          mv _artifacts cilium-junits\n\n      - name: Post-test information gathering\n        if: ${{ !success() && steps.install-cilium.outcome != 'skipped' }}\n        run: |\n          mkdir -p ./_artifacts/logs\n          /usr/local/bin/kind export logs --name  ${{ env.cluster_name }} --verbosity=3 ./_artifacts/logs\n        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently\n\n      - name: Upload cluster logs\n        if: ${{ !success() }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: kind-logs\n          path: ./_artifacts/logs\n          retention-days: 5\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.ipFamily }}\"\n          job_status: \"${{ job.status }}\"\n"
						}
					},
					{
						"name": "lint-bpf-checks.yaml",
						"object": {
							"text": "name: BPF Checks\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n  merge_group:\n    types: [checks_requested]\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after || github.event.merge_group && github.run_id }}\n  cancel-in-progress: ${{ !github.event.merge_group }}\n\njobs:\n  check_changes:\n    name: Deduce required tests from code changes\n    runs-on: ubuntu-24.04\n    outputs:\n      bpf-tree: ${{ steps.changes.outputs.bpf-tree }}\n      coccinelle: ${{ steps.changes.outputs.coccinelle }}\n      bpf-tests-runner: ${{ steps.changes.outputs.bpf-tests-runner }}\n      workflow-description: ${{ steps.changes.outputs.workflow-description }}\n    steps:\n      - name: Checkout code\n        if: ${{ !github.event.pull_request }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Check code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: changes\n        with:\n          # For `push` events, compare against the `ref` base branch\n          # For `pull_request` events, this is ignored and will compare against the pull request base branch\n          base: ${{ github.ref }}\n          filters: |\n            bpf-tree:\n              - 'bpf/**'\n              - 'images/**'\n              - 'Makefile*'\n              - 'contrib/scripts/builder.sh'\n              - '!**/*.md'\n\n            coccinelle:\n              - 'contrib/coccinelle/**'\n            bpf-tests-runner:\n              - 'bpf/tests/bpftest/**'\n              - 'pkg/bpf/**'\n              - '!**/*.md'\n            workflow-description:\n              - '.github/workflows/lint-bpf-checks.yaml'\n\n  checkpatch:\n    name: Check Patch\n    runs-on: ubuntu-24.04\n    if: ${{ github.event_name == 'pull_request' }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Run checkpatch.pl\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          make -C bpf checkpatch || (echo \"Run 'make -C bpf checkpatch' locally to investigate reports\"; exit 1)\n\n  # Runs only if code under bpf/ or contrib/coccinnelle/ is changed.\n  coccicheck:\n    needs: check_changes\n    if: ${{ needs.check_changes.outputs.bpf-tree == 'true' || needs.check_changes.outputs.coccinelle == 'true' || needs.check_changes.outputs.workflow-description == 'true' }}\n    name: Run coccicheck\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n      - name: Run coccicheck\n        uses: docker://cilium/coccicheck:2.4@sha256:24abe3fbb8e829fa41a68a3b76cb4df84fd5a87a7d1d6254c1c1fe5effb5bd1b\n        with:\n          entrypoint: ./contrib/coccinelle/check-cocci.sh\n        # Note: Setting COCCINELLE_HOME can be removed, here and in the\n        # messages in the .cocci files, next time we upgrade coccinelle.\n        # The issue was fixed, after v1.1.1 that we're using, in\n        # https://gitlab.inria.fr/coccinelle/coccinelle/-/commit/540888ff426e.\n        env:\n          COCCINELLE_HOME: /usr/local/lib/coccinelle\n\n  # Runs only if code under bpf/ is changed.\n  build_all:\n    needs: [check_changes]\n    if: ${{ needs.check_changes.outputs.bpf-tree == 'true' || needs.check_changes.outputs.workflow-description == 'true' }}\n    name: Build Datapath\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Build all BPF datapath permutations\n        env:\n          V: 0\n        run: |\n          contrib/scripts/builder.sh make --quiet -C bpf build_all -j \"$(nproc)\" || (echo \"Run 'make -C bpf build_all' locally to investigate build breakages\"; exit 1)\n\n  bpf_tests:\n    needs: [check_changes]\n    if: ${{ needs.check_changes.outputs.bpf-tree == 'true' || needs.check_changes.outputs.bpf-tests-runner == 'true' || needs.check_changes.outputs.workflow-description == 'true' }}\n    name: BPF unit/integration Tests\n    env:\n      # GitHub doesn't provide a way to retrieve the name of a job, so we have\n      # to repeated it here.\n      job_name: \"bpf_tests\"\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Run BPF tests\n        id: run-tests\n        run: |\n          make run_bpf_tests \\\n              LOG_CODEOWNERS=1 \\\n              JUNIT_PATH=\"../../test/${{ env.job_name }}.xml\" \\\n          || (echo \"Run 'make run_bpf_tests' locally to investigate failures\"; exit 1)\n      - name: Fetch JUnits\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        shell: bash\n        run: |\n          mkdir -p cilium-junits\n          cd test/\n          # junit_filename needs to be the same as the Job Name presented on the\n          # GH web UI - In the Summary page of a workflow run, left column\n          # \"Jobs\" - so that we can map the junit file to the right job - step\n          # pair on datastudio.\n          junit_filename=\"${{ env.job_name }}.xml\"\n          for filename in *.xml; do cp \"${filename}\" \"../cilium-junits/${junit_filename}\"; done;\n      - name: Upload JUnits [junit]\n        if: ${{ always() && steps.run-tests.outcome != 'skipped' }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: cilium-junits\n          path: cilium-junits/*.xml\n      - name: Publish Test Results As GitHub Summary\n        if: ${{ always() && runner.arch != 'ARM64' }}\n        uses: aanm/junit2md@332ebf0fddd34e91b03a832cfafaa826306558f9 # v0.0.3\n        with:\n          junit-directory: \"cilium-junits\"\n"
						}
					},
					{
						"name": "lint-build-commits.yaml",
						"object": {
							"text": "name: Build Commits\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n\n  # If the cache was cleaned we should re-build the cache with the latest commit\n  workflow_run:\n    workflows:\n     - \"Image CI Cache Cleaner\"\n    branches:\n     - main\n     - ft/main/**\n    types:\n     - completed\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\njobs:\n  compute-vars:\n    name: Compute variables\n    runs-on: ubuntu-24.04\n    outputs:\n      commits: ${{ steps.commits.outputs.commits }}\n      head-commit: ${{ steps.commits.outputs.head-commit }}\n      build-bpf: ${{ steps.bpf-changes.outputs.src }}\n      build-test: ${{ steps.test-changes.outputs.src }}\n    timeout-minutes: 180\n    steps:\n      - name: Configure git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n          fetch-depth: 0\n\n      - name: Compute commit list\n        id: commits\n        run: |\n          if [[ \"${{ github.event_name == 'push' || github.event_name == 'workflow_run' }}\" == \"true\" ]]; then\n            commits=${{ github.sha }}\n            head_commit=${{ github.sha }}\n          else\n            commits=$(git rev-list ${{ github.event.pull_request.base.sha }}..${{ github.event.pull_request.head.sha }} | tr '\\n' ' ')\n            head_commit=${{ github.event.pull_request.head.sha }}\n          fi\n          echo \"commits=$commits\" >> $GITHUB_OUTPUT\n          echo \"head-commit=$head_commit\" >> $GITHUB_OUTPUT\n\n      - name: Check bpf code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: bpf-changes\n        with:\n          # If these filters are modified, also modify the step:\n          # build-commits-bpf: Check if datapath build works for every commit\n          filters: |\n            src:\n              - 'bpf/**'\n              - '!**/*.md'\n\n      - name: Check test code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: test-changes\n        with:\n          # If these filters are modified, also modify the step:\n          # build-commits-test: Check if ginkgo test suite build works for every commit\n          filters: |\n            src:\n              - 'pkg/**'\n              - 'test/**'\n              - '!**/*.md'\n\n  build-commits-cilium:\n    name: Check if cilium builds for every commit\n    runs-on: ubuntu-24.04\n    needs: [compute-vars]\n    timeout-minutes: 180\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Configure git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n          fetch-depth: 0\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Load Golang cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-all-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-all-cache-\n            ${{ runner.os }}-go-\n\n      - name: Load ccache cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: ccache-cache\n        with:\n          path: /tmp/.cache/ccache\n          key: ${{ runner.os }}-ccache-${{ hashFiles('bpf/**') }}\n          restore-keys: |\n            ${{ runner.os }}-ccache-\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' || steps.ccache-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/go/.cache/go-build\n          mkdir -p /tmp/.cache/go/pkg\n          mkdir -p /tmp/.cache/ccache/.ccache\n\n      - name: Check if build works for every commit\n        if: ${{ github.event_name != 'push' || ( (github.event_name == 'push' || github.event_name == 'workflow_run' ) && (steps.go-cache.outputs.cache-hit != 'true' || steps.ccache-cache.outputs.cache-hit != 'true')) }}\n        env:\n          CLANG: \"ccache clang\"\n          BUILDER_GOCACHE_DIR: \"/tmp/.cache/go/.cache/go-build\"\n          BUILDER_GOMODCACHE_DIR: \"/tmp/.cache/go/pkg\"\n          BUILDER_CCACHE_DIR: \"/tmp/.cache/ccache/.ccache\"\n        run: |\n          set -eu -o pipefail\n          commits=\"${{ needs.compute-vars.outputs.commits }}\"\n          for commit in $commits; do\n            git checkout $commit || exit 1\n            contrib/scripts/builder.sh make CLANG=\"${CLANG}\" build -j \"$(nproc)\" || exit 1\n          done\n\n      - name: Reset cache ownership to GitHub runners user\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' || steps.ccache-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          sudo du -sh /tmp/.cache/\n          sudo chown $USER:$USER -R /tmp/.cache\n\n      - name: Failed commit during the build\n        if: ${{ failure() }}\n        run: git --no-pager log --format=%B -n 1\n\n  build-commits-hubble-cli:\n    name: Check if hubble-cli builds for every commit\n    runs-on: ubuntu-24.04\n    needs: [compute-vars]\n    timeout-minutes: 180\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Configure git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n          fetch-depth: 0\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Load hubble-cli Golang cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: hubble-cache\n        with:\n          path: /tmp/.cache/hubble-cli\n          key: ${{ runner.os }}-go-hubble-cli-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-hubble-cli-cache-\n            ${{ runner.os }}-go-\n\n      - name: Load ccache cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: ccache-cache\n        with:\n          path: /tmp/.cache/ccache\n          key: ${{ runner.os }}-ccache-${{ hashFiles('bpf/**') }}\n          restore-keys: |\n            ${{ runner.os }}-ccache-\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.ccache-cache.outputs.cache-hit != 'true' || steps.hubble-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/ccache/.ccache\n          mkdir -p /tmp/.cache/hubble-cli/.cache/go-build\n          mkdir -p /tmp/.cache/hubble-cli/pkg\n\n      - name: Check if hubble CLI builds for every commit\n        if: ${{ github.event_name != 'push' || ( github.event_name == 'push' && steps.hubble-cache.outputs.cache-hit != 'true' ) }}\n        env:\n          CLANG: \"ccache clang\"\n          BUILDER_GOCACHE_DIR: \"/tmp/.cache/hubble-cli/.cache/go-build\"\n          BUILDER_GOMODCACHE_DIR: \"/tmp/.cache/hubble-cli/pkg\"\n        run: |\n          set -eu -o pipefail\n          commits=\"${{ needs.compute-vars.outputs.commits }}\"\n          head_commit=\"${{ needs.compute-vars.outputs.head-commit }}\"\n          for commit in $commits; do\n            git checkout $commit || exit 1\n            echo \"Only run full build (with \\`local-release\\`) for head commit (i.e. last commit in sequence)\"\n            target=hubble\n            if [[ \"$commit\" == \"$head_commit\" ]]; then\n              target=local-release\n            fi\n            echo \"Running build: $target (commit: $commit)\"\n            contrib/scripts/builder.sh make CLANG=\"${CLANG}\" -C hubble $target -j \"$(nproc)\" || exit 1\n          done\n\n      - name: Reset cache ownership to GitHub runners user\n        if: ${{ steps.ccache-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          sudo du -sh /tmp/.cache/\n          sudo chown $USER:$USER -R /tmp/.cache\n\n      - name: Failed commit during the build\n        if: ${{ failure() }}\n        run: git --no-pager log --format=%B -n 1\n\n  build-commits-bpf:\n    name: Check if bpf builds for every commit\n    runs-on: ubuntu-24.04\n    needs: [compute-vars]\n    # Runs only if code under bpf/ is changed.\n    if: needs.compute-vars.outputs.build-bpf == 'true'\n    timeout-minutes: 180\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Configure git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n          fetch-depth: 0\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Load Golang cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: go-cache\n        with:\n          path: /tmp/.cache/go\n          key: ${{ runner.os }}-go-all-cache-${{ hashFiles('**/go.sum') }}\n          restore-keys: |\n            ${{ runner.os }}-go-all-cache-\n            ${{ runner.os }}-go-\n\n      - name: Load ccache cache build from GitHub\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: ccache-cache\n        with:\n          path: /tmp/.cache/ccache\n          key: ${{ runner.os }}-ccache-${{ hashFiles('bpf/**') }}\n          restore-keys: |\n            ${{ runner.os }}-ccache-\n\n      - name: Create cache directories if they don't exist\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' || steps.ccache-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          mkdir -p /tmp/.cache/go/.cache/go-build\n          mkdir -p /tmp/.cache/go/pkg\n          mkdir -p /tmp/.cache/ccache/.ccache\n\n      - name: Check if datapath build works for every commit\n        env:\n          CLANG: \"ccache clang\"\n          BUILDER_GOCACHE_DIR: \"/tmp/.cache/go/.cache/go-build\"\n          BUILDER_GOMODCACHE_DIR: \"/tmp/.cache/go/pkg\"\n          BUILDER_CCACHE_DIR: \"/tmp/.cache/ccache/.ccache\"\n        run: |\n          set -eu -o pipefail\n          commits=\"${{ needs.compute-vars.outputs.commits }}\"\n          for commit in $commits; do\n            git checkout $commit || exit 1\n            # Do not run make if there aren't any files modified in these\n            # directories from the previous commit to the current commit.\n            # If these filters are modified, also modify the step:\n            # compute-vars: Check bpf code changes\n            if ! git diff --quiet HEAD^ bpf/ ; then\n              contrib/scripts/builder.sh make CLANG=\"${CLANG}\" -C bpf build_all -j \"$(nproc)\" || exit 1\n            fi\n          done\n\n      - name: Reset cache ownership to GitHub runners user\n        if: ${{ steps.go-cache.outputs.cache-hit != 'true' || steps.ccache-cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          sudo du -sh /tmp/.cache/\n          sudo chown $USER:$USER -R /tmp/.cache\n\n      - name: Failed commit during the build\n        if: ${{ failure() }}\n        run: git --no-pager log --format=%B -n 1\n\n  build-commits-test:\n    name: Check if test builds for every commit\n    runs-on: ubuntu-24.04\n    needs: [compute-vars]\n    # Runs only if code under test/ is changed.\n    if: needs.compute-vars.outputs.build-test == 'true'\n    timeout-minutes: 180\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Configure git\n        run: |\n          git config --global user.name \"GitHub Actions\"\n          git config --global user.email \"github-actions@users.noreply.github.com\"\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          ref: ${{ github.event.pull_request.head.sha }}\n          fetch-depth: 0\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache: false\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Set clang directory\n        id: set_clang_dir\n        run: echo \"clang_dir=$HOME/.clang\" >> $GITHUB_OUTPUT\n\n      - name: Install LLVM and Clang prerequisites\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y --no-install-recommends libtinfo6\n\n      - name: Install LLVM and Clang\n        uses: KyleMayes/install-llvm-action@a7a1a882e2d06ebe05d5bb97c3e1f8c984ae96fc # v2.0.7\n        with:\n          version: \"19.1.7\"\n          directory: ${{ steps.set_clang_dir.outputs.clang_dir }}\n\n      - name: Install ginkgo\n        run: |\n          go install github.com/onsi/ginkgo/ginkgo@cc0216944b25a88d3259699a029d4e601fb8a222 # v1.12.1\n\n      - name: Check if ginkgo test suite build works for every commit\n        run: |\n          set -eu -o pipefail\n          commits=\"${{ needs.compute-vars.outputs.commits }}\"\n          for commit in $commits; do\n            git checkout $commit || exit 1\n            # Do not run make if there aren't any files modified in these\n            # directories from the previous commit to the current commit.\n            # If these filters are modified, also modify the step:\n            # compute-vars: Check test code changes\n            if ! git diff --quiet HEAD^ pkg/ test/ ; then\n              (make -C test build -j \"$(nproc)\" && make -C test build-darwin -j \"$(nproc)\") || exit 1\n            fi\n          done\n\n      - name: Failed commit during the build\n        if: ${{ failure() }}\n        run: git --no-pager log --format=%B -n 1\n"
						}
					},
					{
						"name": "lint-codeowners.yaml",
						"object": {
							"text": "name: CODEOWNERS Checks\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request:\n    branches:\n      - main\n      - ft/main/**\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}\n  cancel-in-progress: true\n\njobs:\n  check_changes:\n    name: Deduce required tests from code changes\n    runs-on: ubuntu-24.04\n    outputs:\n      added-files: ${{ steps.changes.outputs.added-files }}\n      deleted-files: ${{ steps.changes.outputs.deleted-files }}\n      codeowners-changed: ${{ steps.changes.outputs.codeowners-changed }}\n    steps:\n      - name: Check code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: changes\n        with:\n          filters: |\n            added-files:\n              - added: '**'\n            deleted-files:\n              - deleted: '**'\n            codeowners-changed:\n              - 'CODEOWNERS'\n              - '.github/workflows/lint-codeowners.yaml'\n\n  codeowners:\n    needs: check_changes\n    if: ${{ needs.check_changes.outputs.codeowners-changed == 'true' || needs.check_changes.outputs.added-files == 'true' || needs.check_changes.outputs.deleted-files == 'true' }}\n    name: Check CODEOWNERS consistency\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # Hard-code the path instead of using ${{ github.repository }}\n          # to make sure it works for forked repo as well.\n          path: src/github.com/cilium/cilium\n\n      - name: Check if all files have attributed code owners\n        if: ${{ needs.check_changes.outputs.codeowners-changed == 'true' || needs.check_changes.outputs.added-files == 'true' }}\n        run: |\n          # CODEOWNERS patterns follows nearly the same syntax as a .gitignore.\n          # To check if all files are covered by patterns other than the\n          # catch-all '*', we turn the file into a .gitignore and list\n          # unmatched files.\n          cd src/github.com/cilium/cilium\n          # Copy all patterns from CODEOWNERS, but skipping the comments\n          # ('^[^#]') and the catch-all '*' rule (the only one with a single\n          # character, we skip it with '^.[^ ]').\n          awk '/^[^#][^ ]/ {print $1}' CODEOWNERS > .gitignore\n          # Reinitialize the repo and list all files NOT covered by .gitignore.\n          rm -rf .git\n          git init -q\n          if [[ -n \"$(git ls-files --others -X .gitignore)\" ]]; then\n              echo '::error title=missing_code_owners::Following files have no owners in CODEOWNERS:'\n              git ls-files --others -X .gitignore\n              exit 1\n          fi\n\n      - name: Check if CODEOWNERS has stale entries\n        if: ${{ needs.check_changes.outputs.codeowners-changed == 'true' || needs.check_changes.outputs.deleted-files == 'true' }}\n        run: |\n          cd src/github.com/cilium/cilium\n          EXIT_STATUS=0\n          # We go through the patterns in CODEOWNERS, and for each of them we\n          # search for corresponding files in the repo.\n          # shellcheck disable=SC2046\n          while read l; do\n              case \"${l}\" in\n                  /CHANGELOG.md)\n                      # Special case: This file doesn't always exist, but it\n                      # may be temporarily created on 'main' branch during the\n                      # preparation of a preview release. Skip it as it's not\n                      # important to track the staleness.\n                      ;;\n                  /*)\n                      # The pattern should match from the root of the repo,\n                      # we'll use 'ls'. For now, just append pattern to $LIST.\n                      LIST+=\" ${l#/}\"\n                      ;;\n                  *)\n                      # No leading slash: may not be at the root of the repo,\n                      # search with 'find'. Print pattern if no file found.\n                      if [[ -z $(find . -path \"*${l}*\" -print -quit) ]]; then\n                          echo \"${l}\"\n                          EXIT_STATUS=1\n                      fi\n                      ;;\n              esac\n          done <<< $(awk '/^[^#][^ ]/ {print $1}' CODEOWNERS)\n          # Just one final call to 'ls' with all /* patterns found. Catch\n          # patterns with no corresponding files/directories from stderr.\n          # shellcheck disable=SC2012\n          STALE_PATTERNS=\"$(ls -- ${LIST} 2>&1 >/dev/null | sed \"s|.*'\\(.*\\)':.*|/\\1|\")\"\n          if [[ -n \"${STALE_PATTERNS}\" ]]; then\n              echo \"${STALE_PATTERNS}\" | sed 's/ /\\n/g'\n              EXIT_STATUS=1\n          fi\n          if [[ ${EXIT_STATUS} -ne 0 ]]; then\n              echo '::error title=stale_patterns::The patterns above should be removed from CODEOWNERS.'\n              exit ${EXIT_STATUS}\n          fi\n\n      - name: Check if all teams in CODEOWNERS rules are documented in the file\n        if: ${{ needs.check_changes.outputs.codeowners-changed == 'true' }}\n        run: |\n          EXIT_STATUS=0\n          # List all teams used in CODEOWNERS rules: discard comments and empty\n          # lines, discard lines with no team assigned (with no space in it),\n          # then discard the first field (pattern to match) for the remaining\n          # rules, split the list of teams by replacing spaces with line\n          # breaks, sort the results. Then grep for each team name among\n          # CODEOWNERS's comments.\n          cd src/github.com/cilium/cilium\n          # shellcheck disable=SC2013\n          for team in $(sed -e '/^\\(#\\|$\\)/d' -e '/^[^ ]*$/d' -e 's/^[^ #]\\+ //' -e 's/ /\\n/g' CODEOWNERS | sort -u); do\n              if ! grep -q \"^#[^@]*${team}\" CODEOWNERS; then\n                  echo \"${team}\";\n                  EXIT_STATUS=1\n              fi;\n          done\n          if [[ ${EXIT_STATUS} -ne 0 ]]; then\n              echo '::error title=missing_team::The teams above are not documented in CODEOWNERS. Typo?'\n              exit ${EXIT_STATUS}\n          fi\n"
						}
					},
					{
						"name": "lint-go.yaml",
						"object": {
							"text": "name: Go Related Checks\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n  # Add this workflow to be triggered by merge queue events\n  merge_group:\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after || github.event.merge_group && github.run_id }}\n  cancel-in-progress: ${{ !github.event.merge_group }}\n\njobs:\n  go-mod:\n    name: Check Go Modules\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n      - name: Check module vendoring\n        run: |\n          go mod tidy\n          go mod vendor\n          test -z \"$(git status --porcelain)\" || (echo \"please run 'go mod tidy && go mod vendor', and submit your changes\"; exit 1)\n\n  license-check:\n    name: Check third party dependencies licenses\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n      - name: Check for unauthorized dependencies\n        run: go run ./tools/licensecheck ./... 2>/dev/null\n\n  golangci:\n    name: Lint Source Code\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n      - name: Run golangci-lint\n        uses: golangci/golangci-lint-action@4afd733a84b1f43292c63897423277bb7f4313a9 # v8.0.0\n        with:\n          # renovate: datasource=docker depName=golangci/golangci-lint\n          version: v2.4.0\n          skip-cache: true\n          args: \"--verbose --modules-download-mode=vendor\"\n\n  precheck:\n    runs-on: ubuntu-24.04\n    name: Precheck\n    steps:\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n      - name: Executables check\n        run: |\n          cd src/github.com/cilium/cilium\n          HELP=\"check permissions of files and allowlist them in contrib/executable_list.txt if you are adding a new executable\"\n          make check-permissions || (echo $HELP; exit 1)\n      - name: Go code prechecks\n        run: |\n          cd src/github.com/cilium/cilium\n          make precheck\n      - name: Custom linters\n        run: |\n          cd src/github.com/cilium/cilium\n          make custom-lint\n\n  generate-api:\n    runs-on: ubuntu-24.04\n    name: Generate API\n    steps:\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n      - name: Check api generated files\n        env:\n          BUILDER_GOCACHE_DIR: \"/tmp/.cache/go/.cache/go-build\"\n          BUILDER_GOMODCACHE_DIR: \"/tmp/.cache/go/pkg\"\n        run: |\n          cd src/github.com/cilium/cilium\n          contrib/scripts/check-api-code-gen.sh\n\n  generate-k8s-api:\n    runs-on: ubuntu-24.04\n    name: Generate k8s API\n    steps:\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n      - name: Check k8s generated files\n        env:\n          BUILDER_GOCACHE_DIR: \"/tmp/.cache/go/.cache/go-build\"\n          BUILDER_GOMODCACHE_DIR: \"/tmp/.cache/go/pkg\"\n        run: |\n          # Set GOBIN to ensure 'go install' binaries end up in the same directory\n          # as the one actions/setup-go adds to PATH, regardless of GOPATH.\n          export GOBIN=\"$HOME/go/bin\"\n\n          cd src/github.com/cilium/cilium\n          contrib/scripts/check-k8s-code-gen.sh\n"
						}
					},
					{
						"name": "lint-images-base.yaml",
						"object": {
							"text": "name: Base Image Lint\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request:\n    types:\n      - opened\n      - synchronize\n      - reopened\n  push:\n    branches:\n      - main\n      - ft/main/**\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\njobs:\n  lint:\n    name: Lint image build logic\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout base or default branch (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          # We first check if base_ref exist, meaning we're in pull_request context, and if not we just use default_branch\n          ref: ${{ github.base_ref || github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Set runtime image env variable\n        uses: ./.github/actions/set-runtime-image\n        with:\n          repository: ${{ env.CILIUM_RUNTIME_IMAGE_PREFIX }}\n\n      - uses: docker://quay.io/cilium/image-maker:7de7f1c855ce063bdbe57fdfb28599a3ad5ec8f1@sha256:dde8500cbfbb6c41433d376fdfcb3831e2df9cec50cf4f49e8553dc6eba74e72\n        name: Run make lint\n        with:\n          entrypoint: make\n          args: -C images lint\n\n      - uses: docker://quay.io/cilium/image-maker:7de7f1c855ce063bdbe57fdfb28599a3ad5ec8f1@sha256:dde8500cbfbb6c41433d376fdfcb3831e2df9cec50cf4f49e8553dc6eba74e72\n        name: Check if builder image is up-to-date\n        with:\n          entrypoint: make\n          args: -C images check-builder-image\n\n      - uses: docker://quay.io/cilium/image-maker:7de7f1c855ce063bdbe57fdfb28599a3ad5ec8f1@sha256:dde8500cbfbb6c41433d376fdfcb3831e2df9cec50cf4f49e8553dc6eba74e72\n        name: Check if runtime image is up-to-date\n        with:\n          entrypoint: make\n          args: -C images check-runtime-image RUNTIME_IMAGE=${{ env.CILIUM_RUNTIME_IMAGE }}\n\n      - name: Check Cilium Envoy image\n        run: make -C images check-envoy-image\n"
						}
					},
					{
						"name": "lint-workflows.yaml",
						"object": {
							"text": "name: GitHub Workflow Related Checks\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\njobs:\n  ginkgo-workflow-comments:\n    name: Lint Ginkgo Workflows Comments\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n\n      # Load Ginkgo build from GitHub\n      - name: Load ginkgo linter from GH cache\n        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4\n        id: cache\n        with:\n          path: /tmp/.ginkgo-build/\n          key: ${{ runner.os }}-ginkgo-linter-${{ hashFiles('src/github.com/cilium/cilium/**/*.go') }}\n\n      - name: Install Go\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          cache-dependency-path: \"src/github.com/cilium/cilium/*.sum\"\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Build Ginkgo\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium\n          go install github.com/onsi/ginkgo/ginkgo@v1.16.5\n          mkdir -p /tmp/.ginkgo-build\n\n      - name: Building Ginkgo Linter Test\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium\n          git apply contrib/testing/ginkgo-get-all-test-names.patch\n\n          cd test\n          /home/runner/go/bin/ginkgo build\n          strip test.test\n          tar -cz test.test -f test.tgz\n\n      - name: Store Ginkgo Linter Test in GitHub cache path\n        if: ${{ steps.cache.outputs.cache-hit != 'true' }}\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium\n          mkdir -p /tmp/.ginkgo-build/\n          if [ -f test/test.tgz ]; then\n            cp test/test.tgz /tmp/.ginkgo-build/\n            echo \"file copied\"\n          fi\n\n      - name: Copy Ginkgo binary\n        if: ${{ steps.cache.outputs.cache-hit == 'true' }}\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium/test/\n          tar -xf /tmp/.ginkgo-build/test.tgz\n\n      - name: Reading Comments From Workflows\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium\n\n          grep '# K8s' .github/actions/ginkgo/main-focus.yaml | \\\n          sed -e 's/^[[:space:]]\\+# //g' | \\\n          sort -u > /tmp/ginkgo-workflow-comments.txt\n\n          grep '# Runtime' .github/workflows/conformance-runtime.yaml | \\\n          sed -e 's/^[[:space:]]\\+# //g' | \\\n          sort -u > /tmp/runtime-workflow-comments.txt\n\n      - name: Getting test runs output\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium/test\n\n          ./test.test -ginkgo.failFast -ginkgo.dryRun -- --cilium.testScope=K8s | \\\n          grep TestRun | \\\n          grep -v 'TestRun\\[Top Level\\] Runtime' | \\\n          sed 's/TestRun\\[Top Level\\]\\ //g' | \\\n          sort -u > /tmp/ginkgo-tests.txt\n\n          ./test.test -ginkgo.failFast -ginkgo.dryRun -- --cilium.testScope=Runtime | \\\n          grep TestRun | \\\n          grep -v 'TestRun\\[Top Level\\] K8s' | \\\n          sed 's/TestRun\\[Top Level\\]\\ //g' | \\\n          sort -u > /tmp/runtime-tests.txt\n\n      - name: Checking diff Ginkgo Workflow\n        shell: bash\n        run: |\n          if ! diff /tmp/ginkgo-workflow-comments.txt /tmp/ginkgo-tests.txt --suppress-common-lines; then\n            echo \"\"\n            echo \"Ginkgo tests out of sync with comments from GH workflow:\"\n            echo \"$diff\"\n            echo \"Please fix the comments from .github/actions/ginkgo/main-focus.yaml accordingly\"\n            echo \"\"\n            exit 1\n          fi\n\n      - name: Checking diff Runtime Workflow\n        shell: bash\n        run: |\n          if ! diff /tmp/runtime-workflow-comments.txt /tmp/runtime-tests.txt --suppress-common-lines; then\n            echo \"\"\n            echo \"Ginkgo tests out of sync with comments from GH workflow:\"\n            echo \"$diff\"\n            echo \"\"\n            echo \"Please fix the comments from .github/workflows/conformance-runtime.yaml accordingly\"\n            exit 1\n          fi\n\n  ginkgo-schema-validation:\n    name: Validate Ginkgo Schema\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout\n        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0\n        with:\n          python-version: '3.10'\n      - name: Install yamela\n        run: pip install yamale\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n\n      - name: Validate schema of ginkgo action files\n        shell: bash\n        run: |\n          cd src/github.com/cilium/cilium/.github/actions/ginkgo/\n          for type in focus k8s-versions prs scheduled; do\n            yamale -s ${type}-schema.yaml ./*-${type}.yaml;\n          done\n\n  conformance-schema-validation:\n    name: Validate k8s Versions Schema\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout\n        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0\n        with:\n          python-version: '3.10'\n      - name: Install yamela\n        run: pip install yamale\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n\n      - name: Validate schema of aws, azure and gke action files\n        shell: bash\n        run: |\n          for dir in aws azure gke;do\n            dir_base=\".github/actions/${dir}\"\n            file_base=\"${dir_base}/k8s-versions\"\n            if [ -f ${file_base}.yaml ];then\n              yamale -s ${file_base}-schema.yaml ${file_base}.yaml;\n            fi\n            if [ -f ${dir_base}/test-config-schema.yaml ];then\n              yamale -s ${dir_base}/test-config-schema.yaml ${dir_base}/test-config-classic.yaml\n              yamale -s ${dir_base}/test-config-schema.yaml ${dir_base}/test-config-helm.yaml\n            fi\n          done\n\n  name-validation:\n    name: Validate Workflow Names\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          # hard-code the path instead of using ${{ github.repository }} to make sure it works for forked repo as well\n          path: src/github.com/cilium/cilium\n\n      - name: Validate Job and Step names\n        shell: bash\n        run: |\n          EXIT=0\n          cd src/github.com/cilium/cilium/.github/workflows\n          for FILE in *.yaml;do\n            JOBS=$(yq '.jobs | to_entries | .[] | select(.value.name == null) | \"  \" + .key' $FILE)\n            # shellcheck disable=SC2016\n            STEPS=$(yq '.jobs | to_entries | .[] as $job | $job.value.steps[] | {\"key\": $job.key, \"name\": .name} | select(.name == null) | \"  \"+.key' $FILE)\n            if [[ ${JOBS} =~ [^[:space:]] ]];then\n              echo Jobs are missing name field, in file $FILE\n              echo \"${JOBS}\" | awk '{for (i=1; i<=NF; i++) print \"  \" $i}'\n              EXIT=1\n            fi\n            if [[ ${STEPS} =~ [^[:space:]] ]];then\n              echo Steps are missing name field, under these Jobs in file $FILE\n              echo \"${STEPS}\" | awk '{for (i=1; i<=NF; i++) print \"  \" $i}'\n              EXIT=1\n            fi\n          done\n          exit ${EXIT}\n\n      - name: Validate Commit Status Start Job\n        shell: bash\n        run: |\n          EXIT=0\n          cd src/github.com/cilium/cilium/.github/workflows\n          for FILE in *.yaml; do\n            # we only care about workflows that has ariane workflow_dispatch events\n            IS_ARIANE_DISPATCH=$(yq '.on.workflow_dispatch.inputs.PR-number' $FILE)\n            if [ \"$IS_ARIANE_DISPATCH\" == \"null\" ]; then\n                continue\n            fi\n            JOB=$(yq '.jobs | to_entries | .[] | select(.key == \"commit-status-start\")' $FILE)\n            if [ \"$JOB\" == \"\" ]; then\n                echo \"commit-status-start job is missing in file $FILE\"\n                EXIT=1\n            fi\n            JOB_NAME=$(echo \"${JOB}\" | yq '.value.name')\n            if [ \"$JOB_NAME\" != \"Commit Status Start\" ]; then\n                echo \"commit-status-start job name must be set as 'Commit Status Start' in file $FILE\"\n                EXIT=1\n            fi\n          done\n          exit ${EXIT}\n\n      - name: Validate Absence of Trailing Spaces\n        shell: bash\n        working-directory: src/github.com/cilium/cilium/\n        run: |\n          if grep --quiet --recursive '[[:blank:]]$' .github; then\n            echo \"Found trailing spaces in the following workflow files\"\n            grep --files-with-matches --recursive '[[:blank:]]$' .github\n            echo\n            echo \"Please run:\"\n            echo \"  find .github -type f -exec sed -ri 's/[[:blank:]]+$//' {} \\;\"\n            echo \"If FreeBSD sed,(MacOS Default) run:\"\n            echo \"  find .github -type f -exec sed -i '' -E 's/[[:blank:]]+$//' {} \\;\"\n            echo \"and submit your changes\"\n            exit 1\n          fi\n\n      - name: Validate the runner\n        shell: bash\n        run: |\n          EXIT=0\n          cd src/github.com/cilium/cilium/.github/workflows\n          for FILE in *.yaml;do\n            JOBS=$(yq '.jobs | to_entries | .[] | select(.value.runs-on == \"ubuntu-latest\") | \"  \" + .key' $FILE)\n            if [[ ${JOBS} =~ [^[:space:]] ]];then\n              echo Jobs are using floating runner tag 'ubuntu-latest', in file $FILE\n              echo \"${JOBS}\" | awk '{for (i=1; i<=NF; i++) print \"  \" $i}'\n              EXIT=1\n            fi\n          done\n          exit ${EXIT}\n\n  actionlint:\n    name: actionlint\n    runs-on: ubuntu-24.04\n    steps:\n      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5\n        name: checkout\n      - name: Setup actionlint matcher\n        run: echo \"::add-matcher::.github/actionlint-matcher.json\"\n      - name: Check workflow files\n        uses: docker://rhysd/actionlint:1.7.7@sha256:887a259a5a534f3c4f36cb02dca341673c6089431057242cdc931e9f133147e9\n        env:\n          SHELLCHECK_OPTS: --exclude=SC2086,SC2129,SC2185,SC2162,SC2090,SC2089,SC2001,SC2002\n        with:\n          args: -color\n"
						}
					},
					{
						"name": "needs-more-info.yaml",
						"object": {
							"text": "name: Issue Info Complete\n\n# This workflow is triggered on issue comments.\non:\n  issue_comment:\n    types: created\n\njobs:\n  applyNeedsAttentionLabel:\n    name: Apply Info Complete Label\n    runs-on: ubuntu-24.04\n    permissions:\n      issues: write\n    steps:\n      - name: Apply Needs Attention Label\n        uses: hramos/needs-attention@d0eaa7f961c04d4da86466b1176b56e0d4089022 # v2.0.0\n        with:\n            repo-token: ${{ secrets.GITHUB_TOKEN }}\n            response-required-label: 'need-more-info'\n            needs-attention-label: 'info-completed'\n"
						}
					},
					{
						"name": "net-perf-gke.yaml",
						"object": {
							"text": "name: Network performance GKE (net-perf-gke)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  schedule:\n    - cron: '39 0 * * 1-5'\n\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  clusterName: ${{ github.event.repository.name }}-${{ github.run_id }}-${{ github.run_attempt }}\n  test_name: gke-perf\n  USE_GKE_GCLOUD_AUTH_PLUGIN: True\n  gcp_zone: us-east5-a\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  installation-and-perf:\n    name: Installation and Perf Test\n    needs: wait-for-images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 60\n    env:\n      job_name: \"Installation and Perf Test\"\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - index: 0\n            name: \"baseline\"\n            mode: \"baseline\"\n            encryption: \"baseline\"\n\n          - index: 1\n            name: \"native\"\n            mode: \"gke\"\n            encryption: \"none\"\n\n          - index: 2\n            name: \"tunnel\"\n            mode: \"tunnel\"\n            encryption: \"none\"\n\n          - index: 3\n            name: \"native-ipsec\"\n            mode: \"gke\"\n            encryption: \"ipsec\"\n\n          - index: 4\n            name: \"tunnel-ipsec\"\n            mode: \"tunnel\"\n            encryption: \"ipsec\"\n\n          - index: 5\n            name: \"native-wireguard\"\n            mode: \"gke\"\n            encryption: \"wireguard\"\n\n          - index: 6\n            name: \"tunnel-wireguard\"\n            mode: \"tunnel\"\n            encryption: \"wireguard\"\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./install/kubernetes/cilium\n          debug: false\n\n      - name: Truncate owner label for GKE\n        id: truncate-owner\n        uses: ./.github/actions/truncate-label\n        with:\n          label: ${{ (github.event_name == 'workflow_dispatch' || github.event.pull_request) && inputs.PR-number || github.ref_name }}\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          OWNER=\"${{ steps.truncate-owner.outputs.truncated_label }}\"\n\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cluster.name=${{ env.clusterName }}-${{ matrix.index }} \\\n            --helm-set=agentNotReadyTaintKey=ignore-taint.cluster-autoscaler.kubernetes.io/cilium-agent-not-ready \\\n            --wait=false \\\n            --datapath-mode=${{ matrix.mode }}\"\n\n          if [ \"${{ matrix.encryption }}\" = \"ipsec\" ] ; then\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set=encryption.enabled=true --helm-set=encryption.type=ipsec\"\n          fi\n\n          if [ \"${{ matrix.encryption }}\" = \"wireguard\" ] ; then\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set=encryption.enabled=true --helm-set=encryption.type=wireguard\"\n          fi\n\n          CILIUM_INSTALL_DEFAULTS+=\" ${{ env.CILIUM_INSTALL_NET_PERF_EXTRA_ARGS }}\"\n\n          NODE_TAINTS=\"ignore-taint.cluster-autoscaler.kubernetes.io/cilium-agent-not-ready=true:NoExecute\"\n\n          if [ \"${{ matrix.mode }}\" = \"baseline\" ] ; then\n            NODE_TAINTS=\"\"\n          fi\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n          echo node_taints=${NODE_TAINTS} >> $GITHUB_OUTPUT\n\n      - name: Set up gcloud credentials\n        id: 'auth'\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Set up gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Install gke-gcloud-auth-plugin\n        run: |\n          gcloud components install gke-gcloud-auth-plugin\n\n      - name: Display gcloud CLI info\n        run: |\n          gcloud info\n\n      - name: Create GKE cluster\n        id: create-cluster\n        uses: ./.github/actions/setup-gke-cluster\n        with:\n          cluster-name: ${{ env.clusterName }}-${{ matrix.index }}\n          zone: ${{ env.gcp_zone }}\n          node-taints: ${{ steps.vars.outputs.node_taints }}\n          labels: \"usage=${{ github.repository_owner }}-${{ github.event.repository.name }},owner=${{ steps.vars.outputs.owner }}\"\n\n      - name: Create ESP allow firewall rule\n        if: ${{ matrix.name == 'tunnel-ipsec' }}\n        uses: ./.github/actions/gke-create-esp-rule\n        with:\n          cluster_name: ${{ env.clusterName }}-${{ matrix.index }}\n          cluster_zone: ${{ env.gcp_zone }}\n\n      - name: Get cluster credentials\n        run: |\n          gcloud container clusters get-credentials ${{ env.clusterName }}-${{ matrix.index }} --zone ${{ env.gcp_zone }}\n\n      - name: Generate cilium-cli kubeconfig\n        id: gen-kubeconfig\n        uses: ./.github/actions/get-cloud-kubeconfig\n        with:\n          kubeconfig: \"~/.kube/config\"\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.default_vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n          kubeconfig: ${{ steps.gen-kubeconfig.outputs.kubeconfig_path }}\n\n      - name: Create custom IPsec secret\n        if: ${{ matrix.encryption == 'ipsec' }}\n        run: |\n          cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n\n      - name: Install Cilium\n        if: ${{ matrix.mode != 'baseline' }}\n        id: install-cilium\n        run: |\n          cilium install --dry-run-helm-values ${{ steps.vars.outputs.cilium_install_defaults }} --helm-set=ipv4NativeRoutingCIDR=${{ steps.create-cluster.outputs.native_cidr }}\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }} --helm-set=ipv4NativeRoutingCIDR=${{ steps.create-cluster.outputs.native_cidr }}\n\n      - name: Wait for Cilium to be ready\n        if: ${{ matrix.mode != 'baseline' }}\n        run: |\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods -n kube-system\n          kubectl -n kube-system exec daemonset/cilium -- cilium-dbg status\n\n      - name: Run perf test (${{ matrix.name }})\n        id: run-perf\n        run: |\n          mkdir output\n          cilium connectivity perf --duration=30s --host-net=true --pod-net=true --crr=true --report-dir=./output --unsafe-capture-kernel-profiles\n          sudo chmod -R +r ./output\n\n      - name: Run common post steps\n        if: ${{ always() && matrix.mode != 'baseline' }}\n        uses: ./.github/actions/post-logic\n        with:\n          always_capture_sysdump: true\n          artifacts_suffix: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }})\"\n          job_status: \"${{ job.status }}\"\n\n      - name: Clean up ESP allow firewall rule\n        if: ${{ always() && matrix.name == 'tunnel-ipsec' }}\n        uses: ./.github/actions/gke-clean-esp-rule\n        with:\n          cluster_name: ${{ env.clusterName }}-${{ matrix.index }}\n          cluster_zone: ${{ env.gcp_zone }}\n\n      - name: Clean up GKE\n        if: ${{ always() }}\n        run: |\n          while [ \"$(gcloud container operations list --zone ${{ env.gcp_zone }} --filter=\"status=RUNNING AND targetLink~${{ env.clusterName }}-${{ matrix.index }}\" --format=\"value(name)\")\" ];do\n            echo \"cluster has an ongoing operation, waiting for all operations to finish\"; sleep 15\n          done\n          gcloud container clusters delete ${{ env.clusterName }}-${{ matrix.index }} --zone ${{ env.gcp_zone }} --quiet --async\n        shell: bash {0} # Disable default fail-fast behavior so that all commands run independently\n\n      # We needed to configure a unique suffix to ensure that the artifacts can\n      # be correctly uploaded, but we want the sysdump to have a fixed name when\n      # uploading it to the GS bucket.\n      - name: Rename sysdump before uploading it to the GS bucket\n        if : ${{ always() && matrix.mode != 'baseline' }}\n        run: |\n          mv \"cilium-sysdump-${{ env.job_name }} (${{ join(matrix.*, ', ') }}).zip\" cilium-sysdump-final.zip\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-perf.outcome != 'skipped' && steps.run-perf.outcome != 'cancelled' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ env.test_name }}-${{ matrix.name }}\n          tested_sha: ${{ inputs.SHA || github.sha }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          artifacts: ./output/\n          results_regex: 'NetworkPerformance*'\n          other_files: ${{ matrix.mode != 'baseline' && 'cilium-sysdump-final.zip' || '' }}\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: installation-and-perf\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.installation-and-perf.result }}\n"
						}
					},
					{
						"name": "push-chart-ci.yaml",
						"object": {
							"text": "name: Chart CI Push\n\non:\n  workflow_call:\n    inputs:\n      checkout_ref:\n        description: 'Git ref to build.'\n        type: string\n        required: true\n      image_tag:\n        description: 'Image tag to use for the images in the chart.'\n        type: string\n        required: true\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n\nconcurrency:\n  # We do not use ${{ github.workflow }} because when triggered via\n  # workflow_call, the value of it is the same as the calling workflow, which\n  # could result in this job cancelling it's caller if the group names conflicted\n  group: |\n    chart-ci-push-${{ github.event_name }}-${{ inputs.checkout_ref }}\n  cancel-in-progress: true\n\njobs:\n  setup-charts:\n    name: Setup Charts\n    runs-on: ubuntu-24.04\n    outputs:\n      chart-version: ${{ steps.get-version.outputs.chart_version }}\n    steps:\n    - name: Checkout GitHub main\n      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n      with:\n        ref: ${{ github.event.repository.default_branch }}\n        persist-credentials: false\n\n    # We do this to ensure that we don't run arbitrary scripts\n    - name: Copy default branch chart version script\n      run: |\n        mkdir -p ../cilium-default-branch/contrib/scripts\n        if [[ -f ./contrib/scripts/print-chart-version.sh ]]; then\n          cp ./contrib/scripts/print-chart-version.sh ../cilium-default-branch/contrib/scripts\n        else\n          echo \"./contrib/scripts/print-chart-version.sh missing. Perhaps it needs to be backported to your target branch?\"\n          exit 1\n        fi\n\n    - name: Checkout Source Code\n      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n      with:\n        persist-credentials: false\n        ref: ${{ inputs.checkout_ref }}\n        # required for git describe\n        fetch-depth: 0\n\n    - name: Get version\n      id: get-version\n      run: |\n        set -o pipefail\n        set -e\n        # print-chart-version.sh expects the VERSION file in a specific location, so copy it there\n        cp VERSION ../cilium-default-branch\n        echo \"chart_version=$(../cilium-default-branch/contrib/scripts/print-chart-version.sh)\" | tee -a $GITHUB_OUTPUT\n\n  push-charts:\n    name: Push Charts\n    runs-on: ubuntu-24.04\n    needs: setup-charts\n    steps:\n    - name: Checkout GitHub Actions definitions\n      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n      with:\n        persist-credentials: false\n        ref: ${{ github.event.repository.default_branch }}\n        sparse-checkout: .github/actions\n\n    - name: Set Environment Variables\n      uses: ./.github/actions/set-env-variables\n\n    - name: Checkout Feature Branch Code\n      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n      with:\n        persist-credentials: false\n        ref: ${{ inputs.checkout_ref }}\n        sparse-checkout: install/kubernetes/cilium\n\n    - name: Push charts\n      uses: cilium/reusable-workflows/.github/actions/push-helm-chart@6ae27958f2f37545bf48e44106b73df05b1f6d12 # v0.1.0\n      with:\n        name: cilium\n        path: install/kubernetes/cilium\n        version: ${{ needs.setup-charts.outputs.chart-version }}\n        values_file_changes: |\n          {\n\n            \"image.repository\": \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci\",\n            \"image.tag\": \"${{ inputs.image_tag }}\",\n            \"image.digest\": \"\",\n            \"image.useDigest\": false,\n            \"preflight.image.repository\": \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci\",\n            \"preflight.image.tag\": \"${{ inputs.image_tag }}\",\n            \"preflight.image.digest\": \"\",\n            \"preflight.image.useDigest\": false,\n            \"operator.image.repository\": \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator\",\n            \"operator.image.suffix\": \"-ci\",\n            \"operator.image.genericDigest\": \"\",\n            \"operator.image.azureDigest\": \"\",\n            \"operator.image.awsDigest\": \"\",\n            \"operator.image.alibabacloudDigest\": \"\",\n            \"operator.image.useDigest\": false,\n            \"operator.image.tag\": \"${{ inputs.image_tag }}\",\n            \"hubble.relay.image.repository\": \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci\",\n            \"hubble.relay.image.tag\": \"${{ inputs.image_tag }}\",\n            \"hubble.relay.image.digest\": \"\",\n            \"hubble.relay.image.useDigest\": false,\n            \"clustermesh.apiserver.image.repository\": \"quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/clustermesh-apiserver-ci\",\n            \"clustermesh.apiserver.image.tag\": \"${{ inputs.image_tag }}\",\n            \"clustermesh.apiserver.image.digest\": \"\",\n            \"clustermesh.apiserver.image.useDigest\": false\n          }\n        registry: quay.io\n        registry_namespace: ${{ env.QUAY_CHARTS_ORGANIZATION_DEV }}\n        registry_username: ${{ secrets.QUAY_CHARTS_DEV_USERNAME }}\n        registry_password: ${{ secrets.QUAY_CHARTS_DEV_PASSWORD }}\n\n  post-push:\n    name: Post-push steps\n    runs-on: ubuntu-24.04\n    needs:\n      - setup-charts\n      - push-charts\n    steps:\n    - name: Checkout GitHub Actions definitions\n      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n      with:\n        persist-credentials: false\n        ref: ${{ github.event.repository.default_branch }}\n        sparse-checkout: .github/actions\n\n    - name: Set Environment Variables\n      uses: ./.github/actions/set-env-variables\n\n    - name: Print helm command\n      env:\n        CHART_VERSION: ${{ needs.setup-charts.outputs.chart-version }}\n      run: |\n        echo \"Example commands:\"\n        echo helm template -n kube-system oci://quay.io/${{ env.QUAY_CHARTS_ORGANIZATION_DEV }}/cilium --version \"$CHART_VERSION\"\n        echo helm install cilium -n kube-system  oci://quay.io/${{ env.QUAY_CHARTS_ORGANIZATION_DEV }}/cilium --version \"$CHART_VERSION\"\n"
						}
					},
					{
						"name": "release.yaml",
						"object": {
							"text": "name: Release Tool\n\non:\n  workflow_dispatch:\n    inputs:\n      step:\n        description: 'Which step do you want to (re-)run?'\n        required: true\n        type: choice\n        options:\n          - 2-prepare-release\n          - 4-post-release\n          - 5-publish-helm\n      version:\n        description: 'Which version are you releasing? (e.g. vX.Y.Z[-(pre|rc).W])'\n        required: true\n        type: string\n        default: vX.Y.Z\n\n  workflow_call:\n    inputs:\n      step:\n        description: 'Which step do you want to (re-)run?'\n        required: true\n        type: string\n      version:\n        description: 'Which version are you releasing? (e.g. vX.Y.Z[-(pre|rc).W])'\n        required: true\n        type: string\n\npermissions:\n  # To be able to access the repository with `actions/checkout`\n  contents: read\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ inputs.version }}-${{ inputs.step }}\n  cancel-in-progress: true\n\njobs:\n  release:\n    name: Release\n    environment: release-tool\n    timeout-minutes: 40\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          # renovate: datasource=golang-version depName=go\n          go-version: 1.25.1\n\n      - name: Install helm\n        if: ${{ inputs.step == '5-publish-helm' }}\n        shell: bash\n        run: |\n          # We don't want renovate to update this version, because we want to\n          # use a specific version of helm for the release tool to avoid\n          # breaking the release process.\n          HELM_VERSION=v3.18.5\n          wget \"https://get.helm.sh/helm-${HELM_VERSION}-linux-amd64.tar.gz\"\n          tar -xf \"helm-${HELM_VERSION}-linux-amd64.tar.gz\"\n          sudo mv ./linux-amd64/helm /usr/local/bin\n\n      - name: Get token\n        id: get_token\n        uses: cilium/actions-app-token@61a6271ce92ba02f49bf81c755685d59fb25a59a # v0.21.1\n        with:\n          APP_PEM: ${{ secrets.CILIUM_RELEASE_BOT_PEM }}\n          APP_ID: ${{ secrets.CILIUM_RELEASE_BOT_APP_ID }}\n\n      - name: Authenticate with GH CLI\n        run: |\n          gh auth login --with-token <<< \"${{ steps.get_token.outputs.app_token }}\"\n\n      - name: Checkout release tool\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          repository: cilium/release\n          path: \"./release\"\n\n      - name: Move release source code to upper directory\n        run: mv release ../\n\n      - name: Checkout helm chart\n        if: ${{ inputs.step == '5-publish-helm' }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          repository: cilium/charts\n          path: \"./cilium-charts\"\n\n      - name: Set up charts repository git configuration\n        if: ${{ inputs.step == '5-publish-helm' }}\n        shell: bash\n        run: |\n          mv cilium-charts ../charts\n          cd ../charts\n          git config user.name \"Cilium Release Bot\"\n          git config user.email \"noreply@cilium.io\"\n          git remote set-url origin https://x-access-token:${{ steps.get_token.outputs.app_token }}@github.com/cilium/charts.git\n          git remote set-head origin --auto\n\n      - name: Checkout cilium source code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.event.repository.default_branch }}\n          persist-credentials: false\n\n      - name: Build release tool\n        shell: bash\n        run: |\n          cd ../release\n          make\n\n      - name: Set-up git\n        run: |\n          git config user.name \"Cilium Release Bot\"\n          git config user.email \"noreply@cilium.io\"\n          git remote set-url origin https://x-access-token:${{ steps.get_token.outputs.app_token }}@github.com/${{ github.repository }}.git\n\n      - name: Run release tool\n        shell: bash\n        env:\n          GITHUB_TOKEN: \"${{ steps.get_token.outputs.app_token }}\"\n          ORG: \"${{ github.repository_owner }}\"\n        run: |\n          cd ../release\n          ./release start \\\n            --force \\\n            --release-tool-dir \"$(pwd)\" \\\n            --charts-repo-dir \"$(pwd)/../charts\" \\\n            --repo-dir \"$(pwd)/../cilium\" \\\n            --repo ${{ github.repository }} \\\n            --target-version ${{ inputs.version }} \\\n            --steps ${{ inputs.step }} \\\n            --exclude-labels \"cilium-cli-exclusive\"\n\n      - name: Wait for helm chart PR checks and merge\n        if: ${{ inputs.step == '5-publish-helm' }}\n        shell: bash\n        env:\n          GITHUB_TOKEN: \"${{ steps.get_token.outputs.app_token }}\"\n          VERSION: ${{ inputs.version }}\n        run: |\n          echo \" Waiting for helm chart PR checks and merging for version $VERSION\"\n\n          # Find the PR for this release\n          BRANCH=\"pr/prepare-$VERSION\"\n          echo \"Looking for PR from branch: $BRANCH\"\n\n          # Wait for PR to exist (in case it was just created)\n          MAX_WAIT=300  # 5 minutes\n          WAIT_TIME=0\n          PR_NUMBER=\"\"\n\n          while [ $WAIT_TIME -lt $MAX_WAIT ]; do\n            PR_NUMBER=$(gh pr list --repo cilium/charts --head \"$BRANCH\" --state open --json number --jq '.[0].number // empty')\n            if [ -n \"$PR_NUMBER\" ]; then\n              echo \"Found PR #$PR_NUMBER\"\n              break\n            fi\n            echo \"Waiting for PR to be created...\"\n            sleep 10\n            WAIT_TIME=$((WAIT_TIME + 10))\n          done\n\n          if [ -z \"$PR_NUMBER\" ]; then\n            echo \" No PR found for branch $BRANCH after waiting $MAX_WAIT seconds\"\n            echo \"Available PRs:\"\n            gh pr list --repo cilium/charts --state open || echo \"Failed to list PRs\"\n            exit 1\n          fi\n\n          # Wait for checks to complete\n          echo \" Waiting for PR checks to complete...\"\n          sleep 30  # Initial wait to allow checks to start\n          if ! gh pr checks $PR_NUMBER --repo cilium/charts --fail-fast --required --watch; then\n            echo \" PR #$PR_NUMBER has failed checks\"\n            echo \" Failed workflow details:\"\n            gh pr checks $PR_NUMBER --repo cilium/charts --json name,state,link | jq -r '.[] | select(.state == \"FAILURE\") | \"  - \\(.name): \\(.state) (\\(.link // \"No URL\"))\"'\n            exit 1\n          fi\n\n          echo \" All required checks passed for PR #$PR_NUMBER\"\n\n          # Merge the PR\n          echo \"Merging PR #$PR_NUMBER...\"\n          if gh pr merge $PR_NUMBER --repo cilium/charts --rebase --delete-branch; then\n            echo \" Successfully merged PR #$PR_NUMBER\"\n          else\n            echo \" Failed to merge PR #$PR_NUMBER\"\n            exit 1\n          fi\n"
						}
					},
					{
						"name": "renovate-config-validator.yaml",
						"object": {
							"text": "name: Validate Renovate configuration\n\non:\n  pull_request:\n    paths:\n      # Run on any renovate.json5, not just .github/renovate.json5\n      - '**renovate.json5'\n\njobs:\n  validate:\n    name: Validate Renovate configuration\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Checkout configuration\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n\n      # this step uses latest renovate slim release\n      - name: Validate configuration\n        run: |\n          # renovate: datasource=docker\n          export RENOVATE_IMAGE=ghcr.io/renovatebot/renovate:41.97.7@sha256:e9016393f1deb97b58bd3d79606dbc166d9a308f24632af7a4f5af5b6f4640f2\n          docker run --rm --entrypoint \"renovate-config-validator\" \\\n            -v \"${{ github.workspace }}/.github/renovate.json5\":\"/renovate.json5\" \\\n            ${RENOVATE_IMAGE} \"/renovate.json5\"\n"
						}
					},
					{
						"name": "renovate.yaml",
						"object": {
							"text": "name: Renovate\non:\n  schedule:\n    # Running every hour every working day (Monday to Friday)\n    - cron: '0 * * * 1-5'\n    # Running every two hours on weekends (Saturday and Sunday)\n    - cron: '0 */2 * * 6,0'\n  # allow to manually trigger this workflow\n  workflow_dispatch:\n    inputs:\n      renovate_log_level_debug:\n        type: boolean\n        description: \"Run Renovate With Debug Log Levels\"\n        default: true\n\njobs:\n  renovate:\n    name: Run self-hosted Renovate\n    runs-on: ubuntu-24.04\n    steps:\n      # we need special permission to be able to operate renovate (view, list,\n      # create issues, PR, etc.) and we use a GitHub application with fine\n      # grained permissions installed in the repository for that.\n      - name: Get token\n        id: get_token\n        uses: cilium/actions-app-token@61a6271ce92ba02f49bf81c755685d59fb25a59a # v0.21.1\n        with:\n          APP_PEM: ${{ secrets.CILIUM_RENOVATE_PEM }}\n          APP_ID: ${{ secrets.CILIUM_RENOVATE_APP_ID }}\n\n      # renovate clones the repository again in its container fs but it needs\n      # the renovate configuration to start.\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n\n      - name: Self-hosted Renovate\n        uses: renovatebot/github-action@7876d7a812254599d262d62b6b2c2706018258a2 # v43.0.10\n        env:\n          # default to DEBUG log level, this is always useful\n          LOG_LEVEL: ${{ github.event.inputs.renovate_log_level_debug == 'false' && 'INFO' || 'DEBUG' }}\n        with:\n          # renovate: datasource=github-releases depName=renovatebot/renovate\n          renovate-version: 41.97.7\n          docker-user: root\n          docker-cmd-file: .github/actions/renovate/entrypoint.sh\n          configurationFile: .github/renovate.json5\n          token: '${{ steps.get_token.outputs.app_token }}'\n          mount-docker-socket: true\n"
						}
					},
					{
						"name": "scale-cleanup-kops.yaml",
						"object": {
							"text": "name: Cleanup GCE kops clusters\n\non:\n  # Run every 3 hours\n  # In case we leak kops cluster, we want to cleanup\n  # 100 node cluster pretty fast\n  schedule:\n    - cron: '0 */3 * * *'\n\npermissions:\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  group: |\n    ${{ github.workflow }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\njobs:\n  cleanup-kops-clusters:\n    runs-on: ubuntu-24.04\n    name: Cleanup kops clusters\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Install Kops\n        uses: cilium/scale-tests-action/install-kops@082339e175a65c282c44c13bf875822e23911359 # main\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Cleanup stale clusters\n        shell: bash\n        timeout-minutes: 25\n        run: |\n          if ./kops get clusters --state ${{ secrets.GCP_PERF_KOPS_STATE_STORE }} -o json > /tmp/clusters.json\n          then\n            echo \"Clusters list fetched successfully\"\n            date=$(date -u +%Y-%m-%d'T'%H:%M'Z' -d \"3 hour ago\")\n            cat /tmp/clusters.json | jq -r --arg date \"$date\" '.[] | select(.metadata.creationTimestamp < $date) | .metadata.name' > /tmp/stale-clusters.txt\n            # iterate through list of cluster names in /tmp/stale-clusters.txt\n            while IFS= read -r cluster; do\n              ./kops delete cluster --state ${{ secrets.GCP_PERF_KOPS_STATE_STORE }} $cluster --yes\n            done < /tmp/stale-clusters.txt\n          else\n            echo \"Failed to fetch clusters list, probably no clusters present\"\n          fi"
						}
					},
					{
						"name": "scale-test-100-gce.yaml",
						"object": {
							"text": "name: 100 Nodes Scale Test (scale-100)\n\non:\n  schedule:\n    - cron: '39 0 * * 1-5'\n\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\npermissions:\n  # To be able to retrieve artifacts information\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  test_name: scale-100\n  cluster_name: ${{ github.run_id }}-${{ github.run_attempt }}\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  install-and-scaletest:\n    runs-on: ubuntu-24.04\n    name: Install and Scale Test\n    timeout-minutes: 300\n    env:\n      job_name: \"Install and Scale Test\"\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ] ; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          # Run test against specific commit SHA if provided\n          if [[ '${{ inputs.extra-args }}' =~ sha=([a-f0-9]+) ]]; then\n            SHA=${BASH_REMATCH[1]}\n          fi\n\n          # Retrieve the desired version from the arguments.\n          if [[ '${{ inputs.extra-args }}' =~ version=([-+.0-9a-z]+) ]]; then\n            VERSION=${BASH_REMATCH[1]}\n          else\n            VERSION=\"\"\n          fi\n\n          # Retrive number of workload nodes from the arguments.\n          if [[ '${{ inputs.extra-args }}' =~ nodes=([0-9+]+) ]]; then\n            WORKLOAD_NODES=${BASH_REMATCH[1]}\n          else\n            WORKLOAD_NODES=100\n          fi\n\n          if [ \"${WORKLOAD_NODES}\" -gt 1000 ]; then\n            echo \"WORKLOAD_NODES cannot be larger than 1000, got ${WORKLOAD_NODES}\"\n            exit 1\n          fi\n\n          # Adding k8s.local to the end makes kops happy\n          # has stricter DNS naming requirements.\n          CLUSTER_NAME=\"${{ env.test_name }}-${{ env.cluster_name }}.k8s.local\"\n\n          CILIUM_INSTALL_DEFAULTS=\" \\\n            --set=pprof.enabled=true \\\n            --set=prometheus.enabled=true \\\n            --set=cluster.name=${{ env.cluster_name }} \\\n            --set=k8sServiceHost=api.internal.${CLUSTER_NAME} \\\n            --set=k8sServicePort=443 \\\n            --set=kubeProxyReplacement=true \\\n            --set=operator.replicas=1 \\\n            --set=updateStrategy.rollingUpdate.maxUnavailable=100% \\\n            --set=ipam.mode=\\\"cluster-pool\\\" \\\n            --set=ipam.operator.clusterPoolIPv4PodCIDRList[0]=\\\"10.0.0.0/9\\\" \\\n            --wait=false\"\n\n          # only add SHA to the image tags if VERSION is not set\n          if [ -z \"${VERSION}\" ]; then\n            CILIUM_INSTALL_DEFAULTS+=\" --set=image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n            --set=image.useDigest=false \\\n            --set=image.tag=${SHA} \\\n            --set=operator.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n            --set=operator.image.suffix=-ci \\\n            --set=operator.image.tag=${SHA} \\\n            --set=operator.image.useDigest=false \\\n            --set=clustermesh.apiserver.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/clustermesh-apiserver-ci \\\n            --set=clustermesh.apiserver.image.tag=${SHA} \\\n            --set=clustermesh.apiserver.image.useDigest=false \\\n            --set=hubble.relay.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci \\\n            --set=hubble.relay.image.tag=${SHA} \\\n            --set=hubble.relay.image.useDigest=false\"\n          fi\n\n          echo SHA=${SHA} >> $GITHUB_OUTPUT\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo CLUSTER_NAME=${CLUSTER_NAME} >> $GITHUB_OUTPUT\n          echo VERSION=${VERSION} >> $GITHUB_OUTPUT\n          echo WORKLOAD_NODES=${WORKLOAD_NODES} >> $GITHUB_OUTPUT\n\n      - name: Checkout pull request branch (NOT TRUSTED)\n        if: ${{ steps.vars.outputs.version == '' }} # We don't need to checkout the PR if it's released version\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Wait for images\n        if: ${{ steps.vars.outputs.version == '' }} # We don't need to wait for images if it's released version\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ steps.vars.outputs.SHA }}\n          images: cilium-ci operator-generic-ci hubble-relay-ci\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version: ${{ env.go_version }}\n\n      - name: Install Kops\n        uses: cilium/scale-tests-action/install-kops@082339e175a65c282c44c13bf875822e23911359 # main\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Clone ClusterLoader2\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes/perf-tests\n          # Avoid using renovate to update this dependency because: (1)\n          # perf-tests does not tag or release, so renovate will pull\n          # all updates to the default branch and (2) continually\n          # updating CL2 may impact the stability of the scale test\n          # results.\n          ref: 6eb52ac89d5de15a0ad13cfeb2b2026e57ce4f64\n          persist-credentials: false\n          sparse-checkout: clusterloader2\n          path: perf-tests\n\n      - name: Setup CL2\n        run: |\n          # CL2 needs ssh access to control plane nodes\n          gcloud compute config-ssh\n\n          # Copy the custom configs to the folder where CL2 expects them.\n          cp -r .github/actions/cl2-modules ./perf-tests/clusterloader2/testing/custom\n\n          cd ./perf-tests/clusterloader2\n\n          # CL2 hardcodes module paths to live in ./testing/load, even\n          # if the path given is relative.\n          cp ../../.github/actions/cl2-modules/cilium-agent-pprofs.yaml ./testing/load/\n          cp ../../.github/actions/cl2-modules/cilium-metrics.yaml ./testing/load/\n          echo \\\n            '{\"CL2_ADDITIONAL_MEASUREMENT_MODULES\": [\"./cilium-agent-pprofs.yaml\", \"./cilium-metrics.yaml\"]}' \\\n            > modules.yaml\n\n          go build ./cmd/clusterloader.go\n\n      - name: Deploy cluster\n        id: deploy-cluster\n        uses: cilium/scale-tests-action/create-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          control_plane_size: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 'n2-standard-8' || 'n2-standard-16' }}\n          control_plane_count: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 1 || 3 }}\n          node_size: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 'n2-standard-8' || 'n2-standard-16' }}\n          node_count: 1\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          node_cidr: 10.255.0.0/16\n          kube_proxy_enabled: false\n          sync_cloud_routes: false\n          etcd_volume_size: 250\n          max_in_flight: 200\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359  # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Display version info of installed tools\n        run: |\n          echo \"--- go ---\"\n          go version\n          echo \"--- cilium-cli ---\"\n          cilium version --client\n          echo \"--- kops ---\"\n          ./kops version\n          echo \"--- gcloud ---\"\n          gcloud version\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium_install_args=\"${{ steps.vars.outputs.cilium_install_defaults }}\"\n          if [[ -z \"${{ steps.vars.outputs.version }}\" ]]; then\n            helm install -n kube-system cilium ./untrusted/install/kubernetes/cilium $cilium_install_args\n          else\n            helm repo add cilium https://helm.cilium.io/\n            helm install -n kube-system cilium cilium/cilium --version ${{ steps.vars.outputs.version }} $cilium_install_args\n          fi\n\n      - name: Wait for cluster to be ready\n        uses: cilium/scale-tests-action/validate-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 20\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          interval: 10s\n\n      - name: Run CL2 to setup prometheus\n        shell: bash\n        working-directory: ./perf-tests/clusterloader2\n        env:\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 12.0 || 24.0 }}\n        timeout-minutes: 10\n        run: |\n          # Don't run any tasks at this point, just setup the monitoring stack\n          ./clusterloader \\\n            -v=2 \\\n            --testconfig=./testing/custom/common/setup.yaml \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --nodes=${{ steps.vars.outputs.workload_nodes }} \\\n            --provider=gce \\\n            --enable-exec-service=false \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --kubeconfig=$HOME/.kube/config \\\n            2>&1 | tee cl2-setup.txt\n\n      - name: Create Instance Group for workload deployments\n        uses: cilium/scale-tests-action/create-instance-group@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          node_size: e2-medium\n          node_count: ${{ steps.vars.outputs.workload_nodes }}\n          ig_name: workloads\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Wait for workloads nodes to be ready\n        timeout-minutes: 20\n        run: |\n          cnt=0\n\n          # Allow for a 2 per thousand toleration in the expected nodes count, to\n          # continue with the test even if a tiny fraction of the workers failed\n          # bootstrapping and joining the cluster.\n          desired=$(( ${{ steps.vars.outputs.WORKLOAD_NODES}} - ${{ steps.vars.outputs.WORKLOAD_NODES}} * 2 / 1000 ))\n\n          # A more idiomatic way would be using the kops.k8s.io/instancegroup=workloads\n          # label selector, but kops appears to be significantly slow at reconciling\n          # the labels to the node objects. Hence, let's just grep for the node names.\n          while [[ \"$cnt\" -lt \"$desired\" ]]; do\n            # shellcheck disable=SC2196\n            cnt=$(kubectl get nodes --no-headers | egrep -c 'workloads-[-a-z0-9]+\\s+Ready\\s' || true)\n            echo \"workloads nodes count: $cnt\"\n            sleep 10\n          done\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          create_native_routing_firewall: 'false'\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          kubectl rollout status -n kube-system ds/cilium\n          kubectl rollout status -n kube-system ds/cilium-envoy\n\n      - name: Run CL2\n        id: run-cl2\n        working-directory: ./perf-tests/clusterloader2\n        shell: bash\n        timeout-minutes: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 60 || 180 }}\n        env:\n          CL2_ENABLE_PVS: \"false\"\n          CL2_ENABLE_NETWORKPOLICIES: \"true\"\n          CL2_ALLOWED_SLOW_API_CALLS: 1\n          CL2_SCHEDULER_THROUGHPUT_THRESHOLD: 0\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 12.0 || 24.0 }}\n          CL2_PPROF_INTERVAL_SECONDS: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 60 || 300 }}\n          CL2_ENABLE_VIOLATIONS: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 'true' || 'false' }}\n        run: |\n          ./clusterloader \\\n            -v=2 \\\n            ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && '--testconfig=./testing/load/config.yaml' || '' }}  \\\n            ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && '--testconfig=./testing/custom/common/restart.yaml' || '' }}  \\\n            --testconfig=./testing/custom/netpol/config.yaml \\\n            --testconfig=./testing/custom/common/restart.yaml \\\n            --testconfig=./testing/custom/servicechurn/config.yaml \\\n            --provider=gce \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --nodes=${{ steps.vars.outputs.workload_nodes }} \\\n            --report-dir=./report \\\n            --experimental-prometheus-snapshot-to-report-dir=true \\\n            --kubeconfig=$HOME/.kube/config \\\n            --testoverrides=./testing/overrides/load_throughput.yaml \\\n            --testoverrides=./testing/experiments/use_simple_latency_query.yaml \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --testoverrides=./modules.yaml \\\n            2>&1 | tee cl2-output.txt\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          capture_sysdump: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && true || false }}\n          always_capture_sysdump: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && true || false }}\n          artifacts_suffix: \"final\"\n          job_status: \"${{ job.status }}\"\n\n      - name: Cleanup cluster\n        if: ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        uses: cilium/scale-tests-action/cleanup-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-cl2.outcome != 'skipped' && steps.run-cl2.outcome != 'cancelled' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ env.test_name }}\n          tested_version: ${{ steps.vars.outputs.version }}\n          tested_sha: ${{ steps.vars.outputs.sha }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          artifacts: ./perf-tests/clusterloader2/report/\n          other_files: ${{ steps.vars.outputs.WORKLOAD_NODES <= 100 && 'cilium-sysdump-final.zip' || '' }} ./perf-tests/clusterloader2/cl2-output.txt\n\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: install-and-scaletest\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.install-and-scaletest.result }}\n"
						}
					},
					{
						"name": "scale-test-5-gce.yaml",
						"object": {
							"text": "name: 5 Nodes Scale Test (scale-5)\n\non:\n  schedule:\n    - cron: '22 5 * * 1-5' # Every weekday at 05:22 AM\n\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\npermissions:\n  # To be able to retrieve artifacts information\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  # Adding k8s.local to the end makes kops happy-\n  # has stricter DNS naming requirements.\n  test_name: scale-5\n  cluster_name: ${{ github.run_id }}-${{ github.run_attempt }}\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  install-and-scaletest:\n    runs-on: ubuntu-24.04\n    name: Install and Scale Test\n    timeout-minutes: 150\n    env:\n      job_name: \"Install and Scale Test\"\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ] ; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          # Adding k8s.local to the end makes kops happy\n          # has stricter DNS naming requirements.\n          CLUSTER_NAME=\"${{ env.test_name }}-${{ env.cluster_name }}.k8s.local\"\n\n          CILIUM_INSTALL_DEFAULTS=\"--chart-directory=install/kubernetes/cilium \\\n            --set pprof.enabled=true \\\n            --helm-set=prometheus.enabled=true \\\n            --helm-set=cluster.name=${{ env.cluster_name }} \\\n            --helm-set=k8sServiceHost=api.internal.${CLUSTER_NAME} \\\n            --helm-set=k8sServicePort=443 \\\n            --helm-set=kubeProxyReplacement=true \\\n            --helm-set=operator.replicas=1 \\\n            --wait=false\"\n\n          # only add SHA to the image tags if it was set\n          if [ -n \"${SHA}\" ]; then\n            echo sha=${SHA} >> $GITHUB_OUTPUT\n            CILIUM_INSTALL_DEFAULTS+=\" --helm-set=image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \\\n            --helm-set=image.useDigest=false \\\n            --helm-set=image.tag=${SHA} \\\n            --helm-set=operator.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \\\n            --helm-set=operator.image.suffix=-ci \\\n            --helm-set=operator.image.tag=${SHA} \\\n            --helm-set=operator.image.useDigest=false \\\n            --helm-set=clustermesh.apiserver.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/clustermesh-apiserver-ci \\\n            --helm-set=clustermesh.apiserver.image.tag=${SHA} \\\n            --helm-set=clustermesh.apiserver.image.useDigest=false \\\n            --helm-set=hubble.relay.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/hubble-relay-ci \\\n            --helm-set=hubble.relay.image.tag=${SHA} \\\n            --helm-set=hubble.relay.image.useDigest=false\"\n          fi\n\n          echo SHA=${SHA} >> $GITHUB_OUTPUT\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo CLUSTER_NAME=${CLUSTER_NAME} >> $GITHUB_OUTPUT\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.SHA }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version: ${{ env.go_version }}\n\n      - name: Install Kops\n        uses: cilium/scale-tests-action/install-kops@082339e175a65c282c44c13bf875822e23911359 # main\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Clone ClusterLoader2\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes/perf-tests\n          # Avoid using renovate to update this dependency because: (1)\n          # perf-tests does not tag or release, so renovate will pull\n          # all updates to the default branch and (2) continually\n          # updating CL2 may impact the stability of the scale test\n          # results.\n          ref: 6eb52ac89d5de15a0ad13cfeb2b2026e57ce4f64\n          persist-credentials: false\n          sparse-checkout: clusterloader2\n          path: perf-tests\n\n      - name: Setup CL2\n        run: |\n          # CL2 needs ssh access to control plane nodes\n          gcloud compute config-ssh\n\n          # Copy the custom configs to the folder where CL2 expects them.\n          cp -r .github/actions/cl2-modules ./perf-tests/clusterloader2/testing/custom\n\n          cd ./perf-tests/clusterloader2\n\n          # CL2 hardcodes module paths to live in ./testing/load, even\n          # if the path given is relative.\n          cp ../../.github/actions/cl2-modules/cilium-agent-pprofs.yaml ./testing/load/\n          cp ../../.github/actions/cl2-modules/cilium-metrics.yaml ./testing/load/\n          echo \\\n            '{\"CL2_ADDITIONAL_MEASUREMENT_MODULES\": [\"./cilium-agent-pprofs.yaml\", \"./cilium-metrics.yaml\"]}' \\\n            > modules.yaml\n\n          go build ./cmd/clusterloader.go\n\n      - name: Deploy cluster\n        id: deploy-cluster\n        uses: cilium/scale-tests-action/create-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          control_plane_size: n1-standard-8\n          control_plane_count: 1\n          node_size: e2-standard-8\n          node_count: 1\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          kube_proxy_enabled: false\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359  # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Display version info of installed tools\n        run: |\n          echo \"--- go ---\"\n          go version\n          echo \"--- cilium-cli ---\"\n          cilium version --client\n          echo \"--- kops ---\"\n          ./kops version\n          echo \"--- gcloud ---\"\n          gcloud version\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install --dry-run-helm-values ${{ steps.vars.outputs.cilium_install_defaults }}\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for cluster to be ready\n        uses: cilium/scale-tests-action/validate-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 20\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          interval: 10s\n\n      - name: Run CL2 to setup prometheus\n        shell: bash\n        working-directory: ./perf-tests/clusterloader2\n        env:\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: 2.0\n        timeout-minutes: 10\n        run: |\n          # Don't run any tasks at this point, just setup the monitoring stack\n          ./clusterloader \\\n            -v=2 \\\n            --testconfig=./testing/custom/common/setup.yaml \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --provider=gce \\\n            --enable-exec-service=false \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --kubeconfig=$HOME/.kube/config \\\n            2>&1 | tee cl2-setup.txt\n\n      - name: Create Instance Group for workload deployments\n        uses: cilium/scale-tests-action/create-instance-group@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          node_size: e2-medium\n          node_count: 5\n          ig_name: workloads\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Wait for cluster to be ready\n        uses: cilium/scale-tests-action/validate-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 20\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          interval: 10s\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          create_native_routing_firewall: 'false'\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n\n      - name: Run CL2\n        id: run-cl2\n        working-directory: ./perf-tests/clusterloader2\n        shell: bash\n        timeout-minutes: 60\n        env:\n          CL2_ENABLE_PVS: \"false\"\n          CL2_ENABLE_NETWORKPOLICIES: \"true\"\n          CL2_ALLOWED_SLOW_API_CALLS: 1\n          CL2_SCHEDULER_THROUGHPUT_THRESHOLD: 0\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: 2.0\n        run: |\n          ./clusterloader \\\n            -v=2 \\\n            --testconfig=./testing/load/config.yaml \\\n            --testconfig=./testing/custom/lbipam/config.yaml \\\n            --provider=gce \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --nodes=5 \\\n            --report-dir=./report \\\n            --experimental-prometheus-snapshot-to-report-dir=true \\\n            --kubeconfig=$HOME/.kube/config \\\n            --testoverrides=./testing/overrides/load_throughput.yaml \\\n            --testoverrides=./testing/experiments/use_simple_latency_query.yaml \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --testoverrides=./modules.yaml \\\n            2>&1 | tee cl2-output.txt\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          capture_sysdump: \"${{ steps.install-cilium.outcome != 'skipped' && steps.install-cilium.outcome != 'cancelled' }}\"\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n\n      - name: Cleanup cluster\n        if: ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        uses: cilium/scale-tests-action/cleanup-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-cl2.outcome != 'skipped' && steps.run-cl2.outcome != 'cancelled' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ env.test_name }}\n          tested_sha: ${{ steps.vars.outputs.SHA }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          artifacts: ./perf-tests/clusterloader2/report/\n          other_files: cilium-sysdump-final.zip ./perf-tests/clusterloader2/cl2-output.txt\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: install-and-scaletest\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.install-and-scaletest.result }}\n"
						}
					},
					{
						"name": "scale-test-clustermesh.yaml",
						"object": {
							"text": "name: Cluster Mesh Scale Test (scale-clustermesh)\n\non:\n  schedule:\n    - cron: '39 12 * * 1-5'\n\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\npermissions:\n  # To be able to retrieve artifacts information\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n  # renovate: datasource=git-refs depName=https://github.com/cilium/scaffolding branch=main\n  cmapisrv_mock_ref: 38f6ed0ddf54dc548187536c385d2d722e265dad\n\n  test_name: scale-clustermesh\n  cluster_name: ${{ github.run_id }}-${{ github.run_attempt }}\n  mock_clusters: 250\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  install-and-test:\n    runs-on: ubuntu-24.04\n    name: Install and Cluster Mesh Scale Test\n    timeout-minutes: 60\n    env:\n      job_name: \"Install and Cluster Mesh Scale Test\"\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          # Adding k8s.local to the end makes kops happy\n          # has stricter DNS naming requirements.\n          CLUSTER_NAME=\"${{ env.test_name }}-${{ env.cluster_name }}.k8s.local\"\n          echo CLUSTER_NAME=${CLUSTER_NAME} >> $GITHUB_OUTPUT\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci clustermesh-apiserver-ci cilium-cli-ci\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version: ${{ env.go_version }}\n\n      - name: Install Kops\n        uses: cilium/scale-tests-action/install-kops@082339e175a65c282c44c13bf875822e23911359 # main\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Clone ClusterLoader2\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes/perf-tests\n          # Avoid using renovate to update this dependency because: (1)\n          # perf-tests does not tag or release, so renovate will pull\n          # all updates to the default branch and (2) continually\n          # updating CL2 may impact the stability of the scale test\n          # results.\n          ref: 6eb52ac89d5de15a0ad13cfeb2b2026e57ce4f64\n          persist-credentials: false\n          sparse-checkout: clusterloader2\n          path: perf-tests\n\n      - name: Clone the Cluster Mesh API Server Mock\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: cilium/scaffolding\n          ref: ${{ env.cmapisrv_mock_ref }}\n          persist-credentials: false\n          sparse-checkout: cmapisrv-mock\n          path: scaffolding\n\n      - name: Deploy cluster\n        id: deploy-cluster\n        uses: cilium/scale-tests-action/create-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.CLUSTER_NAME }}\n          control_plane_size: n2-standard-8\n          control_plane_count: 1\n          node_size: n2-standard-8\n          node_count: 1\n          node_cidr: 100.0.0.0/16\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          kube_proxy_enabled: false\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Display version info of installed tools\n        run: |\n          echo \"--- go ---\"\n          go version\n          echo \"--- cilium-cli ---\"\n          cilium version --client\n          echo \"--- kops ---\"\n          ./kops version\n          echo \"--- gcloud ---\"\n          gcloud version\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.CLUSTER_NAME }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.SHA || github.sha }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/install/kubernetes/cilium\n          debug: false\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          # * Increase the node BPF map size to account for the total number of nodes.\n          # * Disable health checking, as mocked nodes are unreachable.\n          cilium install \\\n            ${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --set ipam.mode=kubernetes \\\n            --set kubeProxyReplacement=true \\\n            --set k8sServiceHost=api.internal.${{ steps.vars.outputs.CLUSTER_NAME }} \\\n            --set k8sServicePort=443 \\\n            --set pprof.enabled=true \\\n            --set prometheus.enabled=true \\\n            --set cluster.name=${{ env.test_name }}-${{ env.cluster_name }} \\\n            --set cluster.id=255 \\\n            --set operator.replicas=1 \\\n            --set operator.nodeSelector.node-role\\\\.kubernetes\\\\.io/control-plane= \\\n            --set bpf.nodeMapMax=65536 \\\n            --set healthChecking=false \\\n            --set endpointHealthChecking.enabled=false\n\n      # This step must be run after installing Cilium, as it requires\n      # system pods (e.g., coredns) to be running.\n      - name: Wait for cluster to be ready\n        uses: cilium/scale-tests-action/validate-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 20\n        with:\n          cluster_name: ${{ steps.vars.outputs.CLUSTER_NAME }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n\n      - name: Setup CL2\n        run: |\n          # CL2 needs ssh access to control plane nodes\n          gcloud compute config-ssh\n\n          # Copy the custom configs to the folder where CL2 expects them.\n          cp -r .github/actions/cl2-modules ./perf-tests/clusterloader2/testing/custom\n\n      - name: Run CL2 to setup prometheus\n        shell: bash\n        working-directory: ./perf-tests/clusterloader2\n        env:\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: 4.0\n        timeout-minutes: 10\n        run: |\n          # Don't run any tasks at this point, just setup the monitoring stack\n          go run ./cmd/clusterloader.go \\\n            -v=2 \\\n            --testconfig=./testing/custom/common/setup.yaml \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --provider=gce \\\n            --enable-exec-service=false \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --kubeconfig=$HOME/.kube/config \\\n            2>&1 | tee cl2-setup.txt\n\n      - name: Deploy the Cluster Mesh API Server Mock\n        run: |\n          helm install cmapisrv-mock \\\n            ./scaffolding/cmapisrv-mock/deploy/cmapisrv-mock \\\n            --namespace kube-system \\\n            --set image.repository=quay.io/cilium/cmapisrv-mock \\\n            --set image.tag=${{ env.cmapisrv_mock_ref }} \\\n            --set nodeSelector.node-role\\\\.kubernetes\\\\.io/control-plane= \\\n            --set tolerations[0].key=node-role.kubernetes.io/control-plane \\\n            --set tolerations[0].operator=Exists \\\n            --set config.ipv6=false \\\n            --set config.clusters=${{ env.mock_clusters }} \\\n            --set config.nodes=100 \\\n            --set config.nodesQPS=0.1 \\\n            --set config.identities=100 \\\n            --set config.identitiesQPS=0.2 \\\n            --set config.endpoints=1000 \\\n            --set config.endpointsQPS=1 \\\n            --set config.services=0 \\\n            --set config.servicesQPS=0 \\\n            --set serviceMonitor=true\n\n          kubectl -n kube-system wait --for=condition=Ready pod \\\n            -l app.kubernetes.io/name=cmapisrv-mock --timeout=300s\n\n      - name: Enable KVStoreMesh and configure Cilium to connect to the Cluster Mesh API Server Mock\n        run: |\n          cat<<EOF > values-clustermesh-config.yaml\n          clustermesh:\n            config:\n              enabled: true\n              clusters:\n          EOF\n\n          for i in $(seq 1 ${{ env.mock_clusters }}); do\n            printf \"    - name: cluster-%03d\\n\" ${i}\n            printf \"      address: cmapisrv-mock.kube-system.svc\\n\"\n            printf \"      port: 2379\\n\"\n          done >> values-clustermesh-config.yaml\n\n          # * We enable KVStoreMesh only at this point to leverage the bootstrap QPS\n          #   and speed-up the overall bootstrap process.\n          # * Increase the KVStoreMesh QPS to match the ones of the cmapisrv-mock,\n          #   as not a problem considering the limited number of watchers.\n          # * Store etcd data directly in memory, for improved performance.\n          cilium upgrade --reuse-values \\\n            --chart-directory=untrusted/install/kubernetes/cilium \\\n            --set clustermesh.useAPIServer=true \\\n            --set clustermesh.apiserver.etcd.storageMedium=Memory \\\n            --set clustermesh.apiserver.kvstoremesh.enabled=true \\\n            --set clustermesh.apiserver.kvstoremesh.extraArgs[0]=--kvstore-opt=etcd.qps=1000 \\\n            --set clustermesh.apiserver.nodeSelector.node-role\\\\.kubernetes\\\\.io/control-plane= \\\n            --set clustermesh.apiserver.tolerations[0].key=node-role.kubernetes.io/control-plane \\\n            --set clustermesh.apiserver.tolerations[0].operator=Exists \\\n            --set clustermesh.apiserver.metrics.serviceMonitor.enabled=true \\\n            --values values-clustermesh-config.yaml\n\n          cilium status --wait --interactive=false\n          cilium clustermesh status --wait --wait-duration=5m\n\n      - name: Run CL2\n        id: run-cl2\n        shell: bash\n        working-directory: ./perf-tests/clusterloader2\n        env:\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: 4.0\n        timeout-minutes: 30\n        run: |\n          go run ./cmd/clusterloader.go \\\n            -v=2 \\\n            --testconfig=./testing/custom/clustermesh/config.yaml \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --provider=gce \\\n            --nodes=1 \\\n            --enable-prometheus-server \\\n            --tear-down-prometheus-server=false \\\n            --report-dir=./report \\\n            --experimental-prometheus-snapshot-to-report-dir=true \\\n            --kubeconfig=$HOME/.kube/config \\\n            2>&1 | tee cl2-output.txt\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          always_capture_sysdump: true\n          artifacts_suffix: \"final\"\n          job_status: \"${{ job.status }}\"\n\n      - name: Cleanup cluster\n        if: ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        uses: cilium/scale-tests-action/cleanup-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.CLUSTER_NAME }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-cl2.outcome != 'skipped' && steps.run-cl2.outcome != 'cancelled' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ env.test_name }}\n          tested_sha: ${{ inputs.SHA || github.sha }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          artifacts: ./perf-tests/clusterloader2/report/\n          other_files: cilium-sysdump-final.zip ./perf-tests/clusterloader2/cl2-output.txt\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: install-and-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.install-and-test.result }}\n"
						}
					},
					{
						"name": "scale-test-egw.yaml",
						"object": {
							"text": "name: Scale Test Egress Gateway (scale-egw)\n\non:\n  schedule:\n    - cron: \"27 0 * * 1-5\"\n\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: \"{}\"\n      num-clients:\n        description: \"Number of clients to create to connect to the external target through EGW\"\n        required: false\n        default: 100\n        type: number\n      client-qps:\n        description: \"Number of client pods to create per second\"\n        required: false\n        default: 20\n        type: number\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\npermissions:\n  # To be able to retrieve artifacts information\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  # renovate: datasource=github-releases depName=eksctl-io/eksctl\n  eksctl_version: v0.214.0\n  # renovate: datasource=github-releases depName=kubernetes/kubernetes\n  kubectl_version: v1.34.0\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\n  # Hosted under quay.io/cilium/egw-scale-utils and built by\n  # a workflow in cilium/scaffolding.\n  # renovate: datasource=git-refs depName=https://github.com/cilium/scaffolding branch=main\n  egw_utils_ref: 38f6ed0ddf54dc548187536c385d2d722e265dad\n  test_name: egw\n  cluster_name: ${{ github.run_id }}-${{ github.run_attempt }}\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-aws-ci cilium-cli-ci\n\n  install-and-scaletest:\n    runs-on: ubuntu-24.04\n    name: Install and Scale Test\n    needs: wait-for-images\n    timeout-minutes: 150\n    strategy:\n      fail-fast: false\n      matrix:\n        test_type:\n          - baseline\n          - egw\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ] ; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          # * The SHA under test will have its helm chart checked out at the following\n          #   path right before the step where Cilium is installed.\n          # * We configure high K8s Client QPS to avoid observing latency ascribed\n          #   to rate limiting when creating CiliumEndpoint/CiliumIdentity objects\n          #   for newly scheduled pods. This latency depends on the scheduling rate\n          #   of new pods on each node, and it is unrelated to the egress gateway\n          #   functionality (i.e., it also possibly affects pod to pod connectivity).\n          # * We configure a high cilium-endpoint-gc-interval value to prevent the\n          #   synthetic endpoints from being deleted.\n          CILIUM_INSTALL_DEFAULTS=\"--chart-directory=untrusted/install/kubernetes/cilium \\\n            --wait=false \\\n            --set=hubble.enabled=true \\\n            --set=pprof.enabled=true \\\n            --set=prometheus.enabled=true \\\n            --set=cluster.name=${{ env.cluster_name }} \\\n            ${{ matrix.test_type == 'egw' && env.EGRESS_GATEWAY_HELM_VALUES || '' }} \\\n            --set=enableIPv4Masquerade=true \\\n            --set=bpf.masquerade=true \\\n            --set=kubeProxyReplacement=true \\\n            --set=l7Proxy=false \\\n            --set=egressMasqueradeInterfaces=\"\" \\\n            --set=eni.enabled=true \\\n            --set=ipam.mode=eni \\\n            --set=eni.awsEnablePrefixDelegation=true \\\n            --set=k8sClientRateLimit.qps=100 \\\n            --set=extraConfig.cilium-endpoint-gc-interval=24h \\\n            --set-string=extraConfig.enable-stale-cilium-endpoint-cleanup=false \\\n            --set=prometheus.metrics=\\\"{+cilium_datapath_nat_gc_entries}\\\" \\\n            --set=image.override=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci:${SHA} \\\n            --set=operator.image.override=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator-aws-ci:${SHA} \\\n            --values=values-dummy-health-server.yaml \\\n            --nodes-without-cilium\"\n\n          # We create a bunch of synthetic nodes during the test, to artificially\n          # increase the testbed scale. In order to pretend that these nodes are\n          # actually ready, let's start a dummy server locally, and redirect\n          # health probes to it.\n          cat<<EOF > values-dummy-health-server.yaml\n          extraInitContainers:\n          - name: iptables-config\n            image: quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci:${SHA}\n            command:\n            - /bin/bash\n            - -c\n            - \\$(SCRIPT)\n            env:\n            - name: SCRIPT\n              value: |\n                set -o errexit\n                set -o pipefail\n                set -o nounset\n\n                iptables -t nat -A OUTPUT -d 10.128.0.0/10 -p tcp --dport 4240 -j REDIRECT --to-ports 4241\n                iptables -t nat -A OUTPUT -d 10.128.0.0/10 -p icmp -j REDIRECT\n                iptables -t nat -vnL OUTPUT\n            securityContext:\n              capabilities:\n                add:\n                - NET_ADMIN\n                drop:\n                - ALL\n            volumeMounts:\n            - mountPath: /run/xtables.lock\n              name: xtables-lock\n\n          extraContainers:\n          - name: dummy-health-server\n            image: node:18.20.7-alpine3.21@sha256:e0340f26173b41066d68e3fe9bfbdb6571ab3cad0a4272919a52e36f4ae56925\n            command:\n            - /usr/local/bin/node\n            - -e\n            - \\$(SCRIPT)\n            env:\n            - name: SCRIPT\n              value: |\n                // Credit: https://stackoverflow.com/a/72638075\n                const http = require('http');\n                http.createServer(function (req, res) {\n                    res.writeHead(200);\n                    res.end();\n                }).listen(4241);\n          EOF\n\n          OWNER=\"${{ github.ref_name }}\"\n          OWNER=\"${OWNER//[.\\/]/-}\"\n\n          if [ \"${{ github.event_name }}\" == \"workflow_dispatch\" ] ; then\n            NUM_CLIENT_PODS=\"${{ inputs.num-clients }}\"\n            CLIENT_QPS=\"${{ inputs.client-qps }}\"\n          else\n            NUM_CLIENT_PODS=\"100\"\n            CLIENT_QPS=\"20\"\n          fi\n\n          # m5n.xlarge instances support up to 25Gbps burst bandwidth.\n          NODE_INSTANCE_TYPE=\"m5n.xlarge\"\n          TARGET_CLIENT_PODS_PER_NODE=25\n\n          # Poor's man round up to derive the number of desired nodes\n          NUM_CLIENT_NODES=\"$(( (NUM_CLIENT_PODS + TARGET_CLIENT_PODS_PER_NODE - 1) / TARGET_CLIENT_PODS_PER_NODE ))\"\n\n          TEST_NAME=\"${{ env.test_name }}-${{ matrix.test_type }}-${NUM_CLIENT_PODS}-${CLIENT_QPS}\"\n          CLUSTER_NAME=\"${TEST_NAME}-${{ env.cluster_name }}\"\n\n          eks_version_and_region=$(yq '.include | sort_by(.version) | reverse | .[0] | \"\\(.version),\\(.region)\"' .github/actions/eks/k8s-versions.yaml)\n          EKS_VERSION=$(echo $eks_version_and_region | cut -d',' -f1)\n          EKS_REGION=$(echo $eks_version_and_region | cut -d',' -f2)\n\n          echo sha=${SHA} >> $GITHUB_OUTPUT\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo owner=${OWNER} >> $GITHUB_OUTPUT\n          echo test_name=${TEST_NAME} >> $GITHUB_OUTPUT\n          echo cluster_name=${CLUSTER_NAME} >> $GITHUB_OUTPUT\n          echo num_client_pods=${NUM_CLIENT_PODS} >> $GITHUB_OUTPUT\n          echo num_client_nodes=${NUM_CLIENT_NODES} >> $GITHUB_OUTPUT\n          echo node_instance_type=${NODE_INSTANCE_TYPE} >> $GITHUB_OUTPUT\n          echo client_qps=${CLIENT_QPS} >> $GITHUB_OUTPUT\n          echo eks_version=${EKS_VERSION} >> $GITHUB_OUTPUT\n          echo eks_region=${EKS_REGION} >> $GITHUB_OUTPUT\n          echo eks_zone_1=${EKS_REGION}b >> $GITHUB_OUTPUT\n          echo eks_zone_2=${EKS_REGION}c >> $GITHUB_OUTPUT\n\n      - name: Ensure EGW scale utils image is available\n        shell: bash\n        run: |\n          # Run this seprate from the other \"Wait for images to be available\" step to help with debugging.\n          if ! docker manifest inspect quay.io/cilium/egw-scale-utils:${{ env.egw_utils_ref }} ; then\n            echo \"FATAL: egw-scale-utils image with ref ${{ env.egw_utils_ref }} is not available, exiting\"\n            exit 1\n          fi\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version: ${{ env.go_version }}\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Install kubectl\n        run: |\n          curl -sLO \"https://dl.k8s.io/release/${{ env.kubectl_version }}/bin/linux/amd64/kubectl\"\n          curl -sLO \"https://dl.k8s.io/${{ env.kubectl_version }}/bin/linux/amd64/kubectl.sha256\"\n          echo \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check\n          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n          kubectl version --client\n\n      - name: Install eksctl CLI\n        run: |\n          curl -LO \"https://github.com/eksctl-io/eksctl/releases/download/${{ env.eksctl_version }}/eksctl_$(uname -s)_amd64.tar.gz\"\n          sudo tar -xzvf \"eksctl_$(uname -s)_amd64.tar.gz\" -C /usr/bin\n          rm \"eksctl_$(uname -s)_amd64.tar.gz\"\n\n      - name: Set up AWS CLI credentials\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: ${{ steps.vars.outputs.eks_region }}\n\n      - name: Display version info of installed tools\n        run: |\n          echo \"--- go ---\"\n          go version\n          echo \"--- kubectl ---\"\n          kubectl version --client\n          echo \"--- eksctl ---\"\n          eksctl version\n          echo \"--- gcloud ---\"\n          gcloud version\n\n      - name: Clone ClusterLoader2\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes/perf-tests\n          # Avoid using renovate to update this dependency because: (1)\n          # perf-tests does not tag or release, so renovate will pull\n          # all updates to the default branch and (2) continually\n          # updating CL2 may impact the stability of the scale test\n          # results.\n          ref: d51da38a445d653c6f7cd039728d313cb31290b9\n          persist-credentials: false\n          sparse-checkout: clusterloader2\n          path: perf-tests\n\n      - name: Create EKS cluster\n        id: deploy-cluster\n        uses: ./.github/actions/setup-eks-cluster\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          region: ${{ steps.vars.outputs.eks_region }}\n          zones: \"${{ steps.vars.outputs.eks_zone_1 }} ${{ steps.vars.outputs.eks_zone_2 }}\"\n          owner: \"${{ steps.vars.outputs.owner }}\"\n          version: \"${{ steps.vars.outputs.eks_version }}\"\n          addons: \"coredns\"\n\n      - name: Generate cilium-cli kubeconfig\n        id: gen-kubeconfig\n        uses: ./.github/actions/get-cloud-kubeconfig\n        with:\n          kubeconfig: \"~/.kube/config\"\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n          kubeconfig: ${{ steps.gen-kubeconfig.outputs.kubeconfig_path }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout context ref (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.SHA }}\n          persist-credentials: false\n          path: untrusted\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          K8S_API_SRV_ADDR=$(kubectl config view -o jsonpath='{.clusters[0].cluster.server}' | sed 's|https://||')\n          echo \"Retrieved Kubernetes API Server address: '${K8S_API_SRV_ADDR}'\"\n\n          # Retrieve the CIDR associated with the availability zone where the cluster\n          # is deployed, and configure it as native routing CIDR. Otherwise, Cilium\n          # would default to the VPC CIDR, but we want to masquerade traffic towards\n          # the external destination (which is located in the same VPC, but different\n          # availability zone), to reflect the most common type of real deployments.\n          NATIVE_CIDR_BLOCK=$(aws ec2 describe-subnets --region ${{ steps.vars.outputs.eks_region }} \\\n            --filters Name=availability-zone,Values=${{ steps.vars.outputs.eks_zone_1 }} \\\n                Name=tag:alpha.eksctl.io/cluster-name,Values=${{ steps.vars.outputs.cluster_name }} \\\n                Name=map-public-ip-on-launch,Values=false \\\n            --query 'Subnets[*].CidrBlock' --output text)\n          echo \"Retrieved native routing CIDR: '${NATIVE_CIDR_BLOCK}'\"\n\n          cilium install --dry-run-helm-values ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            --set=k8sServiceHost=\"${K8S_API_SRV_ADDR}\" --set=k8sServicePort=443 \\\n            --set=ipv4NativeRoutingCIDR=\"${NATIVE_CIDR_BLOCK}\"\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            --set=k8sServiceHost=\"${K8S_API_SRV_ADDR}\" --set=k8sServicePort=443 \\\n            --set=ipv4NativeRoutingCIDR=\"${NATIVE_CIDR_BLOCK}\"\n\n      - name: Delete context ref\n        run: |\n          rm -rf untrusted/\n\n      # This needs to be performed in a different step, because nodeGroups are not\n      # supported during cluster creation in a cluster without VPC CNI. Cilium is\n      # also required to be already installed for the step to complete successfully.\n      - name: Create EKS nodegroups\n        shell: bash\n        run: |\n          cat <<EOF > eks-nodegroup.yaml\n          apiVersion: eksctl.io/v1alpha5\n          kind: ClusterConfig\n\n          metadata:\n            name: ${{ steps.vars.outputs.cluster_name }}\n            region: ${{ steps.vars.outputs.eks_region }}\n            version: \"${{ steps.vars.outputs.eks_version }}\"\n            tags:\n              usage: \"${{ github.repository_owner }}-${{ github.event.repository.name }}\"\n              owner: \"${{ steps.vars.outputs.owner }}\"\n\n          managedNodeGroups:\n          - name: ng-amd64-client\n            instanceTypes:\n            - ${{ steps.vars.outputs.node_instance_type }}\n            availabilityZones:\n            - ${{ steps.vars.outputs.eks_zone_1 }}\n            desiredCapacity: ${{ steps.vars.outputs.num_client_nodes }}\n            spot: false\n            privateNetworking: true\n            volumeType: \"gp3\"\n            volumeSize: 20\n            maxPodsPerNode: 110\n            taints:\n            - key: \"node.cilium.io/agent-not-ready\"\n              value: \"true\"\n              effect: \"NoExecute\"\n            labels:\n              role.scaffolding/egw-client: \"true\"\n          - name: ng-amd64-egw-node\n            instanceTypes:\n            - ${{ steps.vars.outputs.node_instance_type }}\n            availabilityZones:\n            - ${{ steps.vars.outputs.eks_zone_1 }}\n            desiredCapacity: 1\n            spot: false\n            privateNetworking: true\n            volumeType: \"gp3\"\n            volumeSize: 20\n            maxPodsPerNode: 110\n            taints:\n            - key: \"node.cilium.io/agent-not-ready\"\n              value: \"true\"\n              effect: \"NoExecute\"\n            labels:\n              role.scaffolding/egw-node: \"true\"\n          - name: ng-amd64-heapster\n            instanceTypes:\n            - ${{ steps.vars.outputs.node_instance_type }}\n            availabilityZones:\n            - ${{ steps.vars.outputs.eks_zone_1 }}\n            desiredCapacity: 1\n            spot: false\n            privateNetworking: true\n            volumeType: \"gp3\"\n            volumeSize: 20\n            maxPodsPerNode: 110\n            taints:\n            - key: \"node.cilium.io/agent-not-ready\"\n              value: \"true\"\n              effect: \"NoExecute\"\n            labels:\n              role.scaffolding/monitoring: \"true\"\n          - name: ng-amd64-no-cilium\n            instanceTypes:\n            - ${{ steps.vars.outputs.node_instance_type }}\n            availabilityZones:\n            - ${{ steps.vars.outputs.eks_zone_2 }}\n            desiredCapacity: 1\n            spot: false\n            privateNetworking: true\n            volumeType: \"gp3\"\n            volumeSize: 20\n            taints:\n            - key: \"cilium.io/no-schedule\"\n              value: \"true\"\n              effect: \"NoSchedule\"\n            labels:\n              cilium.io/no-schedule: \"true\"\n            # Manually inject a dummy CNI configuration to let the Kubelet turn\n            # ready. This is necessary as otherwise the node creation would\n            # never complete. Regardless, no pods will be scheduled here given\n            # that the node is tainted.\n            preBootstrapCommands:\n            - \"echo '{ \\\"cniVersion\\\": \\\"0.3.1\\\", \\\"name\\\": \\\"dummy\\\", \\\"type\\\": \\\"dummy-cni\\\", \\\"log-file\\\": \\\"/var/run/dummy.log\\\" }' > /etc/cni/net.d/05-dummy.conf\"\n          EOF\n\n          eksctl create nodegroup -f ./eks-nodegroup.yaml --timeout=10m\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n\n      - name: Run preflight steps\n        shell: bash\n        working-directory: ./.github/actions/cl2-modules/egw\n        env:\n          EGW_IMAGE_TAG: ${{ env.egw_utils_ref }}\n        run: |\n          get_node_internal_ip() {\n            kubectl get node -l \"$1\" -ojsonpath='{.items[*].status.addresses[?(@.type==\"InternalIP\")].address}' | \\\n              awk '{print $1}'  # Ignore the IPv6 address in dual stack clusters\n          }\n\n          # shellcheck disable=SC2046\n          echo CL2_EGW_GATEWAY_ADDRESS=$(get_node_internal_ip \"role.scaffolding/egw-node=true\") >> $GITHUB_ENV\n          # shellcheck disable=SC2046\n          echo CL2_EGW_EXTERNAL_TARGET=$(get_node_internal_ip \"cilium.io/no-schedule=true\") >> $GITHUB_ENV\n\n      - name: Run CL2\n        id: run-cl2\n        working-directory: ./perf-tests/clusterloader2\n        shell: bash\n        timeout-minutes: 40\n        env:\n          CL2_PROMETHEUS_PVC_ENABLED: \"false\"\n          CL2_ENABLE_PVS: \"false\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_OPERATOR: \"true\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT: \"true\"\n          CL2_PROMETHEUS_MEMORY_SCALE_FACTOR: \"2.0\"\n          CL2_PROMETHEUS_SCRAPE_CILIUM_AGENT_INTERVAL: \"10s\"\n          CL2_PROMETHEUS_NODE_SELECTOR: 'role.scaffolding/monitoring: \"true\"'\n          CL2_EGW_TEST_IMAGE: quay.io/cilium/egw-scale-utils:${{ env.egw_utils_ref }}\n          CL2_NUM_EGW_CLIENTS: \"${{ steps.vars.outputs.num_client_pods }}\"\n          CL2_EGW_CLIENTS_QPS: \"${{ steps.vars.outputs.client_qps }}\"\n          CL2_MEDIAN_BOOTSTRAP_THRESHOLD: \"80\" # Takes a bit for ENI interfaces to be added\n          CL2_EGW_CREATE_POLICY: ${{ matrix.test_type == 'egw' }}\n          CL2_EGW_MANIFESTS_DIR: ../../.github/actions/cl2-modules/egw/manifests\n          CL2_EGW_PERF_UDP_MSG_SIZE: 8900\n        run: |\n          echo \"CL2-related environment variables\"\n          printenv | grep CL2_\n\n          mkdir ./report\n          go run ./cmd/clusterloader.go \\\n            -v=2 \\\n            --testconfig=../../.github/actions/cl2-modules/egw/config.yaml \\\n            --prometheus-additional-monitors-path=../../.github/actions/cl2-modules/egw/prom-extra-podmons \\\n            --provider=aws \\\n            --enable-exec-service=false \\\n            --enable-prometheus-server \\\n            --prometheus-scrape-kubelets \\\n            --tear-down-prometheus-server=false \\\n            --report-dir=./report \\\n            --experimental-prometheus-snapshot-to-report-dir=true \\\n            --kubeconfig=$HOME/.kube/config \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            2>&1 | tee cl2-output.txt\n\n          # The cilium-cli creates files owned by the root user when run as a container.\n          sudo chmod --recursive +r ./report\n\n      - name: Get sysdump\n        if: ${{ always() && steps.install-cilium.outcome != 'skipped' && steps.install-cilium.outcome != 'cancelled' }}\n        run: |\n          cilium status\n          cilium sysdump \\\n            --output-filename cilium-sysdump-final \\\n            --extra-label-selectors=app.kubernetes.io/name=egw-client \\\n            --extra-label-selectors=app.kubernetes.io/name=egw-external-target\n          sudo chmod +r cilium-sysdump-final.zip\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"final-${{ matrix.test_type }}\"\n          job_status: \"${{ job.status }}\"\n          junits-directory: 'report'\n          capture_sysdump: 'false'\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-cl2.outcome != 'skipped' && steps.run-cl2.outcome != 'cancelled' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ steps.vars.outputs.test_name }}\n          tested_sha: ${{ steps.vars.outputs.SHA }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          artifacts: ./perf-tests/clusterloader2/report/\n          other_files: cilium-sysdump-final.zip ./perf-tests/clusterloader2/cl2-output.txt\n\n      # Refresh credentials\n      - name: Set up AWS CLI credentials\n        if:  ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        uses: aws-actions/configure-aws-credentials@a03048d87541d1d9fcf2ecf528a4a65ba9bd7838 # v5.0.0\n        with:\n          role-to-assume: ${{ secrets.AWS_PR_ASSUME_ROLE }}\n          aws-region: ${{ steps.vars.outputs.eks_region }}\n\n      - name: Cleanup cluster\n        if: ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        run: |\n          eksctl delete cluster --name ${{ steps.vars.outputs.cluster_name }} --region ${{ steps.vars.outputs.eks_region }}\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: install-and-scaletest\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.install-and-scaletest.result }}\n"
						}
					},
					{
						"name": "scale-test-node-throughput-gce.yaml",
						"object": {
							"text": "name: Node Throughput Test\n\non:\n  schedule:\n    - cron: '39 0 * * *'\n\n# For testing uncomment following lines:\n#  push:\n#    branches:\n#      - your_branch_name\n\npermissions:\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To be able to request the JWT from GitHub's OIDC provider\n  id-token: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go_version: 1.25.1\n  # Adding k8s.local to the end makes kops happy-\n  # has stricter DNS naming requirements.\n  test_name: node-throughput\n  cluster_name: ${{ github.run_id }}-${{ github.run_attempt }}\n  GCP_PERF_RESULTS_BUCKET: gs://cilium-scale-results\n  # renovate: datasource=docker depName=google/cloud-sdk\n  gcloud_version: 537.0.0\n\njobs:\n  install-and-scaletest:\n    runs-on: ubuntu-24.04\n    name: Install and Scale Test\n    timeout-minutes: 120\n    env:\n      job_name: \"Install and Scale Test\"\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ github.sha }}\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          SHA=\"${{ github.sha }}\"\n\n          # Setup Cilium install options\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set=cluster.name=${{ env.cluster_name }} \\\n            --wait=false\"\n\n          # Adding k8s.local to the end makes kops happy\n          # has stricter DNS naming requirements.\n          CLUSTER_NAME=\"${{ env.test_name }}-${{ env.cluster_name }}.k8s.local\"\n\n          echo SHA=${SHA} >> $GITHUB_OUTPUT\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n          echo CLUSTER_NAME=${CLUSTER_NAME} >> $GITHUB_OUTPUT\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.SHA }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Install Go\n        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00 # v6.0.0\n        with:\n          go-version: ${{ env.go_version }}\n\n      - name: Install Kops\n        uses: cilium/scale-tests-action/install-kops@082339e175a65c282c44c13bf875822e23911359 # main\n\n      - name: Setup gcloud credentials\n        uses: google-github-actions/auth@7c6bc770dae815cd3e89ee6cdf493a5fab2cc093 # v3.0.0\n        with:\n          workload_identity_provider: ${{ secrets.GCP_PERF_WORKLOAD_IDENTITY_PROVIDER }}\n          service_account: ${{ secrets.GCP_PERF_SA }}\n          create_credentials_file: true\n          export_environment_variables: true\n\n      - name: Setup gcloud CLI\n        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db # v3.0.1\n        with:\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n          version: ${{ env.gcloud_version }}\n\n      - name: Clone ClusterLoader2\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          repository: kubernetes/perf-tests\n          # Avoid using renovate to update this dependency because: (1)\n          # perf-tests does not tag or release, so renovate will pull\n          # all updates to the default branch and (2) continually\n          # updating CL2 may impact the stability of the scale test\n          # results.\n          ref: 920c39ef245a81bd8fb39d7fecf39eb35820d9ef\n          persist-credentials: false\n          sparse-checkout: clusterloader2\n          path: perf-tests\n\n      - name: Deploy cluster\n        id: deploy-cluster\n        uses: cilium/scale-tests-action/create-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 30\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          control_plane_size: n2-standard-4\n          control_plane_count: 1\n          node_size: e2-standard-8\n          node_count: 1\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n          project_id: ${{ secrets.GCP_PERF_PROJECT_ID }}\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.SHA }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Display version info of installed tools\n        run: |\n          echo \"--- go ---\"\n          go version\n          echo \"--- cilium-cli ---\"\n          cilium version --client\n          echo \"--- kops ---\"\n          ./kops version\n          echo \"--- gcloud ---\"\n          gcloud version\n\n      - name: Setup firewall rules\n        uses: cilium/scale-tests-action/setup-firewall@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n\n      - name: Install Cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for cluster to be ready\n        uses: cilium/scale-tests-action/validate-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        timeout-minutes: 20\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n\n      - name: Run CL2\n        id: run-cl2\n        working-directory: ./perf-tests/clusterloader2\n        timeout-minutes: 30\n        shell: bash\n        # --enable-exec-service=false to reduce number of pods so 100 pods can fit in node\n        # POD_STARTUP_LATENCY_THRESHOLD=60s so the test doesn't fail, currently we have ~30s pods startup latency\n        run: |\n          mkdir ./report\n          echo POD_STARTUP_LATENCY_THRESHOLD: 60s >> ./testoverrides.yaml\n          echo POD_COUNT: 98 >> ./testoverrides.yaml\n\n          go run ./cmd/clusterloader.go \\\n            -v=4 \\\n            --testconfig=./testing/node-throughput/config.yaml \\\n            --testoverrides=./testoverrides.yaml \\\n            --enable-exec-service=false \\\n            --provider=gce \\\n            --enable-prometheus-server \\\n            --testoverrides=./testing/prometheus/not-scrape-kube-proxy.yaml \\\n            --tear-down-prometheus-server=false \\\n            --report-dir=./report \\\n            --kubeconfig=$HOME/.kube/config \\\n            2>&1 | tee cl2-output.txt\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          always_capture_sysdump: true\n          artifacts_suffix: \"final\"\n          job_status: \"${{ job.status }}\"\n          junits-directory: 'report'\n\n      - name: Cleanup cluster\n        if: ${{ always() && steps.deploy-cluster.outcome != 'skipped' }}\n        uses: cilium/scale-tests-action/cleanup-cluster@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          cluster_name: ${{ steps.vars.outputs.cluster_name }}\n          kops_state: ${{ secrets.GCP_PERF_KOPS_STATE_STORE }}\n\n      - name: Export results and sysdump to GS bucket\n        if: ${{ always() && steps.run-cl2.outcome != 'skipped' }}\n        uses: cilium/scale-tests-action/export-results@082339e175a65c282c44c13bf875822e23911359 # main\n        with:\n          test_name: ${{ env.test_name }}\n          tested_sha: ${{ steps.vars.outputs.SHA }}\n          results_bucket: ${{ env.GCP_PERF_RESULTS_BUCKET }}\n          results_regex: ''\n          artifacts: ./perf-tests/clusterloader2/report/\n          other_files: cilium-sysdump-final.zip ./perf-tests/clusterloader2/cl2-output.txt\n"
						}
					},
					{
						"name": "tests-ces-migrate.yaml",
						"object": {
							"text": "name: CiliumEndpointSlice migration (ci-ces-migrate)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 5/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - push: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  KIND_CONFIG: .github/kind-config.yaml\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci hubble-relay-ci cilium-cli-ci\n\n  setup-and-test:\n    needs: [wait-for-images]\n    runs-on: ubuntu-24.04\n    name: Installation and Migration Test\n    timeout-minutes: 30\n    env:\n      job_name: \"Installation and Migration Test\"\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout target branch to access local actions\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ github.base_ref || github.ref }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }}\"\n\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo sha=${SHA} >> $GITHUB_OUTPUT\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.KIND_CONFIG }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Set up install variables\n        id: cilium-config\n        uses: ./.github/actions/cilium-config\n        with:\n          image-tag: ${{ steps.vars.outputs.sha }}\n          chart-dir: 'install/kubernetes/cilium'\n          ipv6: false\n          egress-gateway: false # Currently incompatible with CES\n          mutual-auth: false\n          misc: 'bpfClockProbe=false,cni.uninstall=false'\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.cilium-config.outputs.config }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl get pods --all-namespaces -o wide\n          mkdir -p cilium-junits\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Setup conn-disrupt-test\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Enable CiliumEndpointSlice\n        shell: bash\n        run: |\n          kubectl patch -n kube-system configmap cilium-config --type merge --patch '{\"data\":{\"enable-cilium-endpoint-slice\":\"true\"}}'\n\n          kubectl rollout restart -n kube-system deployment cilium-operator\n          # shellcheck disable=SC2034\n          for i in $(seq 1 6);\n          do\n            if [[ $(kubectl get crd ciliumendpointslices.cilium.io) != \"\" ]]; then\n              break\n            fi\n            sleep 10\n          done\n\n          kubectl wait --for condition=established --timeout=2m crd/ciliumendpointslices.cilium.io\n\n          kubectl rollout restart -n kube-system ds cilium\n\n          cilium status --wait --interactive=false\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Run tests after migration\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: ces-enable\n          full-test: 'true'\n          test-concurrency: 5\n          extra-connectivity-test-flags: ${{ steps.vars.outputs.connectivity_test_defaults }}\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          always_capture_sysdump: true\n          artifacts_suffix: \"tests-ces-migrate\"\n          job_status: \"${{ job.status }}\"\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: setup-and-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "tests-cifuzz.yaml",
						"object": {
							"text": "name: CIFuzz\non:\n  schedule:\n    # Run the Fuzzers every Monday at 7am\n    - cron: '0 7 * * 1'\n  workflow_dispatch: {}\n  pull_request:\n    paths:\n      - '.github/workflows/tests-cifuzz.yaml'\n      - '**/fuzz_test.go'\n      - 'test/fuzzing/*'\npermissions: read-all\njobs:\n  Fuzzing:\n    name: Build and Run Fuzzers\n    runs-on: ubuntu-24.04\n    steps:\n    - name: Build Fuzzers\n      id: build\n      uses: google/oss-fuzz/infra/cifuzz/actions/build_fuzzers@aa0dba641cb81070221554e0d2ed4f97aa46db35\n      with:\n        oss-fuzz-project-name: 'cilium'\n        dry-run: false\n        language: go\n    - name: Run Fuzzers\n      uses: google/oss-fuzz/infra/cifuzz/actions/run_fuzzers@aa0dba641cb81070221554e0d2ed4f97aa46db35\n      with:\n        oss-fuzz-project-name: 'cilium'\n        fuzz-seconds: 600\n        dry-run: false\n        language: go\n    - name: Upload Crash\n      uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n      if: failure() && steps.build.outcome == 'success'\n      with:\n        name: artifacts\n        path: ./out/artifacts\n"
						}
					},
					{
						"name": "tests-clustermesh-upgrade.yaml",
						"object": {
							"text": "name: Cilium Cluster Mesh upgrade (ci-clustermesh)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n\n  push:\n    branches:\n      - main\n      - ft/main/**\n      - 'renovate/main-**'\n    paths-ignore:\n      - 'Documentation/**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - push: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  clusterName1: cluster1\n  clusterName2: cluster2\n  contextName1: kind-cluster1\n  contextName2: kind-cluster2\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n          images: cilium-ci operator-generic-ci hubble-relay-ci cilium-cli-ci clustermesh-apiserver-ci\n\n  upgrade-and-downgrade:\n    name: \"Upgrade and Downgrade Test\"\n    needs: wait-for-images\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    timeout-minutes: 60\n    env:\n      job_name: \"Installation and Connectivity Test\"\n\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - name: '1'\n            encryption: 'disabled'\n            kube-proxy: 'iptables'\n            external-kvstore: false\n            max-connected-clusters: 255\n            cm-auth-mode: 'legacy'\n\n          - name: '2'\n            encryption: 'disabled'\n            kube-proxy: 'none'\n            external-kvstore: false\n            max-connected-clusters: 511\n            cm-auth-mode: 'migration'\n\n          # Currently, ipsec requires to synchronously regenerate the host\n          # endpoint to ensure ordering (#25735). Given that this is a blocking\n          # operation, we cannot wait for full clustermesh synchronization\n          # for an extended period of time, as that would prevent the agents from\n          # becoming ready (and new pods scheduled). This means that we will\n          # experience cross-cluster connection drops during upgrades/downgrades,\n          # given that the timeout is too low to account for the initialization\n          # of a new clustermesh-apiserver replica (while it is enough to prevent\n          # issues in case of agent restarts, if all remote clusters are ready,\n          # as well as when connecting to an external kvstore as in this case).\n          - name: '3'\n            encryption: 'ipsec'\n            kube-proxy: 'iptables'\n            external-kvstore: true\n            max-connected-clusters: 255\n\n          - name: '4'\n            encryption: 'wireguard'\n            kube-proxy: 'iptables'\n            external-kvstore: false\n            max-connected-clusters: 511\n            cm-auth-mode: 'cluster'\n\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Set up newest settings\n        id: newest-vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ inputs.SHA || github.sha }}\n          chart-dir: ./untrusted/cilium-newest/install/kubernetes/cilium\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n        with:\n          hubble: false\n          include-unsafe-tests: true\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          CILIUM_DOWNGRADE_VERSION=$(contrib/scripts/print-downgrade-version.sh stable)\n          echo \"downgrade_version=${CILIUM_DOWNGRADE_VERSION}\" >> $GITHUB_OUTPUT\n\n          # * Monitor aggregation is set to medium to avoid the performance penalty\n          #   in the testing environment due to the relatively high traffic load.\n          # * We explicitly configure the IPAM mode to prevent it from being\n          #   reset to the default value on upgrade/downgrade due to --reset-values.\n          # * We explicitly configure the sync timeout to a higher value to\n          #   give enough time to the clustermesh-apiserver to restart after\n          #   the upgrade/downgrade before that agents regenerate the endpoints.\n          # * We configure the maximum number of unavailable agents to 1 to slow\n          #   down the rollout process and highlight possible connection disruption\n          #   occurring in the meanwhile.\n          CILIUM_INSTALL_DEFAULTS=\" \\\n            --set=debug.enabled=true \\\n            --set=hubble.enabled=true \\\n            --set=routingMode=tunnel \\\n            --set=tunnelProtocol=vxlan \\\n            --set=ipv4.enabled=true \\\n            --set=ipv6.enabled=true \\\n            --set=kubeProxyReplacement=${{ matrix.kube-proxy == 'none' }} \\\n            --set=bpf.masquerade=${{ matrix.kube-proxy == 'none' }} \\\n            --set=ipam.mode=kubernetes \\\n            --set=operator.replicas=1 \\\n            --set=updateStrategy.rollingUpdate.maxUnavailable=1 \\\n            --set=clustermesh.useAPIServer=${{ !matrix.external-kvstore }} \\\n            --set=clustermesh.maxConnectedClusters=${{ matrix.max-connected-clusters }} \\\n            --set=clustermesh.config.enabled=true \\\n            --set=extraConfig.clustermesh-sync-timeout=10m \\\n            --set=extraConfig.lb-init-wait-timeout=4m \\\n            --set=clustermesh.apiserver.readinessProbe.periodSeconds=1 \\\n            --set=clustermesh.apiserver.kvstoremesh.readinessProbe.periodSeconds=1 \\\n            --set=clustermesh.apiserver.updateStrategy.rollingUpdate.maxSurge=1 `# Use surge update strategy to enable clients to failover` \\\n            --set=clustermesh.apiserver.updateStrategy.rollingUpdate.maxUnavailable=0 \\\n            --set=clustermesh.apiserver.tls.authMode=${{ matrix.cm-auth-mode }} \\\n          \"\n\n          # Run only a limited subset of tests to reduce the amount of time\n          # required. The full suite is run in conformance-clustermesh.\n          CONNECTIVITY_TEST_DEFAULTS=\" \\\n            ${{ steps.e2e_config.outputs.test_flags }} \\\n            --test='no-interrupted-connections' \\\n            --test='no-unexpected-packet-drops' \\\n            --test='check-log-errors' \\\n            --test='no-policies/' \\\n            --test='no-policies-extra/' \\\n            --test='allow-all-except-world/' \\\n            --test='client-ingress/' \\\n            --test='client-egress/' \\\n            --test='cluster-entity-multi-cluster/' \\\n            --test='!/pod-to-world' \\\n            --test='!/pod-to-cidr' \\\n          \"\n\n          CILIUM_INSTALL_ENCRYPTION=\"\"\n          if [ \"${{ matrix.encryption }}\" != \"disabled\" ]; then\n            CILIUM_INSTALL_ENCRYPTION=\" \\\n              --set=encryption.enabled=true \\\n              --set=encryption.type=${{ matrix.encryption }}\"\n          fi\n\n          echo \"cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} ${CILIUM_INSTALL_ENCRYPTION}\" >> $GITHUB_OUTPUT\n          echo \"connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS}\" >> $GITHUB_OUTPUT\n\n      - name: Generate Kind configuration files\n        run: |\n          PODCIDR=10.242.0.0/16,fd00:10:242::/48 \\\n            SVCCIDR=10.243.0.0/16,fd00:10:243::/112 \\\n            IPFAMILY=dual \\\n            KUBEPROXYMODE=${{ matrix.kube-proxy }} \\\n            envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-cluster1.yaml\n\n          PODCIDR=10.244.0.0/16,fd00:10:244::/48 \\\n            SVCCIDR=10.245.0.0/16,fd00:10:245::/112 \\\n            IPFAMILY=dual \\\n            KUBEPROXYMODE=${{ matrix.kube-proxy }} \\\n            envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-cluster2.yaml\n\n      - name: Create Kind cluster 1\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          cluster_name: ${{ env.clusterName1 }}\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ./.github/kind-config-cluster1.yaml\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Create Kind cluster 2\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          cluster_name: ${{ env.clusterName2 }}\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ./.github/kind-config-cluster2.yaml\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ inputs.SHA || github.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Label one of the nodes as external to the cluster\n        # Currently, we only use external nodes for the north/south\n        # conn-disrupt-test, which requires KPR to be enabled.\n        if: matrix.kube-proxy == 'none'\n        run: |\n          kubectl --context ${{ env.contextName1 }} label node \\\n            ${{ env.clusterName1 }}-worker2 cilium.io/no-schedule=true\n          kubectl --context ${{ env.contextName2 }} label node \\\n            ${{ env.clusterName2 }}-worker2 cilium.io/no-schedule=true\n\n      # Make sure that coredns uses IPv4-only upstream DNS servers also in case of clusters\n      # with IP family dual, since IPv6 ones are not reachable and cause spurious failures.\n      # Additionally, this is also required to workaround\n      # https://github.com/cilium/cilium/issues/23283#issuecomment-1597282247.\n      - name: Configure the coredns nameservers\n        run: |\n          COREDNS_PATCH=\"\n          spec:\n            template:\n              spec:\n                dnsPolicy: None\n                dnsConfig:\n                  nameservers:\n                  - 8.8.4.4\n                  - 8.8.8.8\n          \"\n\n          kubectl --context ${{ env.contextName1 }} patch deployment -n kube-system coredns --patch=\"$COREDNS_PATCH\"\n          kubectl --context ${{ env.contextName2 }} patch deployment -n kube-system coredns --patch=\"$COREDNS_PATCH\"\n\n      - name: Create the IPSec secret in both clusters\n        if: matrix.encryption == 'ipsec'\n        run: |\n          SECRET=\"3+ rfc4106(gcm(aes)) $(openssl rand -hex 20) 128\"\n          kubectl --context ${{ env.contextName1 }} create -n kube-system secret generic cilium-ipsec-keys --from-literal=keys=\"${SECRET}\"\n          kubectl --context ${{ env.contextName2 }} create -n kube-system secret generic cilium-ipsec-keys --from-literal=keys=\"${SECRET}\"\n\n      - name: Start kvstore clusters\n        id: kvstore\n        if: matrix.external-kvstore\n        uses: ./.github/actions/kvstore\n        with:\n          clusters: 2\n\n      - name: Create the secret containing the kvstore credentials\n        if: matrix.external-kvstore\n        run: |\n          kubectl --context ${{ env.contextName1 }} create -n kube-system -f ${{ steps.kvstore.outputs.cilium_etcd_secrets_path }}\n          kubectl --context ${{ env.contextName2 }} create -n kube-system -f ${{ steps.kvstore.outputs.cilium_etcd_secrets_path }}\n\n      - name: Set clustermesh connection parameters\n        id: clustermesh-vars\n        run: |\n          # Let's retrieve in advance the parameters to mesh the two clusters, so\n          # that we don't need to do that through the CLI in a second step, as it\n          # would be reset during upgrade (as we are resetting the values).\n\n          # Explicitly configure the NodePorts to make sure that they are different\n          # in each cluster, to workaround #24692\n          PORT1=32379\n          PORT2=32380\n\n          CILIUM_INSTALL_CLUSTER1=\" \\\n            --set cluster.name=${{ env.clusterName1 }} \\\n            --set cluster.id=1 \\\n            --set clustermesh.apiserver.service.nodePort=$PORT1 \\\n          \"\n\n          CILIUM_INSTALL_CLUSTER2=\" \\\n            --set cluster.name=${{ env.clusterName2 }} \\\n            --set cluster.id=${{ matrix.max-connected-clusters }} \\\n            --set clustermesh.apiserver.service.nodePort=$PORT2 \\\n          \"\n\n          CILIUM_INSTALL_COMMON=\" \\\n            --set clustermesh.config.clusters[0].name=${{ env.clusterName1 }} \\\n            --set clustermesh.config.clusters[1].name=${{ env.clusterName2 }} \\\n          \"\n\n          if [ \"${{ matrix.external-kvstore }}\" == \"true\" ]; then\n            CILIUM_INSTALL_COMMON=\"$CILIUM_INSTALL_COMMON \\\n              ${{ steps.kvstore.outputs.cilium_install_clustermesh }}\"\n          else\n            IP1=$(kubectl --context ${{ env.contextName1 }} get nodes \\\n              ${{ env.clusterName1 }}-worker -o wide --no-headers | awk '{ print $6 }')\n            IP2=$(kubectl --context ${{ env.contextName2 }} get nodes \\\n              ${{ env.clusterName2 }}-worker -o wide --no-headers | awk '{ print $6 }')\n\n            CILIUM_INSTALL_COMMON=\"$CILIUM_INSTALL_COMMON \\\n              --set clustermesh.config.clusters[0].ips={$IP1} \\\n              --set clustermesh.config.clusters[0].port=$PORT1 \\\n              --set clustermesh.config.clusters[1].ips={$IP2} \\\n              --set clustermesh.config.clusters[1].port=$PORT2 \\\n            \"\n          fi\n\n          echo cilium_install_cluster1=\"$CILIUM_INSTALL_CLUSTER1 $CILIUM_INSTALL_COMMON\" >> $GITHUB_OUTPUT\n          echo cilium_install_cluster2=\"$CILIUM_INSTALL_CLUSTER2 $CILIUM_INSTALL_COMMON\" >> $GITHUB_OUTPUT\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.newest-vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted/cilium-newest\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Checkout ${{ steps.vars.outputs.downgrade_version }} branch\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.downgrade_version }}\n          persist-credentials: false\n          path: untrusted/cilium-downgrade\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Retrieve downgrade target SHA\n        id: downgrade-branch\n        run: |\n          echo \"sha=$(cd untrusted/cilium-downgrade && git rev-parse HEAD)\" >> $GITHUB_OUTPUT\n\n      - name: Set up downgrade settings\n        id: downgrade-vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ steps.downgrade-branch.outputs.sha }}\n          chart-dir: ./untrusted/cilium-downgrade/install/kubernetes/cilium\n\n      - name: Wait for images to be available (downgrade)\n        timeout-minutes: 10\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci clustermesh-apiserver-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.downgrade-branch.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n\n      - name: Install Cilium ${{ steps.vars.outputs.downgrade_version }} in cluster1\n        id: install-cilium-cluster1\n        env:\n          KVSTORE_ID: 1\n        run: |\n          cilium --context ${{ env.contextName1 }} install \\\n            ${{ steps.downgrade-vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.kvstore.outputs.cilium_install_kvstore }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_cluster1 }} \\\n            --nodes-without-cilium\n\n      - name: Copy the Cilium CA secret to cluster2, as they must match\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          kubectl --context ${{ env.contextName1 }} get secret -n kube-system cilium-ca -o yaml |\n            kubectl --context ${{ env.contextName2 }} create -f -\n\n      - name: Install Cilium in cluster2\n        env:\n          KVSTORE_ID: 2\n        run: |\n          cilium --context ${{ env.contextName2 }} install \\\n            ${{ steps.newest-vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.kvstore.outputs.cilium_install_kvstore }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_cluster2 }} \\\n            --nodes-without-cilium\n\n      - name: Wait for cluster mesh status to be ready\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait --wait-duration=5m\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait --wait-duration=5m\n\n      - name: Make JUnit report directory\n        run: |\n          mkdir -p cilium-junits\n\n      - name: Run connectivity test - pre-upgrade (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} \\\n            ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --junit-file \"cilium-junits/${{ env.job_name }} - pre-upgrade (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests pre-upgrade (${{ join(matrix.*, ', ') }})\"\n\n          # Create pods which establish long lived connections. They will be used by\n          # subsequent connectivity tests with --include-conn-disrupt-test to catch any\n          # interruption in such flows.\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} --hubble=false \\\n            --include-conn-disrupt-test --include-conn-disrupt-test-ns-traffic \\\n            --conn-disrupt-test-setup \\\n            --conn-disrupt-test-restarts-path \"./cilium-conn-disrupt-restarts\" \\\n            --conn-disrupt-dispatch-interval 0ms\n\n      - name: Features tested on cluster 1\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName1 }}\"\n          title: \"Summary of all features tested on cluster 1\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 1\"\n\n      - name: Features tested on cluster 2\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName2 }}\"\n          title: \"Summary of all features tested on cluster 2\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 2\"\n\n\n      - name: Upgrade Cilium in cluster1\n        env:\n          KVSTORE_ID: 1\n        run: |\n          cilium --context ${{ env.contextName1 }} upgrade --reset-values \\\n            ${{ steps.newest-vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.kvstore.outputs.cilium_install_kvstore }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_cluster1 }} \\\n            --nodes-without-cilium\n\n      - name: Wait for cluster mesh status to be ready\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait --wait-duration=5m\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait --wait-duration=5m\n\n      - name: Set cilium connectivity test namespace\n        id: cilium-cli\n        run: |\n          NAMESPACE=$(kubectl get namespace -l \"app.kubernetes.io/name=cilium-cli\" -o name | sort | cut -d / -f 2 | head -1)\n          echo namespace=\"$NAMESPACE\" >> $GITHUB_OUTPUT\n\n      - name: Write the Service manifest for testing failover\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          cat << EOF > echo-failover.yaml\n          apiVersion: v1\n          kind: Service\n          metadata:\n            annotations:\n              service.cilium.io/global: \"true\"\n            labels:\n              kind: echo\n              context: failover\n            name: echo-other-node-failover\n            namespace: ${{ steps.cilium-cli.outputs.namespace }}\n          spec:\n            ipFamilies:\n            - IPv4\n            - IPv6\n            ipFamilyPolicy: PreferDualStack\n            ports:\n            - name: http\n              port: 80\n              protocol: TCP\n              targetPort: 8080\n            selector:\n              name: echo-other-node\n            sessionAffinity: None\n            type: ClusterIP\n          EOF\n\n      - name: Restart clustermesh-apiserver and ensure client can connect to new Service\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          echo \"Restarting clustermesh-apiserver deployments\"\n          kubectl --context ${{ env.contextName2 }} -n kube-system rollout restart deployment -l k8s-app=clustermesh-apiserver\n          kubectl --context ${{ env.contextName2 }} -n kube-system rollout status deployment -l k8s-app=clustermesh-apiserver\n\n          echo \"Deploying a global Service to test failover\"\n          kubectl --context ${{ env.contextName1 }} apply -f echo-failover.yaml\n          kubectl --context ${{ env.contextName2 }} apply -f echo-failover.yaml\n\n          echo \"Testing client connection to global Service\"\n          kubectl --context ${{ env.contextName1 }} -n ${{ steps.cilium-cli.outputs.namespace }} exec deploy/client -i -- curl -s -v --connect-timeout 2 --max-time 5 --retry-max-time 60 --retry-all-errors --retry 10 --output /dev/null --fail echo-other-node-failover\n\n          # Clean up the service so that it can be re-deployed in subsequent steps\n          kubectl --context ${{ env.contextName1 }} delete -f echo-failover.yaml\n          kubectl --context ${{ env.contextName2 }} delete -f echo-failover.yaml\n\n      - name: Disable kvstoremesh on cluster1\n        if: ${{ !matrix.external-kvstore }}\n        env:\n          KVSTORE_ID: 1\n        run: |\n          cilium --context ${{ env.contextName1 }} upgrade --reset-values \\\n            ${{ steps.newest-vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_cluster1 }} \\\n            --set clustermesh.apiserver.kvstoremesh.enabled=false \\\n            --nodes-without-cilium\n\n      - name: Wait for cluster mesh status to be ready\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait --wait-duration=5m\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait --wait-duration=5m\n\n      - name: Restart clustermesh-apiserver and ensure client can connect to new Service\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          echo \"Restarting clustermesh-apiserver deployments\"\n          kubectl --context ${{ env.contextName2 }} -n kube-system rollout restart deployment -l k8s-app=clustermesh-apiserver\n          kubectl --context ${{ env.contextName2 }} -n kube-system rollout status deployment -l k8s-app=clustermesh-apiserver\n\n          echo \"Deploying a global Service to test failover\"\n          kubectl --context ${{ env.contextName1 }} apply -f echo-failover.yaml\n          kubectl --context ${{ env.contextName2 }} apply -f echo-failover.yaml\n\n          echo \"Testing client connection to global Service\"\n          kubectl --context ${{ env.contextName1 }} -n ${{ steps.cilium-cli.outputs.namespace }} exec deploy/client -i -- curl -s -v --connect-timeout 2 --max-time 5 --retry-max-time 60 --retry-all-errors --retry 10 --output /dev/null --fail echo-other-node-failover\n\n          # Clean up the service so that it can be re-deployed in subsequent steps\n          kubectl --context ${{ env.contextName1 }} delete -f echo-failover.yaml\n          kubectl --context ${{ env.contextName2 }} delete -f echo-failover.yaml\n\n      - name: Gather additional troubleshooting information\n        run: |\n          kubectl --context ${{ env.contextName1 }} get po -n ${{ steps.cilium-cli.outputs.namespace }} -o wide -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)'\n          kubectl --context ${{ env.contextName2 }} get po -n ${{ steps.cilium-cli.outputs.namespace }} -o wide -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)'\n          kubectl --context ${{ env.contextName1 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --timestamps\n          kubectl --context ${{ env.contextName2 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --timestamps\n          kubectl --context ${{ env.contextName2 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --previous --ignore-errors --timestamps\n\n      - name: Run connectivity test - post-upgrade (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} \\\n            ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --include-conn-disrupt-test --include-conn-disrupt-test-ns-traffic \\\n            --conn-disrupt-test-restarts-path \"./cilium-conn-disrupt-restarts\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }} - post upgrade (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests post-upgrade (${{ join(matrix.*, ', ') }})\"\n\n          # Create pods which establish long lived connections. They will be used by\n          # subsequent connectivity tests with --include-conn-disrupt-test to catch any\n          # interruption in such flows.\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} --hubble=false \\\n            --include-conn-disrupt-test --include-conn-disrupt-test-ns-traffic \\\n            --conn-disrupt-test-setup \\\n            --conn-disrupt-test-restarts-path \"./cilium-conn-disrupt-restarts\" \\\n            --conn-disrupt-dispatch-interval 0ms\n\n      - name: Features tested on cluster 1 - post upgrade\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName1 }}\"\n          title: \"Summary of all features tested on cluster 1 - post upgrade\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 1 - post upgrade\"\n\n      - name: Features tested on cluster 2 - post upgrade\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName2 }}\"\n          title: \"Summary of all features tested on cluster 2 - post upgrade\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 2 - post upgrade\"\n\n\n      # Perform an additional \"stress\" test, scaling the clustermesh-apiservers in both clusters\n      # to zero replicas, and restarting all agents. Existing connections should not be disrupted.\n      # One exception to this is represented by Cilium being in charge of handling NodePort\n      # traffic, as the simultaneous restart of the clustermesh-apiserver pods in both clusters\n      # after rolling out all agents can lead to a circular dependency, as service reconciliation\n      # needs to wait on clustermesh synchronization, which requires the clustermesh-apiserver\n      # service to be reconciled to include the new backends.\n      - name: Scale the clustermesh-apiserver replicas to 0\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          kubectl --context ${{ env.contextName1 }} scale -n kube-system deploy/clustermesh-apiserver --replicas 0\n          if [ \"${{ matrix.kube-proxy }}\" != \"none\" ]; then\n            kubectl --context ${{ env.contextName2 }} scale -n kube-system deploy/clustermesh-apiserver --replicas 0\n          fi\n\n      - name: Rollout Cilium agents in both clusters\n        run: |\n          kubectl --context ${{ env.contextName1 }} rollout restart -n kube-system ds/cilium\n          kubectl --context ${{ env.contextName2 }} rollout restart -n kube-system ds/cilium\n\n          # Wait until all agents successfully restarted before scaling the replicas again\n          kubectl --context ${{ env.contextName1 }} rollout status -n kube-system ds/cilium --timeout=10m\n          kubectl --context ${{ env.contextName2 }} rollout status -n kube-system ds/cilium --timeout=10m\n\n      - name: Scale the clustermesh-apiserver replicas back to 1\n        if: ${{ !matrix.external-kvstore }}\n        run: |\n          kubectl --context ${{ env.contextName1 }} scale -n kube-system deploy/clustermesh-apiserver --replicas 1\n          kubectl --context ${{ env.contextName2 }} scale -n kube-system deploy/clustermesh-apiserver --replicas 1\n\n      - name: Wait for cluster mesh status to be ready\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait --wait-duration=5m\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait --wait-duration=5m\n\n      - name: Gather additional troubleshooting information\n        run: |\n          kubectl --context ${{ env.contextName1 }} get po -n ${{ steps.cilium-cli.outputs.namespace }} -o wide -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)'\n          kubectl --context ${{ env.contextName2 }} get po -n ${{ steps.cilium-cli.outputs.namespace }} -o wide -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)'\n          kubectl --context ${{ env.contextName1 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --timestamps\n          kubectl --context ${{ env.contextName2 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --timestamps\n          kubectl --context ${{ env.contextName2 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --previous --ignore-errors --timestamps\n\n      - name: Run connectivity test - stress-test (${{ join(matrix.*, ', ') }})\n        run: |\n          # Only check that no long living connection was disrupted\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} \\\n            --hubble=false \\\n            --log-code-owners --code-owners=${CILIUM_CLI_CODE_OWNERS_PATHS} \\\n            --exclude-code-owners=${CILIUM_CLI_EXCLUDE_OWNERS} \\\n            --flow-validation=disabled \\\n            --test='no-interrupted-connections' \\\n            --test='no-unexpected-packet-drops' \\\n            --include-conn-disrupt-test \\\n            --include-conn-disrupt-test-ns-traffic \\\n            --conn-disrupt-test-restarts-path \"./cilium-conn-disrupt-restarts\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }} - stress test (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests stess-test (${{ join(matrix.*, ', ') }})\"\n\n          # Create pods which establish long lived connections. They will be used by\n          # subsequent connectivity tests with --include-conn-disrupt-test to catch any\n          # interruption in such flows.\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} --hubble=false \\\n            --include-conn-disrupt-test --include-conn-disrupt-test-ns-traffic \\\n            --conn-disrupt-test-setup \\\n            --conn-disrupt-test-restarts-path \"./cilium-conn-disrupt-restarts\" \\\n            --conn-disrupt-dispatch-interval 0ms\n\n      - name: Features tested on cluster 1 - stress-test\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName1 }}\"\n          title: \"Summary of all features tested on cluster 1 - stress-test\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 1 - stress-test\"\n\n      - name: Features tested on cluster 2 - stress-test\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName2 }}\"\n          title: \"Summary of all features tested on cluster 2 - stress-test\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 2 - stress-test\"\n\n\n      - name: Downgrade Cilium in cluster1 to ${{ steps.vars.outputs.downgrade_version }} and enable kvstoremesh again\n        env:\n          KVSTORE_ID: 1\n        run: |\n          cilium --context ${{ env.contextName1 }} upgrade --reset-values \\\n            ${{ steps.downgrade-vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.vars.outputs.cilium_install_defaults }} \\\n            ${{ steps.kvstore.outputs.cilium_install_kvstore }} \\\n            ${{ steps.clustermesh-vars.outputs.cilium_install_cluster1 }} \\\n            --nodes-without-cilium\n\n      - name: Wait for cluster mesh status to be ready\n        run: |\n          cilium --context ${{ env.contextName1 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName2 }} status --wait --interactive=false --wait-duration=10m\n          cilium --context ${{ env.contextName1 }} clustermesh status --wait --wait-duration=5m\n          cilium --context ${{ env.contextName2 }} clustermesh status --wait --wait-duration=5m\n\n      - name: Gather additional troubleshooting information\n        run: |\n          kubectl --context ${{ env.contextName1 }} get po -n ${{ steps.cilium-cli.outputs.namespace }} -o wide -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)'\n          kubectl --context ${{ env.contextName2 }} get po -n ${{ steps.cilium-cli.outputs.namespace }} -o wide -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)'\n          kubectl --context ${{ env.contextName1 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --timestamps\n          kubectl --context ${{ env.contextName2 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --timestamps\n          kubectl --context ${{ env.contextName2 }} logs -n ${{ steps.cilium-cli.outputs.namespace }} -l 'kind in (test-conn-disrupt, test-conn-disrupt-ns-traffic)' --prefix --previous --ignore-errors --timestamps\n\n      - name: Run connectivity test - post-downgrade (${{ join(matrix.*, ', ') }})\n        run: |\n          cilium --context ${{ env.contextName1 }} connectivity test \\\n            --multi-cluster=${{ env.contextName2 }} \\\n            ${{ steps.vars.outputs.connectivity_test_defaults }} \\\n            --include-conn-disrupt-test --include-conn-disrupt-test-ns-traffic \\\n            --conn-disrupt-test-restarts-path \"./cilium-conn-disrupt-restarts\" \\\n            --junit-file \"cilium-junits/${{ env.job_name }} - post downgrade (${{ join(matrix.*, ', ') }}).xml\" \\\n            --junit-property github_job_step=\"Run tests post-downgrade (${{ join(matrix.*, ', ') }})\"\n\n      - name: Features tested on cluster 1 - post-downgrade\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName1 }}\"\n          title: \"Summary of all features tested on cluster 1 - post-downgrade\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 1 - post-downgrade\"\n\n      - name: Features tested on cluster 2 - post-downgrade\n        uses: ./.github/actions/feature-status\n        with:\n          cilium-cli: \"cilium --context ${{ env.contextName2 }}\"\n          title: \"Summary of all features tested on cluster 2 - post-downgrade\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - cluster 2 - post-downgrade\"\n\n\n      - name: Post-test information gathering\n        if: ${{ !success() && steps.install-cilium-cluster1.outcome != 'skipped' }}\n        run: |\n          cilium --context ${{ env.contextName1 }} status\n          cilium --context ${{ env.contextName1 }} clustermesh status\n          cilium --context ${{ env.contextName2 }} status\n          cilium --context ${{ env.contextName2 }} clustermesh status\n\n          kubectl config use-context ${{ env.contextName1 }}\n          kubectl get pods --all-namespaces -o wide\n          cilium sysdump --output-filename cilium-sysdump-context1-final-${{ join(matrix.*, '-') }}\n\n          kubectl config use-context ${{ env.contextName2 }}\n          kubectl get pods --all-namespaces -o wide\n          cilium sysdump --output-filename cilium-sysdump-context2-final-${{ join(matrix.*, '-') }}\n\n          if [ \"${{ matrix.external-kvstore }}\" == \"true\" ]; then\n            for i in {1..2}; do\n              echo\n              echo \"# Retrieving logs from kvstore$i docker container\"\n              docker logs kvstore$i\n            done\n          fi\n        shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n          capture_sysdump: false\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: upgrade-and-downgrade\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.upgrade-and-downgrade.result }}\n"
						}
					},
					{
						"name": "tests-datapath-verifier.yaml",
						"object": {
							"text": "name: Datapath BPF Complexity (ci-verifier)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 5/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  # renovate: datasource=golang-version depName=go\n  go-version: 1.25.1\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  setup-and-test:\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    name: Setup & Test\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: 'rhel8.6-20250812.093650'\n            ci-kernel: '510'\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: '5.10-20250812.093650'\n            ci-kernel: '510'\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: '5.15-20250812.093650'\n            ci-kernel: '510'\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: '6.1-20250812.093650'\n            ci-kernel: '61'\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: '6.6-20250812.093650'\n            ci-kernel: '61'\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: '6.12-20250812.093650'\n            ci-kernel: '61'\n          # renovate: datasource=docker depName=quay.io/lvh-images/complexity-test\n          - kernel: 'bpf-next-20250812.093650'\n            ci-kernel: 'netnext'\n    timeout-minutes: 60\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.SHA || github.sha }}\n          persist-credentials: false\n\n      - name: Provision LVH VMs\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          test-name: datapath-bpf-complexity\n          image: 'complexity-test'\n          image-version: ${{ matrix.kernel }}\n          host-mount: ./\n          images-folder-parent: \"/tmp\"\n          cpu: 4\n          # renovate: datasource=github-tags depName=cilium/little-vm-helper\n          lvh-version: \"v0.0.26\"\n          install-dependencies: 'true'\n          cmd: |\n            for i in {1..5}; do curl \"https://golang.org\" > /dev/null 2>&1 && break || sleep 5; echo \"Waiting for systemd-resolved to be ready...\"; done\n\n            git config --global --add safe.directory /host\n            uname -a\n\n            # The LVH image might ship with an arbitrary Go toolchain version,\n            # install the same Go toolchain version as current HEAD.\n            CGO_ENABLED=0 GOPROXY=direct GOSUMDB= go install golang.org/dl/go${{ env.go-version }}@latest\n            go${{ env.go-version }} download\n\n            # The LVH image ships with LLVM taken from a release Cilium version.\n            # Replace it with the one extracted from the cilium-builder image.\n            /host/contrib/scripts/extract-llvm.sh /tmp/llvm\n            mv /tmp/llvm/usr/local/bin/{clang,llc} /bin/\n            rm -r /tmp/llvm\n\n      - name: Run verifier tests\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            cd /host/\n            mkdir /host/datapath-verifier\n            # Run with cgo disabled, LVH images don't ship with gcc.\n            CGO_ENABLED=0 PRIVILEGED_TESTS=true go${{ env.go-version }} test -v -timeout=20m ./pkg/datapath/loader -run \"TestPrivilegedVerifier\" --cilium-base-path /host --kernel-version ${{ matrix.ci-kernel }} --result-dir /host/datapath-verifier\n\n      - name: Upload artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2\n        with:\n          name: datapath-verifier_${{ matrix.kernel }}\n          path: datapath-verifier\n          retention-days: 5\n\n  commit-status-final:\n    if: ${{ always() }}\n    name: Commit Status Final\n    needs: setup-and-test\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set final commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n          status: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "tests-e2e-upgrade.yaml",
						"object": {
							"text": "name: Cilium E2E Upgrade (ci-e2e-upgrade)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n  # Run every 8 hours\n  schedule:\n    - cron:  '0 5/8 * * *'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  test_concurrency: 5\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.generate-matrix.outputs.matrix }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/e2e\"\n          destination_directory=\"/tmp/generated/e2e\"\n          mkdir -p \"${destination_directory}\"\n\n          cat ${work_dir}/* > \"${destination_directory}/configs_merged.yaml\"\n\n          yq -o=json \"${destination_directory}/configs_merged.yaml\" | jq . > \"${destination_directory}/configs.json\"\n\n      - name: Generate Matrix\n        id: generate-matrix\n        run: |\n          cd /tmp/generated/e2e\n          jq '[.[] | del(.\"key-one\", .\"key-two\") | . as $entry | [$entry + {mode: \"minor\"}]] | flatten' configs.json > matrix.json\n          echo \"Generated matrix:\"\n          cat /tmp/generated/e2e/matrix.json\n          echo \"matrix=$(jq -c . < /tmp/generated/e2e/matrix.json)\" >> $GITHUB_OUTPUT\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  setup-and-test:\n    needs: [wait-for-images, generate-matrix]\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    name: 'Setup & Test'\n    env:\n      job_name: 'Setup & Test'\n    strategy:\n      fail-fast: false\n      max-parallel: 100\n      matrix:\n        include: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}\n\n    timeout-minutes: 55\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n          echo sha=${SHA} >> $GITHUB_OUTPUT\n          CILIUM_DOWNGRADE_VERSION=$(contrib/scripts/print-downgrade-version.sh stable)\n          echo downgrade_version=${CILIUM_DOWNGRADE_VERSION} >> $GITHUB_OUTPUT\n\n          CONCURRENT_CONNECTIVITY_TESTS=\"!seq-.*\"\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            CONCURRENT_CONNECTIVITY_TESTS=\"!(seq-.*|pod-to-world.*|pod-to-cidr)\"\n          fi\n          echo concurrent_connectivity_tests=${CONCURRENT_CONNECTIVITY_TESTS} >> $GITHUB_OUTPUT\n\n      - name: Derive stable Cilium installation config\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        id: cilium-stable-config\n        uses: ./.github/actions/cilium-config\n        with:\n          image-tag: ${{ steps.vars.outputs.downgrade_version }}\n          chart-dir: './untrusted/cilium-downgrade/install/kubernetes/cilium/'\n          tunnel: ${{ matrix.tunnel }}\n          devices: ${{ matrix.devices }}\n          endpoint-routes: ${{ matrix.endpoint-routes }}\n          ipv4: ${{ matrix.ipv4 }}\n          ipv6: ${{ matrix.ipv6 }}\n          underlay: ${{ matrix.underlay }}\n          kpr: ${{ matrix.kpr }}\n          lb-mode: ${{ matrix.lb-mode }}\n          lb-acceleration: ${{ matrix.lb-acceleration }}\n          encryption: ${{ matrix.encryption }}\n          encryption-node: ${{ matrix.encryption-node }}\n          encryption-strict-mode: ${{ matrix.encryption-strict-mode }}\n          egress-gateway: ${{ matrix.egress-gateway }}\n          host-fw: ${{ matrix.host-fw }}\n          mutual-auth: false\n          ingress-controller: ${{ matrix.ingress-controller }}\n          misc: ${{ matrix.misc || 'bpfClockProbe=false,cni.uninstall=false' }}\n          ciliumendpointslice: ${{ matrix.ciliumendpointslice }}\n          local-redirect-policy: ${{ matrix.local-redirect-policy }}\n          bgp-control-plane: ${{ matrix.bgp-control-plane }}\n\n      - name: Derive newest Cilium installation config\n        id: cilium-newest-config\n        uses: ./.github/actions/cilium-config\n        with:\n          image-tag: ${{ steps.vars.outputs.sha }}\n          chart-dir: './untrusted/cilium-newest/install/kubernetes/cilium'\n          tunnel: ${{ matrix.tunnel }}\n          devices: ${{ matrix.devices }}\n          endpoint-routes: ${{ matrix.endpoint-routes }}\n          ipv4: ${{ matrix.ipv4 }}\n          ipv6: ${{ matrix.ipv6 }}\n          underlay: ${{ matrix.underlay }}\n          kpr: ${{ matrix.kpr }}\n          lb-mode: ${{ matrix.lb-mode }}\n          lb-acceleration: ${{ matrix.lb-acceleration }}\n          encryption: ${{ matrix.encryption }}\n          encryption-node: ${{ matrix.encryption-node }}\n          encryption-strict-mode: ${{ matrix.encryption-strict-mode }}\n          egress-gateway: ${{ matrix.egress-gateway }}\n          host-fw: ${{ matrix.host-fw }}\n          mutual-auth: false\n          ingress-controller: ${{ matrix.ingress-controller }}\n          misc: ${{ matrix.misc || 'bpfClockProbe=false,cni.uninstall=false' }}\n          ciliumendpointslice: ${{ matrix.ciliumendpointslice }}\n          local-redirect-policy: ${{ matrix.local-redirect-policy }}\n          bgp-control-plane: ${{ matrix.bgp-control-plane }}\n\n      - name: Set Kind params\n        id: kind-params\n        shell: bash\n        run: |\n          IP_FAM=\"dual\"\n          if [ \"${{ matrix.ipv6 }}\" == \"false\" ]; then\n            IP_FAM=\"ipv4\"\n          fi\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            IP_FAM=\"ipv6\"\n          fi\n          echo params=\"--xdp --secondary-network \\\"\\\" 3 \\\"\\\" \\\"\\\" ${{ matrix.kube-proxy }} $IP_FAM\" >> $GITHUB_OUTPUT\n\n      - name: Provision K8s on LVH VM\n        id: lvh-kind\n        uses: ./.github/actions/lvh-kind\n        with:\n          test-name: e2e-conformance\n          kernel: ${{ matrix.kernel }}\n          kind-params: \"${{ steps.kind-params.outputs.params }}\"\n          kind-image: ${{ env.KIND_K8S_IMAGE }}\n\n      - name: Set up job variables for connectivity tests\n        id: vars-conn\n        run: |\n          EXTRA_CLI_FLAGS=(\n            \"--external-target=${{ steps.lvh-kind.outputs.external_target_name }}\"\n            \"--external-other-target=${{ steps.lvh-kind.outputs.other_external_target_name }}\"\n            \"--external-cidr=${{ steps.lvh-kind.outputs.ipv4_external_cidr }}\"\n            \"--external-cidrv6=${{ steps.lvh-kind.outputs.ipv6_external_cidr }}\"\n            \"--external-ip=${{ steps.lvh-kind.outputs.ipv4_external_target }}\"\n            \"--external-ipv6=${{ steps.lvh-kind.outputs.ipv6_external_target }}\"\n            \"--external-other-ip=${{ steps.lvh-kind.outputs.ipv4_other_external_target }}\"\n            \"--external-other-ipv6=${{ steps.lvh-kind.outputs.ipv6_other_external_target }}\"\n            \"--external-target-ca-namespace=external-target-secrets\"\n            \"--external-target-ca-name=custom-ca\"\n            \"--external-target-ipv6-capable\"\n          )\n          if [ \"${{ matrix.secondary-network }}\" = \"true\" ]; then\n            EXTRA_CLI_FLAGS+=(\"--secondary-network-iface=eth1\")\n          fi\n\n          if [ \"${{ matrix.encryption-strict-mode }}\" = \"true\" ]; then\n            # \"Test Cilium after upgrade\" ran strict-mode-encryption test which caused temporary drops.\n            EXTRA_CLI_FLAGS+=(\"--expected-drop-reasons=+Traffic is unencrypted\")\n          fi\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }} \\\n                                      ${EXTRA_CLI_FLAGS[*]@Q}\"\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo \"test default: ${CONNECTIVITY_TEST_DEFAULTS}\"\n\n      - name: Setup bootid file\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            set -ex\n            for container in \\$(docker ps -q); do\n              docker exec \\$container mkdir -p /var/run/cilium/\n              docker exec \\$container sh -c 'cat /proc/sys/kernel/random/uuid > /var/run/cilium/boot_id'\n            done\n\n      - name: Start Cilium KVStore\n        id: kvstore\n        if: matrix.kvstore == 'true'\n        run: |\n          make kind-kvstore-start KVSTORE_POD_NAME=kvstore KVSTORE_POD_PORT=2378\n\n          IP=$(kubectl --namespace kube-system get pod kvstore -o jsonpath='{.status.hostIP}')\n          echo \"config= \\\n            --set=etcd.enabled=true \\\n            --set=identityAllocationMode=kvstore \\\n            --set=etcd.endpoints[0]=http://${IP}:2378 \\\n          \" >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted/cilium-newest\n          sparse-checkout: |\n            install/kubernetes/cilium\n            examples\n\n      - name: Checkout ${{ steps.vars.outputs.downgrade_version }} branch to get the Helm chart\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.downgrade_version }}\n          persist-credentials: false\n          path: untrusted/cilium-downgrade\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium ${{ matrix.skip-upgrade == 'true' && 'from main' || steps.vars.outputs.downgrade_version }}\n        shell: bash\n        run: |\n          kubectl patch node kind-worker3 --type=json -p='[{\"op\":\"add\",\"path\":\"/metadata/labels/cilium.io~1no-schedule\",\"value\":\"true\"}]'\n\n          if ${{ matrix.encryption == 'ipsec' }}; then\n            cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n          fi\n\n          if ${{ matrix.skip-upgrade != 'true' }}; then\n            cilium install ${{ steps.cilium-stable-config.outputs.config }} ${{ steps.kvstore.outputs.config }} --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n          else\n            cilium install ${{ steps.cilium-newest-config.outputs.config }} ${{ steps.kvstore.outputs.config }} --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n          fi\n\n          cilium status --wait --interactive=false\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n          mkdir -p cilium-junits\n\n      - name: Install node local DNS\n        timeout-minutes: 3\n        if: ${{ matrix.node-local-dns == 'true' }}\n        shell: bash\n        run: |\n          sed -i '/Corefile: |/r .github/actions/kind-external-targets/node-local-dns-patch.txt' untrusted/cilium-newest/examples/kubernetes-local-redirect/node-local-dns.yaml\n          kubedns=$(kubectl get svc kube-dns -n kube-system -o jsonpath=\"{.spec.clusterIP}\") && sed -i \"s/__PILLAR__DNS__SERVER__/$kubedns/g;\" untrusted/cilium-newest/examples/kubernetes-local-redirect/node-local-dns.yaml\n          sed -i \"s/__PILLAR__UPSTREAM__SERVERS__/1.1.1.1/g;\" untrusted/cilium-newest/examples/kubernetes-local-redirect/node-local-dns.yaml\n          kubectl apply -k untrusted/cilium-newest/examples/kubernetes-local-redirect\n          kubectl rollout status --timeout=2m -n kube-system ds/node-local-dns\n\n      - name: Prepare the bpftrace parameters\n        if: ${{ matrix.encryption != '' }}\n        id: bpftrace-params\n        run: |\n          CILIUM_INTERNAL_IPS=$(kubectl get ciliumnode -o jsonpath='{.items[*].spec.addresses[?(@.type==\"CiliumInternalIP\")].ip}')\n          if [[ \"${{ matrix.ipv6 }}\" == \"false\" ]]; then\n            CILIUM_INTERNAL_IPS=\"${CILIUM_INTERNAL_IPS// / ::1 } ::1\"\n          fi\n          if [[ \"${{ matrix.ipv4 }}\" == \"false\" ]]; then\n            CILIUM_INTERNAL_IPS=\"0.0.0.1 ${CILIUM_INTERNAL_IPS// / 0.0.0.1 }\"\n          fi\n\n          echo \"params=$CILIUM_INTERNAL_IPS\" >> $GITHUB_OUTPUT\n\n      - name: Start unencrypted packets check for upgrade\n        if: ${{ matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/start\n        with:\n          # disable the check for proxy traffic.\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"false\" \"${{ matrix.encryption }}\"\n\n      - name: Start conn-disrupt-test\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Upgrade Cilium\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        shell: bash\n        run: |\n          cilium upgrade \\\n            --helm-set=disableEnvoyVersionCheck=true \\\n            ${{ steps.cilium-newest-config.outputs.config }} \\\n            ${{ steps.kvstore.outputs.config }} \\\n            --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Assert that no unencrypted packets are leaked during upgrade\n        if: ${{ matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Test Cilium ${{ matrix.skip-upgrade != 'true' && 'after upgrade' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-precheck\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Start unencrypted packets check for connectivity tests after upgrade\n        if: ${{ matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/start\n        with:\n          # Enable the check for proxy traffic only if IPv4 is enabled.\n          # Otherwise we will be skipping proxy tests and won't have DNS proxy traffic.\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"${{ matrix.ipv4 != 'false' }}\" \"${{ matrix.encryption }}\"\n\n      - name: Run sequential Cilium tests\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-sequential\n          tests: 'seq-.*,!pod-to-world.*'\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Run concurrent Cilium tests\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-concurrent\n          tests: ${{ steps.vars.outputs.concurrent_connectivity_tests }}\n          test-concurrency: ${{ env.test_concurrency }}\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Check for unexpected packet drops during connectivity tests\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-postcheck\n          tests: 'no-unexpected-packet-drops'\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Assert that no unencrypted packets are leaked during connectivity tests after upgrade\n        if: ${{ matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Features tested before downgrade\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested before downgrade\"\n          json-filename: \"${{ env.job_name }} (${{ matrix.name }}) - before downgrade\"\n\n      - name: Setup conn-disrupt-test before downgrading\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Start unencrypted packets check for downgrade\n        if: ${{ matrix.skip-upgrade != 'true' && matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/start\n        with:\n          # disable the check for proxy traffic.\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"false\" \"${{ matrix.encryption }}\"\n\n\n      - name: Downgrade to Cilium ${{ steps.vars.outputs.downgrade_version }}\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        shell: bash\n        run: |\n          cilium upgrade \\\n            --helm-set=disableEnvoyVersionCheck=true \\\n            ${{ steps.cilium-stable-config.outputs.config }} \\\n            ${{ steps.kvstore.outputs.config }} \\\n            --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Assert that no unencrypted packets are leaked during downgrade\n        if: ${{ matrix.skip-upgrade != 'true' && matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Test Cilium after downgrade to ${{ steps.vars.outputs.downgrade_version }}\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-downgrade-${{ matrix.name }}-precheck\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Start unencrypted packets check for connectivity tests after downgrade\n        if: ${{ matrix.skip-upgrade != 'true' && matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/start\n        with:\n          # enable the check for proxy traffic.\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"${{ matrix.ipv4 != 'false' }}\" \"${{ matrix.encryption }}\"\n\n      - name: Run sequential Cilium tests\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-downgrade-${{ matrix.name }}-sequential\n          tests: 'seq-.*,!pod-to-world.*'\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Run concurrent Cilium tests\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-downgrade-${{ matrix.name }}-concurrent\n          tests: ${{ steps.vars.outputs.concurrent_connectivity_tests }}\n          test-concurrency: ${{ env.test_concurrency }}\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Check for unexpected packet drops during connectivity tests\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-postcheck\n          tests: 'no-unexpected-packet-drops'\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n          skip-include-conn-disrupt-test-ns-traffic: ${{ matrix.skip-include-conn-disrupt-test-ns-traffic }}\n\n      - name: Assert that no unencrypted packets are leaked during connectivity tests after downgrade\n        if: ${{ matrix.skip-upgrade != 'true' && matrix.encryption != '' }}\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Features tested after downgrade\n        if: ${{ matrix.skip-upgrade != 'true' }}\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested after downgrade\"\n          json-filename: \"${{ env.job_name }} (${{ matrix.name }}) - after downgrade\"\n\n      - name: Fetch artifacts\n        if: ${{ !success() }}\n        shell: bash\n        run: |\n          if [ \"${{ matrix.kvstore }}\" == \"true\" ]; then\n            echo\n            echo \"# Retrieving Cilium etcd logs\"\n            kubectl -n kube-system logs kvstore\n          fi\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n\n  merge-upload-and-status:\n    if: ${{ always() }}\n    name: Merge Upload and Status\n    needs: setup-and-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "tests-ipsec-upgrade.yaml",
						"object": {
							"text": "name: Cilium IPsec upgrade (ci-ipsec-upgrade)\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  workflow_dispatch:\n    inputs:\n      PR-number:\n        description: \"Pull request number.\"\n        required: true\n      context-ref:\n        description: \"Context in which the workflow runs. If PR is from a fork, will be the PR target branch (general case). If PR is NOT from a fork, will be the PR branch itself (this allows committers to test changes to workflows directly from PRs).\"\n        required: true\n      SHA:\n        description: \"SHA under test (head of the PR branch).\"\n        required: true\n      extra-args:\n        description: \"[JSON object] Arbitrary arguments passed from the trigger comment via regex capture group. Parse with 'fromJson(inputs.extra-args).argName' in workflow.\"\n        required: false\n        default: '{}'\n  push:\n    branches:\n      - 'renovate/main-**'\n\n# By specifying the access of one of the scopes, all of those that are not\n# specified are set to 'none'.\npermissions:\n  # To read actions state with catchpoint/workflow-telemetry-action\n  actions: read\n  # To be able to access the repository with actions/checkout\n  contents: read\n  # To allow retrieving information from the PR API\n  pull-requests: read\n  # To be able to set commit status\n  statuses: write\n\nconcurrency:\n  # Structure:\n  # - Workflow name\n  # - Event type\n  # - A unique identifier depending on event type:\n  #   - schedule: SHA\n  #   - workflow_dispatch: PR number\n  #\n  # This structure ensures a unique concurrency group name is generated for each\n  # type of testing, such that re-runs will cancel the previous run.\n  group: |\n    ${{ github.workflow }}\n    ${{ github.event_name }}\n    ${{\n      (github.event_name == 'push' && github.sha) ||\n      (github.event_name == 'schedule' && github.sha) ||\n      (github.event_name == 'workflow_dispatch' && github.event.inputs.PR-number)\n    }}\n  cancel-in-progress: true\n\nenv:\n  test_concurrency: 5\n\njobs:\n  echo-inputs:\n    if: ${{ github.event_name == 'workflow_dispatch' }}\n    name: Echo Workflow Dispatch Inputs\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Echo Workflow Dispatch Inputs\n        run: |\n          echo '${{ tojson(inputs) }}'\n\n  commit-status-start:\n    name: Commit Status Start\n    runs-on: ubuntu-24.04\n    steps:\n      - name: Set initial commit status\n        uses: myrotvorets/set-commit-status-action@3730c0a348a2ace3c110851bed53331bc6406e9f # v2.0.1\n        with:\n          sha: ${{ inputs.SHA || github.sha }}\n\n  generate-matrix:\n    name: Generate Matrix\n    runs-on: ubuntu-24.04\n    outputs:\n      matrix: ${{ steps.generate-matrix.outputs.matrix }}\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Convert YAML to JSON\n        run: |\n          work_dir=\".github/actions/e2e\"\n          destination_directory=\"/tmp/generated/ipsec\"\n          mkdir -p \"${destination_directory}\"\n\n          yq -o=json \"${work_dir}/ipsec_configs.yaml\" | jq . > \"${destination_directory}/configs.json\"\n\n      - name: Generate Matrix\n        id: generate-matrix\n        run: |\n          cd /tmp/generated/ipsec\n          jq '[.[] | del(.\"key-one\", .\"key-two\") | . as $entry | [$entry + {mode: \"patch\"}]] | flatten' configs.json > matrix.json\n          echo \"Generated matrix:\"\n          cat /tmp/generated/ipsec/matrix.json\n          echo \"matrix=$(jq -c . < /tmp/generated/ipsec/matrix.json)\" >> $GITHUB_OUTPUT\n\n  wait-for-images:\n    name: Wait for images\n    runs-on: ubuntu-24.04\n    timeout-minutes: 30\n    steps:\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n      - name: Wait for images\n        uses: ./.github/actions/wait-for-images\n        with:\n          SHA: ${{ inputs.SHA || github.sha }}\n\n  setup-and-test:\n    needs: [wait-for-images, generate-matrix]\n    runs-on: ${{ vars.GH_RUNNER_EXTRA_POWER_UBUNTU_LATEST || 'ubuntu-24.04' }}\n    name: 'Setup & Test'\n    env:\n      job_name: 'Setup & Test'\n    strategy:\n      fail-fast: false\n      max-parallel: 100\n      matrix:\n        include: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}\n\n    timeout-minutes: 45\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout context ref (trusted)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          # We keep the credentials here, to make sure we're able to run\n          # \"git fetch\" in print-downgrade-version.sh in a few steps below.\n          # We'll call it again to remove the credentials before pulling the\n          # untrusted branch from the PR. We remain in a trusted context while\n          # credentials persist.\n          # This remains faster than downloading the full project history to\n          # make tags available to print-downgrade-version.sh.\n          persist-credentials: true\n\n      - name: Cleanup Disk space in runner\n        uses: ./.github/actions/disk-cleanup\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get connectivity test flags\n        id: e2e_config\n        uses: ./.github/actions/cli-test-config\n\n      - name: Set up job variables\n        id: vars\n        run: |\n          if [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n            SHA=\"${{ inputs.SHA }}\"\n          else\n            SHA=\"${{ github.sha }}\"\n          fi\n          echo sha=${SHA} >> $GITHUB_OUTPUT\n          if [ \"${{ matrix.mode }}\" = \"minor\" ]; then\n            CILIUM_DOWNGRADE_VERSION=$(contrib/scripts/print-downgrade-version.sh stable)\n            IMAGE_TAG=${CILIUM_DOWNGRADE_VERSION}\n          else\n            # Upgrade from / downgrade to patch release.\n            # In some cases we expect to fail to get the version number, do not\n            # fail the workflow in such case. This is typically the case on\n            # main branch where we don't have preceeding patch releases.\n            CILIUM_DOWNGRADE_VERSION=$(contrib/scripts/print-downgrade-version.sh patch || true)\n            # Pass an empty tag to the cilium-config action to fall back to the\n            # default release image, without crafting an image path with the\n            # \"-ci\" suffix\n            IMAGE_TAG=''\n          fi\n          echo \"CILIUM_DOWNGRADE_VERSION: ${CILIUM_DOWNGRADE_VERSION}\"\n          echo \"IMAGE_TAG: ${IMAGE_TAG}\"\n          if [ -z \"${CILIUM_DOWNGRADE_VERSION}\" ]; then\n            echo \"::notice::No CILIUM_DOWNGRADE_VERSION returned; skipping remaining steps\"\n          fi\n          echo downgrade_version=${CILIUM_DOWNGRADE_VERSION} >> $GITHUB_OUTPUT\n          echo image_tag=${IMAGE_TAG} >> $GITHUB_OUTPUT\n\n          SEQUENTIAL_CONNECTIVITY_TESTS=\"seq-.*\"\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            SEQUENTIAL_CONNECTIVITY_TESTS=\"seq-.*,!(pod-to-world.*|pod-to-cidr)\"\n          fi\n          echo sequential_connectivity_tests=${SEQUENTIAL_CONNECTIVITY_TESTS} >> $GITHUB_OUTPUT\n\n          CONCURRENT_CONNECTIVITY_TESTS=\"!seq-.*\"\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            CONCURRENT_CONNECTIVITY_TESTS=\"!(seq-.*|pod-to-world.*|pod-to-cidr)\"\n          fi\n          echo concurrent_connectivity_tests=${CONCURRENT_CONNECTIVITY_TESTS} >> $GITHUB_OUTPUT\n\n      - name: Checkout pull request branch (NOT TRUSTED)\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ inputs.context-ref || github.sha }}\n          persist-credentials: false\n\n      - name: Derive stable Cilium installation config\n        id: cilium-stable-config\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/cilium-config\n        with:\n          image-tag: ${{ steps.vars.outputs.image_tag }}\n          chart-dir: './untrusted/cilium-downgrade/install/kubernetes/cilium'\n          tunnel: ${{ matrix.tunnel }}\n          endpoint-routes: ${{ matrix.endpoint-routes }}\n          ipv4: ${{ matrix.ipv4 }}\n          ipv6: ${{ matrix.ipv6 }}\n          underlay: ${{ matrix.underlay }}\n          kpr: ${{ matrix.kpr }}\n          lb-mode: ${{ matrix.lb-mode }}\n          lb-acceleration: ${{ matrix.lb-acceleration }}\n          encryption: 'ipsec'\n          encryption-node: ${{ matrix.encryption-node }}\n          egress-gateway: ${{ matrix.egress-gateway }}\n          host-fw: ${{ matrix.host-fw }}\n          ingress-controller: ${{ matrix.ingress-controller }}\n          mutual-auth: false\n          misc: 'bpfClockProbe=false,cni.uninstall=false'\n\n      - name: Derive newest Cilium installation config\n        id: cilium-newest-config\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/cilium-config\n        with:\n          image-tag: ${{ steps.vars.outputs.sha }}\n          chart-dir: './untrusted/cilium-newest/install/kubernetes/cilium'\n          tunnel: ${{ matrix.tunnel }}\n          endpoint-routes: ${{ matrix.endpoint-routes }}\n          ipv4: ${{ matrix.ipv4 }}\n          ipv6: ${{ matrix.ipv6 }}\n          underlay: ${{ matrix.underlay }}\n          kpr: ${{ matrix.kpr }}\n          lb-mode: ${{ matrix.lb-mode }}\n          lb-acceleration: ${{ matrix.lb-acceleration }}\n          encryption: 'ipsec'\n          encryption-node: ${{ matrix.encryption-node }}\n          egress-gateway: ${{ matrix.egress-gateway }}\n          host-fw: ${{ matrix.host-fw }}\n          ingress-controller: ${{ matrix.ingress-controller }}\n          mutual-auth: false\n          misc: 'bpfClockProbe=false,cni.uninstall=false'\n\n      - name: Set Kind params\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        id: kind-params\n        shell: bash\n        run: |\n          IP_FAM=\"dual\"\n          if [ \"${{ matrix.ipv6 }}\" == \"false\" ]; then\n            IP_FAM=\"ipv4\"\n          fi\n          if [ \"${{ matrix.ipv4 }}\" == \"false\" ]; then\n            IP_FAM=\"ipv6\"\n          fi\n          echo params=\"\\\"\\\" 3 \\\"\\\" \\\"\\\" ${{ matrix.kube-proxy }} $IP_FAM\" >> $GITHUB_OUTPUT\n\n      - name: Provision K8s on LVH VM\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        id: lvh-kind\n        uses: ./.github/actions/lvh-kind\n        with:\n          test-name: e2e-conformance\n          kernel: ${{ matrix.kernel }}\n          kind-params: \"${{ steps.kind-params.outputs.params }}\"\n          kind-image: ${{ env.KIND_K8S_IMAGE }}\n\n      - name: Set up job variables for connectivity tests\n        id: vars-conn\n        run: |\n          EXTRA_CLI_FLAGS=(\n            \"--external-target=${{ steps.lvh-kind.outputs.external_target_name }}\"\n            \"--external-other-target=${{ steps.lvh-kind.outputs.other_external_target_name }}\"\n            \"--external-cidr=${{ steps.lvh-kind.outputs.ipv4_external_cidr }}\"\n            \"--external-cidrv6=${{ steps.lvh-kind.outputs.ipv6_external_cidr }}\"\n            \"--external-ip=${{ steps.lvh-kind.outputs.ipv4_external_target }}\"\n            \"--external-ipv6=${{ steps.lvh-kind.outputs.ipv6_external_target }}\"\n            \"--external-other-ip=${{ steps.lvh-kind.outputs.ipv4_other_external_target }}\"\n            \"--external-other-ipv6=${{ steps.lvh-kind.outputs.ipv6_other_external_target }}\"\n            \"--external-target-ca-namespace=external-target-secrets\"\n            \"--external-target-ca-name=custom-ca\"\n            \"--external-target-ipv6-capable\"\n          )\n\n          CONNECTIVITY_TEST_DEFAULTS=\"${{ steps.e2e_config.outputs.test_flags }} \\\n                                      ${EXTRA_CLI_FLAGS[*]@Q}\"\n          echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT\n          echo \"test default: ${CONNECTIVITY_TEST_DEFAULTS}\"\n\n      - name: Setup bootid file\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: cilium/little-vm-helper@9c1f3a549af06e213863d034c13ba1c5d1e3c667 # v0.0.26\n        with:\n          provision: 'false'\n          cmd: |\n            set -ex\n            for container in \\$(docker ps -q); do\n              docker exec \\$container mkdir -p /var/run/cilium/\n              docker exec \\$container sh -c 'cat /proc/sys/kernel/random/uuid > /var/run/cilium/boot_id'\n            done\n\n      - name: Start Cilium KVStore\n        id: kvstore\n        if: ${{ steps.vars.outputs.downgrade_version != '' && matrix.kvstore == 'true' }}\n        run: |\n          make kind-kvstore-start KVSTORE_POD_NAME=kvstore KVSTORE_POD_PORT=2378\n\n          IP=$(kubectl --namespace kube-system get pod kvstore -o jsonpath='{.status.hostIP}')\n          echo \"config= \\\n            --set=etcd.enabled=true \\\n            --set=identityAllocationMode=kvstore \\\n            --set=etcd.endpoints[0]=http://${IP}:2378 \\\n          \" >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.vars.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      # Warning: since this is a privileged workflow, subsequent workflow job\n      # steps must take care not to execute untrusted code.\n      - name: Checkout pull request branch (NOT TRUSTED)\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.sha }}\n          persist-credentials: false\n          path: untrusted/cilium-newest\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Checkout ${{ steps.vars.outputs.downgrade_version }} branch to get the Helm chart\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          ref: ${{ steps.vars.outputs.downgrade_version }}\n          persist-credentials: false\n          path: untrusted/cilium-downgrade\n          sparse-checkout: |\n            install/kubernetes/cilium\n\n      - name: Install Cilium ${{ steps.vars.outputs.downgrade_version }} (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        shell: bash\n        run: |\n          kubectl patch node kind-worker3 --type=json -p='[{\"op\":\"add\",\"path\":\"/metadata/labels/cilium.io~1no-schedule\",\"value\":\"true\"}]'\n          cilium encrypt create-key --auth-algo rfc4106-gcm-aes\n\n          mkdir -p cilium-junits\n\n          cilium install \\\n            ${{ steps.cilium-stable-config.outputs.config }} \\\n            ${{ steps.kvstore.outputs.config }} \\\n            --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Prepare the bpftrace parameters\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        id: bpftrace-params\n        run: |\n          CILIUM_INTERNAL_IPS=$(kubectl get ciliumnode -o jsonpath='{.items[*].spec.addresses[?(@.type==\"CiliumInternalIP\")].ip}')\n          if [[ \"${{ matrix.ipv6 }}\" == \"false\" ]]; then\n            CILIUM_INTERNAL_IPS=\"${CILIUM_INTERNAL_IPS// / ::1 } ::1\"\n          fi\n          if [[ \"${{ matrix.ipv4 }}\" == \"false\" ]]; then\n            CILIUM_INTERNAL_IPS=\" 0.0.0.1 ${CILIUM_INTERNAL_IPS// / 0.0.0.1 }\"\n          fi\n          echo \"params=$CILIUM_INTERNAL_IPS\" >> $GITHUB_OUTPUT\n\n      - name: Start unencrypted packets check for Cilium upgrade\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/bpftrace/start\n        with:\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"${{ matrix.ipv4 != 'false' }}\" \"ipsec\"\n\n      - name: Setup conn-disrupt-test before upgrading (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Upgrade Cilium (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        shell: bash\n        run: |\n          cilium upgrade --reset-values=true \\\n            --helm-set=disableEnvoyVersionCheck=true \\\n            ${{ steps.cilium-newest-config.outputs.config }} \\\n            ${{ steps.kvstore.outputs.config }} \\\n            --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Run connection interrupted tests after upgrading (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-precheck\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Run sequential tests after upgrading (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-sequential\n          tests: ${{ steps.vars.outputs.sequential_connectivity_tests }}\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Run concurrent tests after upgrading (${{ matrix.name }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-upgrade-${{ matrix.name }}-concurrent\n          tests: ${{ steps.vars.outputs.concurrent_connectivity_tests }}\n          test-concurrency: ${{ env.test_concurrency }}\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Assert that no unencrypted packets are leaked during Cilium upgrade\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Start unencrypted packets check for Cilium downgrade\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/bpftrace/start\n        with:\n          script: ./.github/actions/bpftrace/scripts/check-encryption-leaks.bt\n          args: ${{ steps.bpftrace-params.outputs.params }} \"${{ matrix.ipv4 != 'false' }}\" \"ipsec\"\n\n      - name: Setup conn-disrupt-test before downgrading\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-setup\n\n      - name: Features tested before downgrade\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested before downgrade\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - before downgrade\"\n\n      - name: Downgrade Cilium to ${{ steps.vars.outputs.downgrade_version }} (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        shell: bash\n        run: |\n          cilium upgrade --reset-values=true \\\n            --helm-set=disableEnvoyVersionCheck=true \\\n            ${{ steps.cilium-stable-config.outputs.config }} \\\n            ${{ steps.kvstore.outputs.config }} \\\n            --set extraConfig.boot-id-file=/var/run/cilium/boot_id\n\n          cilium status --wait --interactive=false --wait-duration=10m\n          kubectl get pods --all-namespaces -o wide\n          kubectl -n kube-system exec daemonset/cilium -c cilium-agent -- cilium-dbg status\n\n      - name: Run connection interrupted tests after downgrading (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-downgrade-${{ matrix.name }}-precheck\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Run sequential tests after downgrading (${{ join(matrix.*, ', ') }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-downgrade-${{ matrix.name }}-sequential\n          tests: ${{ steps.vars.outputs.sequential_connectivity_tests }}\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Run concurrent tests after downgrading (${{ matrix.name }})\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/conn-disrupt-test-check\n        with:\n          job-name: cilium-downgrade-${{ matrix.name }}-concurrent\n          tests: ${{ steps.vars.outputs.concurrent_connectivity_tests }}\n          test-concurrency: ${{ env.test_concurrency }}\n          extra-connectivity-test-flags: ${{ steps.vars-conn.outputs.connectivity_test_defaults }}\n\n      - name: Assert that no unencrypted packets are leaked during Cilium downgrade\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/bpftrace/check\n\n      - name: Features tested after downgrade\n        if: ${{ steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/feature-status\n        with:\n          title: \"Summary of all features tested after downgrade\"\n          json-filename: \"${{ env.job_name }} (${{ join(matrix.*, ', ') }}) - after downgrade\"\n\n      - name: Fetch artifacts\n        if: ${{ steps.vars.outputs.downgrade_version != '' && !success() }}\n        shell: bash\n        run: |\n          if [ \"${{ matrix.kvstore }}\" == \"true\" ]; then\n            echo\n            echo \"# Retrieving Cilium etcd logs\"\n            kubectl -n kube-system logs kvstore\n          fi\n\n      - name: Run common post steps\n        if: ${{ always() && steps.vars.outputs.downgrade_version != '' }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ matrix.name }}\"\n          job_status: \"${{ job.status }}\"\n          capture_features_tested: false\n\n  merge-upload-and-status:\n    name: Merge Upload and Status\n    if: ${{ always() }}\n    needs: setup-and-test\n    uses: ./.github/workflows/common-post-jobs.yaml\n    secrets: inherit\n    with:\n      context-ref: ${{ inputs.context-ref || github.sha }}\n      sha: ${{ inputs.SHA || github.sha }}\n      result: ${{ needs.setup-and-test.result }}\n"
						}
					},
					{
						"name": "tests-smoke-ipv6.yaml",
						"object": {
							"text": "name: Smoke Test with IPv6\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after }}\n  cancel-in-progress: true\n\nenv:\n  KIND_CONFIG: .github/kind-config-ipv6.yaml\n  # Skip external traffic (e.g. 1.1.1.1 and www.google.com) due to no support for IPv6 in github action\n  CONFORMANCE_TEMPLATE: examples/kubernetes/connectivity-check/connectivity-check-internal.yaml\n  TIMEOUT: 5m\n  LOG_TIME: 30m\n\njobs:\n  check_changes:\n    name: Deduce required tests from code changes\n    runs-on: ubuntu-24.04\n    outputs:\n      tested: ${{ steps.tested-tree.outputs.src }}\n    steps:\n      - name: Checkout code\n        if: ${{ !github.event.pull_request }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Check code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: tested-tree\n        with:\n          # For `push` events, compare against the `ref` base branch\n          # For `pull_request` events, this is ignored and will compare against the pull request base branch\n          base: ${{ github.ref }}\n          filters: |\n            src:\n              - '!(test|Documentation)/**'\n              - '!**/*.md'\n\n  conformance-test-ipv6:\n    env:\n      job_name: \"Conformance Smoke Test with IPv6\"\n    needs: check_changes\n    if: ${{ needs.check_changes.outputs.tested == 'true' }}\n    runs-on: ubuntu-24.04\n    name: Installation and Conformance Test (ipv6)\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ github.event.pull_request.head.sha || github.sha }}\n\n      - name: Set image tag\n        id: sha\n        run: |\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n      - name: Precheck generated connectivity manifest files\n        run: |\n          make -C examples/kubernetes/connectivity-check fmt\n          make -C examples/kubernetes/connectivity-check all\n          test -z \"$(git status --porcelain)\" || (echo \"please run 'make -C examples/kubernetes/connectivity-check fmt all' and submit your changes\"; exit 1)\n\n      - name: Enable IPv6 in docker\n        run: |\n          sudo cat /etc/docker/daemon.json || true\n          # Keep existing config like cgroup-parent in github action\n          sudo sh -c \"echo '{ \\\"exec-opts\\\": [\\\"native.cgroupdriver=cgroupfs\\\"], \\\"cgroup-parent\\\": \\\"/actions_job\\\", \\\"ipv6\\\": true, \\\"fixed-cidr-v6\\\": \\\"2001:db8:1::/64\\\" }' > /etc/docker/daemon.json\"\n          sudo cat /etc/docker/daemon.json\n          sudo ip -6 route add 2001:db8:1::/64 dev docker0\n          sudo sysctl net.ipv6.conf.default.forwarding=1\n          sudo sysctl net.ipv6.conf.all.forwarding=1\n          sudo systemctl restart docker\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.KIND_CONFIG }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.sha.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Set up install variables\n        id: vars\n        run: |\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n            --helm-set nodeinit.enabled=true \\\n            --helm-set kubeProxyReplacement=true \\\n            --helm-set ipam.mode=kubernetes \\\n            --helm-set hubble.enabled=true \\\n            --helm-set hubble.relay.enabled=true \\\n            --helm-set ipv6.enabled=true \\\n            --helm-set ipv4.enabled=false \\\n            --helm-set routingMode=native \\\n            --helm-set autoDirectNodeRoutes=true \\\n            --helm-set ipv6NativeRoutingCIDR=2001:db8:1::/64 \\\n            --helm-set ingressController.enabled=true\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.sha.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl -n kube-system get pods\n\n      - name: Run conformance test (e.g. connectivity check without external 1.1.1.1 and www.google.com)\n        run: |\n          kubectl apply -f ${{ env.CONFORMANCE_TEMPLATE }}\n          kubectl wait --for=condition=Available --all deployment --timeout=${{ env.TIMEOUT }}\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n"
						}
					},
					{
						"name": "tests-smoke.yaml",
						"object": {
							"text": "name: Smoke Test\n\n# Any change in triggers needs to be reflected in the concurrency group.\non:\n  pull_request: {}\n  push:\n    branches:\n      - main\n      - ft/main/**\n  merge_group:\n    types: [checks_requested]\n\npermissions: read-all\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.event.after || github.event.merge_group && github.run_id }}\n  cancel-in-progress: ${{ !github.event.merge_group }}\n\nenv:\n  KIND_CONFIG: .github/kind-config.yaml\n  CONFORMANCE_TEMPLATE: examples/kubernetes/connectivity-check/connectivity-check.yaml\n  TIMEOUT: 2m\n  LOG_TIME: 30m\n  PROM_VERSION: 2.34.0\n\njobs:\n  check_changes:\n    name: Deduce required tests from code changes\n    runs-on: ubuntu-24.04\n    outputs:\n      tested: ${{ steps.tested-tree.outputs.src }}\n    steps:\n      - name: Checkout code\n        if: ${{ !github.event.pull_request }}\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - name: Check code changes\n        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: tested-tree\n        with:\n          # For `push` events, compare against the `ref` base branch\n          # For `pull_request` events, this is ignored and will compare against the pull request base branch\n          base: ${{ github.ref }}\n          filters: |\n            src:\n              - '!(test|Documentation)/**'\n              - '!**/*.md'\n\n  preflight-clusterrole:\n    runs-on: ubuntu-24.04\n    name: Preflight Clusterrole Check\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Check pre-flight clusterrole\n        run: make check-k8s-clusterrole\n\n  helm-charts:\n    runs-on: ubuntu-24.04\n    name: Helm Charts Check\n    steps:\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Run helm-charts\n        run: |\n          make -C install/kubernetes\n          test -z \"$(git status --porcelain)\" || (echo \"please run 'make -C install/kubernetes' and submit your changes\"; exit 1)\n\n  conformance-test:\n    env:\n      job_name: \"Conformance Smoke Test\"\n    needs: check_changes\n    if: ${{ needs.check_changes.outputs.tested == 'true' && github.event_name != 'merge_group' }}\n    runs-on: ubuntu-24.04\n    name: Installation and Conformance Test\n    steps:\n      - name: Collect Workflow Telemetry\n        uses: catchpoint/workflow-telemetry-action@94c3c3d9567a0205de6da68a76c428ce4e769af1 # v2.0.0\n        with:\n          comment_on_pr: false\n\n      - name: Checkout\n        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n        with:\n          persist-credentials: false\n\n      - name: Set Environment Variables\n        uses: ./.github/actions/set-env-variables\n\n      - name: Get Cilium's default values\n        id: default_vars\n        uses: ./.github/actions/helm-default\n        with:\n          image-tag: ${{ github.event.pull_request.head.sha || github.sha }}\n\n      - name: Set image tag\n        id: sha\n        run: |\n          echo sha=${{ steps.default_vars.outputs.sha }} >> $GITHUB_OUTPUT\n\n      - name: Precheck generated connectivity manifest files\n        run: |\n          make -C examples/kubernetes/connectivity-check fmt\n          make -C examples/kubernetes/connectivity-check all\n          test -z \"$(git status --porcelain)\" || (echo \"please run 'make -C examples/kubernetes/connectivity-check fmt all' and submit your changes\"; exit 1)\n\n      - name: Create kind cluster\n        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0\n        with:\n          version: ${{ env.KIND_VERSION }}\n          node_image: ${{ env.KIND_K8S_IMAGE }}\n          kubectl_version: ${{ env.KIND_K8S_VERSION }}\n          config: ${{ env.KIND_CONFIG }}\n          wait: 0 # The control-plane never becomes ready, since no CNI is present\n\n      - name: Wait for images to be available\n        timeout-minutes: 30\n        shell: bash\n        run: |\n          for image in cilium-ci operator-generic-ci hubble-relay-ci ; do\n            until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.sha.outputs.sha }} &> /dev/null; do sleep 45s; done\n          done\n\n      - name: Set up install variables\n        id: vars\n        run: |\n          CILIUM_INSTALL_DEFAULTS=\"${{ steps.default_vars.outputs.cilium_install_defaults }} \\\n             --helm-set nodeinit.enabled=true \\\n             --helm-set kubeProxyReplacement=true \\\n             --helm-set ipam.mode=kubernetes \\\n             --helm-set hubble.relay.enabled=true \\\n             --helm-set prometheus.enabled=true \\\n             --helm-set operator.prometheus.enabled=true \\\n             --helm-set hubble.enabled=true \\\n             --helm-set=hubble.metrics.enabled=\\\"{dns,drop,tcp,flow,port-distribution,icmp,http}\\\" \\\n             --helm-set ingressController.enabled=true\"\n\n          echo cilium_install_defaults=${CILIUM_INSTALL_DEFAULTS} >> $GITHUB_OUTPUT\n\n      - name: Install Cilium CLI\n        uses: cilium/cilium-cli@024e340cca1465e2a6336521f12370c7ca58c59a # v0.18.7\n        with:\n          skip-build: ${{ env.CILIUM_CLI_SKIP_BUILD }}\n          image-repo: ${{ env.CILIUM_CLI_IMAGE_REPO }}\n          image-tag: ${{ steps.sha.outputs.sha }}\n          repository: ${{ env.CILIUM_CLI_RELEASE_REPO }}\n          release-version: ${{ env.CILIUM_CLI_VERSION }}\n\n      - name: Install Cilium\n        id: install-cilium\n        run: |\n          cilium install ${{ steps.vars.outputs.cilium_install_defaults }}\n\n      - name: Wait for Cilium status to be ready\n        run: |\n          cilium status --wait --interactive=false\n          kubectl -n kube-system get pods\n\n      - name: Run conformance test (e.g. connectivity check)\n        run: |\n          kubectl apply -f ${{ env.CONFORMANCE_TEMPLATE }}\n          kubectl wait --for=condition=Available --all deployment --timeout=${{ env.TIMEOUT }}\n\n      - name: Check prometheus metrics\n        if: ${{ success() }}\n        run: |\n          cd $HOME\n          cilium_pod_ip=$(kubectl -n kube-system get po -o name --field-selector=status.phase==Running -l 'k8s-app=cilium' -o jsonpath='{.items[0].status.podIP}' )\n          curl http://${cilium_pod_ip}:9962/metrics > metrics-agent.prom\n\n          operator_ip=$(kubectl get pods -n kube-system -l io.cilium/app=operator -o jsonpath='{range .items[*]}{.status.podIP}{\"\\n\"}{end}')\n          curl http://${operator_ip}:9963/metrics > metrics-operator.prom\n          # Install promtool binary release. `go install` doesn't work due to\n          # https://github.com/prometheus/prometheus/issues/8852 and related issues.\n          curl -sSL --remote-name-all https://github.com/prometheus/prometheus/releases/download/v${PROM_VERSION}/{prometheus-${PROM_VERSION}.linux-amd64.tar.gz,sha256sums.txt}\n          sha256sum --check --ignore-missing sha256sums.txt\n          tar -xzvf prometheus-${PROM_VERSION}.linux-amd64.tar.gz prometheus-${PROM_VERSION}.linux-amd64/promtool\n          rm -f prometheus-${PROM_VERSION}.linux-amd64.tar.gz\n          sudo mv prometheus-${PROM_VERSION}.linux-amd64/promtool /usr/bin\n          cat metrics-agent.prom | promtool check metrics\n          cat metrics-operator.prom | promtool check metrics\n\n      - name: Check prometheus feature metrics documentation\n        if: ${{ success() }}\n        run: |\n          cd $HOME\n          cat metrics-agent.prom | grep cilium_feature > metrics-agent-features.prom\n          cat metrics-operator.prom | grep cilium_operator_feature > metrics-operator-features.prom\n          cd -\n          go run ./tools/feature-helm-generator \\\n             --prom-file \"$HOME/metrics-agent-features.prom\" \\\n             --metrics-prefix cilium_feature \\\n             --metrics-separators adv_connect_and_lb,controlplane,datapath,network_policies \\\n             > Documentation/observability/feature-metrics-agent.txt\n          go run ./tools/feature-helm-generator \\\n             --prom-file \"$HOME/metrics-operator-features.prom\" \\\n             --metrics-prefix cilium_operator_feature \\\n             --metrics-separators adv_connect_and_lb \\\n             > Documentation/observability/feature-metrics-operator.txt\n          if ! git diff; then\n            echo \"Feature documentation metrics out-of-sync\"\n            exit 1\n          fi\n\n      - name: Run common post steps\n        if: ${{ always() }}\n        uses: ./.github/actions/post-logic\n        with:\n          artifacts_suffix: \"${{ env.job_name }}\"\n          job_status: \"${{ job.status }}\"\n"
						}
					},
					{
						"name": "update-label-backport-pr.yaml",
						"object": {
							"text": "---\n    # A reusable workflow designed to be called from the context of a specific\n    # branch whenever a backport PR is merged. The workflow scans the backport PR\n    # body to get the list of the backported PRs and updates their labels, replacing\n    # all \"backport-pending/<version>\" with \"backport-done/<version>\".\n    name: Update labels of backported PRs\n    on:\n      workflow_call:\n        inputs:\n          pr-body:\n            required: true\n            type: string\n            description: \"The PR description containing all the references to the backported PRs.\"\n          branch:\n            required: true\n            type: string\n            description: \"The stable branch version.\"\n\n    jobs:\n      backport-label-updater:\n        name: Update labels of backported PRs\n        runs-on: ubuntu-24.04\n        permissions:\n          pull-requests: write # Adding and removing labels\n          repository-projects: read # Additionally required by `gh pr edit`\n        env:\n          body: ${{ inputs.pr-body }}\n        steps:\n          - name: Pre-process PR body\n            id: pre-process\n            uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0\n            with:\n              script: |\n                const { body } = process.env\n                return body.replace(/\\'/g, '')\n                  .replace(/\"/g, '')\n                  .replace(/`/g, '')\n                  .replace(/$/g, '')\n              result-encoding: string\n\n          - name: Update labels\n            env:\n              GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n              BRANCH: ${{ inputs.branch }}\n            run: |\n              VERSION=${BRANCH#v}\n              echo \"${{steps.pre-process.outputs.result}}\" | sed -En \"/upstream-prs/ { n; p }\" | cut -d ';' -f 1 | grep -Eo '[0-9]+' | while read -r pr; do\n                echo \"Removing label backport-pending/${VERSION} from pr #${pr}.\"\n                gh pr edit ${pr} --repo \"${GITHUB_REPOSITORY}\" --remove-label backport-pending/${VERSION}\n                echo \"Adding label backport-done/${VERSION} to pr #${pr}.\"\n                gh pr edit ${pr} --repo \"${GITHUB_REPOSITORY}\" --add-label backport-done/${VERSION}\n              done\n"
						}
					}
				]
			}
		}
	}
}